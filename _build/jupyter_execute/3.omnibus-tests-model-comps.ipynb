{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Omnibus Tests and Model Comparisons\n",
    "In the previous section, we saw how to use dummy variables with multiple categorical levels and then specify a subsequent regression model that fits group means and mean differeces. Although we called this a One-way ANOVA model, we have yet to connect what we have done with the familiar ANOVA table. In this section, we will complete the picture by discussing the nature of the ANOVA omnibus tests and showing how these are effectively *model comparisons*. The familiar ANOVA table is simply a way of displaying the results of model comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f0b40",
   "metadata": {},
   "source": [
    "## ANOVA as a Model Comparison Procedure\n",
    "In order to understand the ANOVA within the framework of linear models, we need to demonstrate how the ANOVA results are simply the outcomes from comparing different linear models in a specific way. To begin, we need to consider the logic of an *omnibus test*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd4d0f",
   "metadata": {},
   "source": [
    "### Omnibus Tests\n",
    "An omnibus test is a test that contains *multiple* comparisons between means. In comparison to a procedure such as a $t$-test, which only compares *two* means, an omnibus test can compare *multiple* means. In our example of a One-way ANOVA where $k = 3$, the omnibus null hypothesis is\n",
    "\n",
    "$$\n",
    "\\mathcal{H}_{0} : \\mu_{1} = \\mu_{2} = \\mu_{3}.\n",
    "$$\n",
    "\n",
    "In other words, the null is that *all* the means are identical. We can also put this in the context of the model in the previous part. If all the means were identical, they would the same as the grand mean and the deflections would be 0. We can therefore express our omnibus null equivalently as\n",
    "\n",
    "$$\n",
    "\\mathcal{H}_{0} : \\alpha_{1} = \\alpha_{2} = \\alpha_{3} = 0.\n",
    "$$\n",
    "\n",
    "No matter how it is written, an omnibus test is able to simultaneously consider *all possible comparions* between the group means. Within the NHST framework, a significant omnibus effect suggests that *at least one* of all possible mean differences is significant. Traditionally, we would then drill-down to see which of the differences is driving this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36146853",
   "metadata": {},
   "source": [
    "```{admonition} What is the point of an omnibus test?\n",
    ":class: tip, dropdown\n",
    "At this point, you may well ask: what is the point of an omnibus test? If we just end up drilling-down to work out which differences are significant, why not just start there? Why even both with the omnibus test? \n",
    "\n",
    "The traditional argument is one of *error control* in relation to the problem of *multiple testing* or *multiple comparisons*. If our categorical variable has $k$ levels, then there are $m = \\frac{k(k-1)}{2}$ comparisons we can make between the levels. If our desired error level is given by $\\alpha$, then across all tests the probability of *at least one* being significant is $1 - (1 - \\alpha)^{m}$. This is known as the *familywise error rate* (FWER). So, notice that whenever $m > 1$ our desired error-rate will be scaled by the number of tests and therefore get *bigger*. \n",
    "\n",
    "As an example, if we take $k = 5$ and $\\alpha = 0.05$, we have $m = 10$ comparisons between means that we can make and the FWER is \n",
    "\n",
    "$$\n",
    "\\text{FWER} = 1 - (1 - \\alpha)^{m} = 1 - 0.95^{10} = 0.40.\n",
    "$$\n",
    "\n",
    "This means there is now a 40% chance of a significant effect under the null, rather than a 5% chance. This is the *multiple testing* problem. The more levels our categorical predictor has, the worse this gets. This is where an omnibus test helps because, irrespective of the value of $k$, the FWER stays at the desired $\\alpha$ because it is only a *single test*. So, we can have a factor with many levels and can assess all the differerences simultaneously using a single test that does not inflate the FWER.\n",
    "\n",
    "It is worth noting as well that multiple testing is really a problem of NHST and frequentist statistics. Because of these approaches, there is a sense that traditional statistical inference actively *punishes* researchers for wanting to investigate and explore their data. This is not universal of all statistical methods. For instance, Bayesian statistics allows as many comparisons as you want without disturbing the probabilistic structure of the conclusions. So just know that ominbus tests and the multiple comparisons problem are not *universal* in statistics, rather they are a consequence of one particular school of thought and one particular definition of probability.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfbe13e",
   "metadata": {},
   "source": [
    "### Omnibus Tests From Model Comparisons\n",
    "So, how do we generate omnibus tests from model comparisons? To see how this works, consider that the omnibus null hypothesis above actually *implies* a specific model. If it were true that all the group means are identical, then the grouping variable is effectively meaningless. It has simply chopped the data up randomly into 3 groups. Assuming that the population means of the groups are all the *same* implies that all the data are drawn from the *same population distibution*. Thus, rather than assuming\n",
    "\n",
    "$$\n",
    "y_{ij} \\sim \\mathcal{N}\\left(\\mu + \\alpha_{j},\\sigma^{2}\\right)\n",
    "$$\n",
    "\n",
    "we are assuming\n",
    "\n",
    "$$\n",
    "y_{i} \\sim \\mathcal{N}\\left(\\mu,\\sigma^{2}\\right).\n",
    "$$\n",
    "\n",
    "Here we have *two different models*. One that just assumes a single mean for all the data and one that assumes *different* means for the different groups. Typically, these are called the *null model* and the *full model*, so we have\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{3}\n",
    "    \\mathcal{M}_{0} &: y_{i}  &&= \\mu + \\epsilon_{i} &&\\quad \\text{Null Model} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ij} &&= \\mu + \\alpha_{j} + \\epsilon_{ij} &&\\quad \\text{Full Model} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "In `R`, sticking with our `mtcars` example, we could specify these in the following way[^intercept-foot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca320d8",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(mtcars)\n",
    "mtcars$origin <- c('Japan','Japan','USA','USA','USA','USA','USA','Europe','Europe',\n",
    "                   'Europe','Europe','Europe','Europe','Europe','USA','USA','USA',\n",
    "                   'Europe','Japan','Japan','Japan','USA','USA','USA','USA',\n",
    "                   'Europe','Europe','Europe','USA','Europe','Europe','Europe')\n",
    "mtcars$origin <- as.factor(mtcars$origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f101c14",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "null.mod <- lm(mpg ~ 1,      data=mtcars) # null model (intercept only)\n",
    "full.mod <- lm(mpg ~ origin, data=mtcars) # full model (intercept + factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333cfcd",
   "metadata": {},
   "source": [
    "Thus, the full model contains our categorical variable of interest and the null model does not. If our question revolves around whether this predictor is actually necessary, a natural way to do so would be to compare how well each model fits the data. If the null and full model have a similar model fit, then it suggests that `origin` is doing little more than an intercept. In other words, the groups means appear largely identical. Alternatively, if the full model fits much better than the null model then it suggests that allowing the group means to differ is a more accurate reflection of the data. In other words, at least two of the group means appear to be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94e3e1",
   "metadata": {},
   "source": [
    "### Model Comparisons Using Sums-of-Squares\n",
    "In order to compare the model fits, the most intuitive method would be to calculate the the magnitude of the residual variance of each model and compare them. If a model fits better, its residual variance will be smaller, meaning that the average degree to which the data deviates from the model prediction is smaller. Intutively, what we might think about doing is calculating\n",
    "\n",
    "$$\n",
    "\\Delta\\sigma^{2} = \\sigma^{2}_{\\text{null}} - \\sigma^{2}_{\\text{full}}.\n",
    "$$\n",
    "\n",
    "At the level of the *population*, this would work. However, at the level of *sample estimates*, this is actually a messy quantity that does not cleanly isolate the improvement added by the full model. To see why, consider the expanded definition of the variances as calculated from a sample\n",
    "\n",
    "$$\n",
    "\\Delta\\hat{\\sigma}^{2} = \\underbrace{\\frac{\\sum{\\epsilon_{0}^{2}}}{n - p_{0}}}_{\\hat{\\sigma}^{2}_{\\text{null}}} - \\underbrace{\\frac{\\sum{\\epsilon_{1}^{2}}}{n - p_{1}}}_{\\hat{\\sigma}^{2}_{\\text{full}}},\n",
    "$$\n",
    "\n",
    "where $p_{0}$ and $p_{1}$ are the number of parameters from the null and full models. Written this way, it is clear that we are subtracting quantities with different denominators[^pop-foot]. This makes the final value unclear in terms of what it is actually telling us, because the two terms are weighted differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3853ee",
   "metadata": {},
   "source": [
    "#### Sum-of-Squares for the Effect\n",
    "Given that the residual variance is *not* a suitable metric, our solution is to simply forego the denominators to give\n",
    "\n",
    "$$\n",
    "SS_{\\text{effect}} = \\sum{\\epsilon_{0}^{2}} - \\sum{\\epsilon_{1}^{2}} = RSS_{\\text{null}} - RSS_{\\text{full}}\n",
    "$$\n",
    "\n",
    "This value is more usually known as the *between-groups sum-of-squares* ($SS_{B}$) and is formed from the *residual sum-of-squares* (RSS) from each model. Unlike the residual variance, the sum-of-squares *do* have nice summative properties and can be used to assess the model fit across models with different numbers of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86585c0",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "\n",
    "`````{admonition} Key Point!\n",
    ":class: tip\n",
    "The main point here is that, when comparing different models, the residual variance does not have nice summative properties, due to the degrees of freedom. This means that we cannot isolate the magnitude of the model improvement by using the sample error variances because\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^{2}_{\\text{effect}} \\neq \\hat{\\sigma}^{2}_{\\text{null}} - \\hat{\\sigma}^{2}_{\\text{full}}.\n",
    "$$\n",
    "\n",
    "However, we *can* work with the sums-of-squares because they *do* have nice summative properties. As such\n",
    "\n",
    "$$\n",
    "SS_{\\text{effect}} = RSS_{\\text{null}} - RSS_{\\text{full}}.\n",
    "$$\n",
    "\n",
    "This is a direct consequence of removing the messiness of the denominators from the calculation and is the reason why ANOVAs and other model comparisons procedures tend to focus on sums-of-squares.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db1ba2",
   "metadata": {},
   "source": [
    "Let us see this in practice for our two example models. In the code below, we can calculate the RSS as a measure of each model fit. The *larger* the value, the more error remains and the *worse* the model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f4ea7d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1126.0472  732.1721\n"
     ]
    }
   ],
   "source": [
    "null.RSS <- sum(resid(null.mod)^2)\n",
    "full.RSS <- sum(resid(full.mod)^2)\n",
    "\n",
    "print(c(null.RSS,full.RSS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953fa40",
   "metadata": {},
   "source": [
    "So, we can see already that the null model has a larger RSS and thus is a worse fit to the data. The difference between these values therefore tells us how much the error *reduces* after including `origin` in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dccaeb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 393.8751\n"
     ]
    }
   ],
   "source": [
    "SS.B <- null.RSS - full.RSS\n",
    "\n",
    "print(SS.B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e9305",
   "metadata": {},
   "source": [
    "Generally, we cannot interpret this value directly because it is not any sort of standardised scale. However, what we can do is compare this value *relative* to some other measure on the same scale. At present, the $SS_{B}$ gives us a sense of how much we have reduced the error of the null model by including a specific predictor. What we want to know is whether this is *large* or *small*. More generally, we want to know whether any improvement we have seen is likely to be random noise (in which case the predictor has done *nothing* to help the model) or whether it implies something more systematic about the data (such as the population means differing across the groups)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba8f2d",
   "metadata": {},
   "source": [
    "#### Sum-of-Squares for the Error\n",
    "Given what we have stated above, what we need is some measure of *noise* to compare $SS_{B}$ to. This will tell us whether $SS_{B}$ is large relative to the noise in the data, or of a similar magnitude. If it is of a similar magnitude, then we have no way of telling whether any apparent improvement is actually just random variation. It might be, or it might not be, we cannot tell. However, if the improvement is much larger than noise, then it gets harder to believe that the improvement is simply random chance. In this case, it becomes more plausible that there is some systematic relationship between the data and the predictor we have added into the full model. In the context of an ANOVA, this would be taken as evidence of some difference between the group means. For this purpose, we typically use $RSS_{\\text{full}}$ to represent noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300e08a",
   "metadata": {},
   "source": [
    "```{admonition} Why choose $RSS_{\\text{full}}$?\n",
    ":class: tip, dropdown\n",
    "In general, within the context of our two models we have two options to represent noise: $RSS_{\\text{null}}$ or $RSS_{\\text{full}}$. These are both sums-of-sqaures that reflect *error* or *noise*, as they capture the degree of variability that is left-over within each model. If it were the case that the predictor was *not* related to the data then these quantities would be similar. However, if the predictor *was* related to the data then the null model would be missing a key explanatory component and its error would be larger than it should be. This would make $RSS_{\\text{null}}$ a poor choice. Because of this, $RSS_{\\text{full}}$ becomes the much better option. If the predictor *does* relate to the data then $RSS_{\\text{full}}$ will be the correct magnitude, but if the predictor *does not* relate to the data then $RSS_{\\text{full}}$ will be similar to $RSS_{\\text{null}}$. So either way, $RSS_{\\text{full}}$ becomes the better measure of *noise*.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd265bb",
   "metadata": {},
   "source": [
    "Within the context of an ANOVA model, $RSS_{\\text{full}}$ is more usually known as the *within-group sum-of-squares*, or $SS_{W}$ for short. This is because it effectively measures variability in terms of the scattering of individual subjects around the group means. In other words, how well do the group means fit the data? Within our example in `R`, we already calculated $RSS_{\\text{full}}$ and so can simply copy it to a new variable with a different name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6444a1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 732.1721\n"
     ]
    }
   ],
   "source": [
    "SS.W <- full.RSS\n",
    "print(SS.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82eb91",
   "metadata": {},
   "source": [
    "### The $F$-ratio\n",
    "Given what we have discussed above, we could just eye-ball the magnitude of $SS_{B}$ relative to $SS_{W}$. However, a more principled approach is to combine these values into some sort of *test statistic*, akin to the $t$-statistic we have discussed previously. In doing so, we can combine the two sources of information into a single standardised value that can be interpreted across different datasets. Much in the same way that a $t$-statistic is formed by dividing an *effect* by *error*, we could similarly form a statistic by calculating $\\frac{SS_{B}}{SS_{W}}$. This would tell us how large the improvement in model fit is, relative to the amount of error left over. \n",
    "\n",
    "The statistic we use for this purpose is known as $F$ (named after *Fisher*). Given the description above, it may seem like we could calculate $F = \\frac{SS_{B}}{SS_{W}}$. However, there is some additional complexity. Although both $SS_{B}$ and $SS_{W}$ appear to be compatible, because they are both sums-of-squares, they cannot be directly compared. This is because they are both *sums*, and so their magnitude is dependant upon whatever we are summing over. If they were both summed over the same element of the model, there would be no problem. But this is not the case. As we will see below, the magnitude of $SS_{B}$ depends upon the number of model parameters, yet the magnitude of $SS_{W}$ depends upon the sample size. So both terms need to be *scaled* first, to make them truly comparable. These scaled values are known as *mean squares*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716927cd",
   "metadata": {},
   "source": [
    "#### The Between-Group Mean Square\n",
    "Starting with $SS_{B}$, this value can be interpreted as the improvement in model fit after adding a certain number of parameters to the model. Unfortunately, this value will always scale with the number of parameters we add. This is because the more parameters we add, the better the fit can become. The most extreme example of this is having one parameter for every observation. In this case, we could make the model fit *perfectly* with no error. Thus, we can always make the model better and better by adding more and more parameters[^overfit-foot]. The problem is that we do not know whether $SS_{B}$ is large because of a genuine improvement to the model fit, or simply because we have added more parameters. \n",
    "\n",
    "To make this value more meaningful, we can therefore divide it by the number of parameters we have added to give an *average improvement per-parameter*. This has the advantage of turning the sums-of-squares back into a measure of variance, but one that is now correctly calculated to give $\\hat{\\sigma}^{2}_{\\text{effect}}$. The number of additional parameters is known as the *numerator degrees of freedom* (or $df_{1}$) and the scaled version of $SS_{B}$ is known as the *between-group mean square*, or $MS_{B}$ for short. As such \n",
    "\n",
    "$$\n",
    "MS_{B} = \\frac{SS_{B}}{df_{1}} = \\frac{SS_{B}}{k - 1} = \\hat{\\sigma}^{2}_{\\text{effect}}.\n",
    "$$\n",
    "\n",
    "In the case of the `mtcars` example, we need to add $k - 1 = 2$ parameters to the model to capture the different group means. As such, we divide $SS_{B}$ by $df_{1} = 2$ to produce the $MS_{B}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e48c77",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 196.9376\n"
     ]
    }
   ],
   "source": [
    "df.1 <- 2\n",
    "MS.B <- SS.B / df.1\n",
    "print(MS.B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5280c1",
   "metadata": {},
   "source": [
    "So, we have an improvement in model fit in terms of reducing the error variance by 196.94 per-parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad470b9",
   "metadata": {},
   "source": [
    "#### The Within-Group Mean Square\n",
    "Moving on to $SS_{W}$, we have a similar problem because this value always scales with *sample size*. Remember, this is simply the RSS for the full model. As such, the more residuals we have, the larger the sum will be. As noted above for $SS_{B}$, we therefore do not know whether $SS_{W}$ is large because the model fit is poor, or because we have a large $n$.\n",
    "\n",
    "Using a similar logic to above, it would seem that we could just divide $SS_{W}$ by $n$. However, there is a catch. Because $SS_{W}$ is an *estimate* that depends upon other estimates (i.e. the parameters from the model), it does not scale with $n$ it actually scales with $n-p$. This is the same logic as Bessel's correction and agrees with what we have discussed before about degrees of freedom. In fact, dividing $SS_{W}$ by $n-p$ gives us the estimated *error variance* of the model, $\\hat{\\sigma}^{2}$. Within the context of an ANOVA, this is known as the *within-groups mean-square*, or $MS_{W}$ for short \n",
    "\n",
    "$$\n",
    "MS_{W} = \\frac{SS_{W}}{df_{2}} = \\frac{SS_{W}}{n-p} = \\hat{\\sigma}^{2}_{\\text{error}}.\n",
    "$$\n",
    "\n",
    "We can see this in our `mtcars` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30e87f9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 25.24731\n"
     ]
    }
   ],
   "source": [
    "df.2 <- full.mod$df.residual # this is always n - p\n",
    "MS.W <- SS.W / df.2\n",
    "print(MS.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6830f",
   "metadata": {},
   "source": [
    "Which, as already indicated, is *identical* to the error variance from the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168f7e2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 25.24731\n"
     ]
    }
   ],
   "source": [
    "sigma <- summary(full.mod)$sigma\n",
    "print(sigma^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df514a5e",
   "metadata": {},
   "source": [
    "This gives us the left-over variance after fitting the full model. So together, we have a reduction in residual variance of 196.94 after adding `origin` to the model, with only a residual variance of 25.25 left over. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3304a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "\n",
    "If our reduction in variance were of a similar magnitude to the amount left over, we could not say with any certainty that it was a true effect because the \"effect\" and the \"error\" look basically the same. However, in this case, the reduction in error variance is *much larger* than the amount left over, which is already suggestive of some true effect and thus that including `origin` in the model allows for a much better model fit. Because the `origin` factor allows for the group means to differ, this implies that *at least* one pair of group means are different from each other. This connects this result directly to our original omnibus hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f990f",
   "metadata": {},
   "source": [
    "```{admonition} What's in a name?\n",
    ":class: tip\n",
    "As we can see, some of the confusion around ANOVAs and ANOVA calculations simply comes down to using *different names* for familiar quantities. The name ANOVA tells us that the method involves comparing variances, yet those variances are called *mean-squares*. Usually, we would not give a name to the intermediate quantities produced during the calculation of variances, but the ANOVA names them as *sums-of-squares*. These quantities take on more importance within an ANOVA, because the sums-of-squares are the only meaningful way to compare two model fits, before they can be scaled back into variances. However, this creates a confusing collection of sums-of-squares, mean squares and degrees of freedom. \n",
    "\n",
    "*Remember*, all we are doing is comparing two models using their residuals. That is it. Try not to get too lost in the specifics of *how* this is done and keep focus on the very simple aim of the ANOVA. Remember as well that the ANOVA table was introduced by Fisher as a convenient way of organising all the arithmetic. The table was designed to make the calculations less confusing, but the table is *not* the ANOVA itself. There is nothing in an ANOVA table that implies any form of model comparison, but this is exactly what it is showing. As we will see below, in `R` such a table can be produce by *directly* comparing two models, making this perspective event clearer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a28597",
   "metadata": {},
   "source": [
    "#### The Definition of $F$\n",
    "So, given everything we have discussed above, we have taken a rather long and winding road to the definition of the $F$-statistic, which is:\n",
    "\n",
    "$$\n",
    "F = \\frac{SS_{B} / df_{1}}{SS_{W} / df_{2}} = \\frac{MS_{B}}{MS_{W}} = \\frac{\\hat{\\sigma}^{2}_{\\text{effect}}}{\\hat{\\sigma}^{2}_{\\text{error}}}.\n",
    "$$\n",
    "\n",
    "At its most basic, the $F$-ratio is compaing two measures of variance. Hence the name, Analysis of *Variance*. If we want to make this even simpler, we can say \n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{Improvement in error between the null and full models}}{\\text{Error remaining}}.\n",
    "$$\n",
    "\n",
    "Or, to put this a difference way, how much variance have we managed to explain for each parameter we have added compared to how much we still have left to explain?\n",
    "\n",
    "Given that $F$ is a *ratio*, we can think of its value in fairly simple terms. If $F = 1$ then the magnitude of the improvement is the same as the magnitude of the error. This is what we would expect if the null hypothesis were true, because any improvement is indistinguishable from normal sampling error. However, if $F > 1$, it means that the improvement is much larger than the error. The bigger this value becomes, the more the improvement dwarfs the error and the harder it becomes to believe that all we have captured is noise.\n",
    "\n",
    "Because the $F$ is the ratio of two *estimates* ($\\hat{\\sigma}^{2}_{\\text{effect}}$ and $\\hat{\\sigma}^{2}_{\\text{error}}$), and because each estimate is a *random variable*, the $F$-ratio itself is a random variable with some distribution. Under the null hypothesis that there is no effect, $\\sigma^{2}_{\\text{effect}} = \\sigma^{2}_{\\text{error}}$ and the $F$-ratio will be 1 on average, as indicated above. The null $F$-distribution, as derived from our original assumptions of normality, has a form where the expected value is 1. This makes the null $F$-distribution only *one-tailed*, as illustrated below for an example $F_{2,29}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082b24da",
   "metadata": {
    "tags": [
     "remove-input"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title ~\n",
       "Plot with title Null F-distribution, \n",
       "Plot with title F[2 * \",\" * 29]"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters\n",
    "df1 <- 2   # numerator degrees of freedom\n",
    "df2 <- 29  # denominator degrees of freedom\n",
    "\n",
    "# Range of F values to plot\n",
    "x <- seq(0, 6, length.out = 200)  # up to ~6 is enough for df1=2, df2=30\n",
    "\n",
    "# Density of the F-distribution\n",
    "y <- df(x, df1, df2)\n",
    "\n",
    "# Plot\n",
    "plot(x, y, type = \"l\",\n",
    "     lwd = 2, col = \"blue\",\n",
    "     main = bquote(\"Null F-distribution, \" ~ F[2*\",\"*29]),\n",
    "     xlab = \"F-value\", ylab = \"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd55d9c",
   "metadata": {},
   "source": [
    "If we are following NHST convention, we can therefore compare the value of $F$ we have calculated to the null distribution and produce an associated $p$-value. As with the $t$-statistic, the larger $F$ becomes, the less probable it is if the null were true and thus the *smaller* the $p$-value becomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b2fc4",
   "metadata": {},
   "source": [
    "#### Summary of Calculations\n",
    "\n",
    "Because the steps needed to calculate $F$ are quite involved, we have summarised all of them in the `R` code below. This will hopefully make it clear that we are really comparing two models to each other, it is just that we have to go about it in a slightly complicated way in order for the numbers to make sense. Also, do not worry, we will see how to automate all of this in `R` very shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5bcac81",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  F.ratio     p.value\n",
      " 7.800338 0.001946794\n"
     ]
    }
   ],
   "source": [
    "# Null model and full model\n",
    "null.mod <- lm(mpg ~ 1,      data=mtcars)\n",
    "full.mod <- lm(mpg ~ origin, data=mtcars)\n",
    "\n",
    "# Residual sums-of-squares\n",
    "null.RSS  <- sum(resid(null.mod)^2)\n",
    "full.RSS  <- sum(resid(full.mod)^2)\n",
    "\n",
    "# Sums-of-squares\n",
    "SS.B <- null.RSS - full.RSS # between-groups (model improvement)\n",
    "SS.W <- full.RSS            # within-groups (error)\n",
    "\n",
    "# Mean-squares\n",
    "df.1 <- 2                    # k - 1\n",
    "df.2 <- full.mod$df.residual # n - p\n",
    "MS.B <- SS.B / df.1          # reduction in error variance (effect)\n",
    "MS.W <- SS.W / df.2          # remaining error variance (error)\n",
    "\n",
    "# F-ratio\n",
    "F <- MS.B / MS.W\n",
    "\n",
    "# p-value from null F-distribution with df1 and df2\n",
    "p <- pf(q=F, df1=df.1, df2=df.2, lower.tail=FALSE)\n",
    "\n",
    "# Results\n",
    "print(data.frame(\"F.ratio\"=F, \"p.value\"=p), row.names=FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7bb4d8",
   "metadata": {},
   "source": [
    "The value of $F$ indicates that the reduction in error between the null and full model is nearly 8 times *larger* than we would expect, if this effect was just noise. In other words, this is nearly 8 times bigger than our expectation under the null hypothesis of no differences between the group means. The probability of achieving a value of $F_{2,29} = 7.80$ if the null were true is $p = 0.002$, which is below the usual NHST threshold of $p = 0.05$, thus this would be declared \"significant\" within this framework. In terms of our omnibus hypothesis, this is taken to imply that *at least one* of the mean differences between the levels of `origin` is also significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271ce6a",
   "metadata": {},
   "source": [
    "## ANOVA Tables in `R`\n",
    "As should now be clear, the calculation of $F$ as a metric for comparing two models is somewhat involved. As such, it would be a bit unreasonable if we were expected to perform all this arithmetic manually every time we wanted to compare two models. Luckily, `R` can do all of this very easily for us using the `anova()` function. All we do is provide the function with two models (or more) and `R` will produce an ANOVA table of all the calculations, along with an $F$-statistic and $p$-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc813785",
   "metadata": {},
   "source": [
    "### The `anova()` Function\n",
    "The built-in `anova()` function can be used in many different contexts to compare different models. For our current use case, providing two models fit using `lm()` will produce the expected ANOVA table. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9625a3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Model 1: mpg ~ 1\n",
      "Model 2: mpg ~ origin\n",
      "  Res.Df     RSS Df Sum of Sq      F   Pr(>F)   \n",
      "1     31 1126.05                                \n",
      "2     29  732.17  2    393.88 7.8003 0.001947 **\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n"
     ]
    }
   ],
   "source": [
    "print(anova(null.mod, full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd36bc",
   "metadata": {},
   "source": [
    "Within this table, we should see all the values that we calculated manually above. The `anova()` function can also automate the model comparisons procedure if we simply provide the full model, producing something closer to a traditional ANOVA table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6320b5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Response: mpg\n",
      "          Df Sum Sq Mean Sq F value   Pr(>F)   \n",
      "origin     2 393.88 196.938  7.8003 0.001947 **\n",
      "Residuals 29 732.17  25.247                    \n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n"
     ]
    }
   ],
   "source": [
    "print(anova(full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb0424",
   "metadata": {},
   "source": [
    "As practise, to make sure you have understood the discussion so far, see if you can explain all the values in this table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e4fb3",
   "metadata": {},
   "source": [
    "### The `Anova()` Function\n",
    "Although the default `anova()` function is useful for model comparisons, things start to get more complicated once we consider *unbalanced* higher-order ANOVA models. Unbalanced ANOVAs are those where there are different numbers of subjects in each group. We will discuss all this later, but for now it is enough to indicate that these types of application are special because the summative nature of the sums-of-squares breaks-down, making it harder to disentangle the different effects. Because of this, we just want to recommend the use of the `Anova()` function from the `car` package as the most flexible method of producing an ANOVA table within `R`. As an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e6a714",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type II tests)\n",
      "\n",
      "Response: mpg\n",
      "          Sum Sq Df F value   Pr(>F)   \n",
      "origin    393.88  2  7.8003 0.001947 **\n",
      "Residuals 732.17 29                    \n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "print(Anova(full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08145828",
   "metadata": {},
   "source": [
    "Here, there is no difference between `anova()` and `Anova()`. However, this will not always be true and so we would always recommend defaulting to `Anova()`. Notice that this table says `Type II tests` at the top. This is related to how the `Anova()` function deals with unablanced data, which `anova()` does not do. This is a complicated topic we will leave for another day. For the moment, just try and remember that whatever form of ANOVA table we produce, this is the result of comparing multiple models, with the $F$-statistic reflecting the degree of model improvement relative to the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73a374",
   "metadata": {},
   "source": [
    "### Effect Sizes and Confidence Intervals\n",
    "As we can see above, the standard inferential results for the omnibus tests are based on $p$-values and NHST. If we would prefer effect sizes and confidence intervals, we can generate these using the `effectsize` package. In the example below, we generate Cohen's $f$. In general, effect sizes on omnibus tests are quite messy and difficult to interpret and are often not recommended. Still, if we want omnibus tests but do not want NHST, we have few options. This could be cause to just abandon omnibus tests entirely and jump straight to comparisons between means. There is an argument for this (as we will see more in the materials next week), but if we want a traditional ANOVA with traditional omnibus tests and no $p$-values, this is our only option.\n",
    "\n",
    "Although there are several different ANOVA effect sizes, Cohen's $f^2$ is particularly useful in the context of model comparisons. ...\n",
    "\n",
    "$$\n",
    "f^2 = \\frac{R^{2}_{\\text{full}} - R^{2}_{\\text{null}}}{1 - R^{2}_{\\text{full}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a13a5ad4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For one-way between subjects designs, partial eta squared is equivalent\n",
      "  to eta squared. Returning eta squared.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m# Effect Size for ANOVA\u001b[39m\n",
      "\n",
      "Parameter | Cohen's f |      95% CI\n",
      "-----------------------------------\n",
      "origin    |      0.73 | [0.35, Inf]\n",
      "\u001b[36m\n",
      "- One-sided CIs: upper bound fixed at [Inf].\u001b[39m"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.733453704897696"
      ],
      "text/latex": [
       "0.733453704897696"
      ],
      "text/markdown": [
       "0.733453704897696"
      ],
      "text/plain": [
       "[1] 0.7334537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(effectsize)\n",
    "aov.table <- Anova(full.mod)\n",
    "print(cohens_f(aov.table))\n",
    "\n",
    "sqrt((summary(full.mod)$r.squared - summary(null.mod)$r.squared) / (1 - summary(full.mod)$r.squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb578a33",
   "metadata": {},
   "source": [
    "## The Regression ANOVA $F$-test\n",
    "As a final point, it is interesting to note that we did not actually need to do any of the calculations above, because the results were provided all along at the bottom of the summary table for the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a61dc0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = mpg ~ origin, data = mtcars)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.8071 -4.1718 -0.7885  3.3444 10.5929 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   21.807      1.343  16.239 4.26e-16 ***\n",
       "originJapan    3.753      2.618   1.434  0.16238    \n",
       "originUSA     -5.669      1.935  -2.929  0.00656 ** \n",
       "---\n",
       "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n",
       "\n",
       "Residual standard error: 5.025 on 29 degrees of freedom\n",
       "Multiple R-squared:  0.3498,\tAdjusted R-squared:  0.3049 \n",
       "F-statistic:   7.8 on 2 and 29 DF,  p-value: 0.001947\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(full.mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8902bce",
   "metadata": {},
   "source": [
    "Notice that the very last line says:\n",
    "\n",
    "`F-statistic:   7.8 on 2 and 29 DF,  p-value: 0.001947`\n",
    "\n",
    "which is exactly the results from the ANOVA table. In general, it is customary to always provide an omnibus test of the *whole* regression model, by comparing the full model to a model containing only an intercept. Because this model only contains a single predictor, this is then equivalent to the one-way ANOVA. In general, if there are multiple predictor variables, this will not be the same. However, the omnibus regression test is useful as a single way of asking the question \"is our model actually doing anything?\" or \"is our model any better than just fitting an intercept?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa8e53",
   "metadata": {},
   "source": [
    "`````{topic} What do you now know?\n",
    "In this section, we have explored the concept of omnibus ANOVA tests and model comparisons. After reading this section, you should have a good sense of:\n",
    "\n",
    "- What an omnibus test is and why we might be interested in using them.\n",
    "- The concept of an omnibus test as a *comparison* between two competing models (known as the *null* and *full* models).\n",
    "- The idea that the omnibus test of a single factor in an ANOVA model is equivalent to comparing a model that contains the factor and the model that does not contain the factor.\n",
    "- The concept that comparing two models uses the *residual sum-of-squares* rather than the error variance, due to differences in the number of model parameters. This results in a value known as the *between-groups sums-of-squares* ($SS_{B}$).\n",
    "- The concept that the value of $SS_{B}$ is only meaningful when *compared* to some measure of noise. This measure of noise is typically the residual sums-of-squares from the full model, which is known as the *within-groups sums-of-squares* ($SS_{W}$).\n",
    "- The idea that our final comparison forms a test statistic, known as $F$, from the ratio of the effect to the noise, similar to the structure of the $t$-statistic. However, both $SS_{B}$ and $SS_{W}$ must first be scaled to make them comparible.\n",
    "- The idea that we can perform all these calculations in `R` automatically, either through explicit model comparisons with the `anova()` function, or by using the `Anova()` function from the `car` package.\n",
    "- The concept that an overall ANOVA omnibus test is always provided at the bottom of the `summary()` table produced when using `lm()`.\n",
    "\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007d828",
   "metadata": {},
   "source": [
    "[^overfit-foot]: You may wonder what the problem is with this. Surely we want the model to fit as well as possible? However, a *perfect* fit suggests *over-fitting*. Remember, our aim is to use our model to separate those effects that are universal to our population of interest from the noise. A model that fits one specific dataset does not do this. In fact, it will be fitting *both* the effects we are interested in *and* the noise. This may result in a perfect fit for that specific dataset, but it tells us nothing about our population of interest and certainly would not fit another sample very well.\n",
    "\n",
    "[^anova-foot]: This is actually true of the `anova()` function as well, but this function does not have the flexibility to deal with unbalanced models and so should be avoided in these cases.\n",
    "\n",
    "[^intercept-foot]: Remember, the intercept term is always *implicit* in `R`. However, if you like the symmetry, you can specify the full model as `mpg ~ 1 + origin`. Similarly, you can remove the intercept by adding `- 1`, or you can use `0`. For instance, `mpg ~ origin - 1` or `mpg ~ 0 + origin`.\n",
    "\n",
    "[^pop-foot]: Remember that Bessel's correction is related to *estimating* parameters from a sample. When we have the full population, we would simply divide by $n$ and could therefore compare the variances as the denominators would be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41133d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}