{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Follow-up Tests and Visualisations\n",
    "... For instance, the typical sequence is that we have fit the model using `lm()`, checked and dealt with all the assumptions to our satisfaction and then generated the ANOVA table using `Anova()` from the `car` package. So, despite everything we have covered, the actual analysis is deceptively simple. For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb4b2f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(predvars, data, env): object 'origin' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(predvars, data, env): object 'origin' not found\nTraceback:\n",
      "1. lm(mpg ~ origin, data = mtcars)",
      "2. eval(mf, parent.frame())",
      "3. eval(mf, parent.frame())",
      "4. stats::model.frame(formula = mpg ~ origin, data = mtcars, drop.unused.levels = TRUE)",
      "5. model.frame.default(formula = mpg ~ origin, data = mtcars, drop.unused.levels = TRUE)",
      "6. eval(predvars, data, env)",
      "7. eval(predvars, data, env)"
     ]
    }
   ],
   "source": [
    "data(mtcars)\n",
    "\n",
    "# Fit full factorial model\n",
    "mod <- lm(mpg ~ origin, data=mtcars)\n",
    "\n",
    "# Check assumptions\n",
    "plot(mod)\n",
    "\n",
    "# Deal with assumptions (not shown here for brevity)\n",
    "# ...\n",
    "\n",
    "# Generate Type II ANOVA table\n",
    "print(Anova(mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a51f7f",
   "metadata": {},
   "source": [
    "## Using the Regression Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c057de",
   "metadata": {},
   "source": [
    "## Using Linear Contrasts\n",
    "\n",
    "### The `emmeans` Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc6ff0",
   "metadata": {},
   "source": [
    "## Follow-up Tests and Multiple Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7778314",
   "metadata": {},
   "source": [
    "### Planned vs Post-hoc Tests\n",
    "... Beware of this reasoning. Although planned tests are more *credible* in the sense that you are not $p$-hacking, this does not change anything about the error rate. The error does not magically know what your intentions were and then change itself. The error rate is a fact of multiple testing that does not change with intent. As such, even if you have pre-specified tests, you still need to control for multiple comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e004d8",
   "metadata": {},
   "source": [
    "## Visualising ANOVA Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110874b3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
