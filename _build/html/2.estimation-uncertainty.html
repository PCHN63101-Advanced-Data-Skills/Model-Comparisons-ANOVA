
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Uncertainty in Estimation &#8212; Linear Models II: Statistical Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=90b7ad94" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.estimation-uncertainty';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="NHST I: The Null Hypothesis" href="3.null-hypothesis-testing-I.html" />
    <link rel="prev" title="The Purpose of Statistical Inference" href="1.purpose-of-inference.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models II: Statistical Inference - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models II: Statistical Inference - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.purpose-of-inference.html">The Purpose of Statistical Inference</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Uncertainty in Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.null-hypothesis-testing-I.html">NHST I: The Null Hypothesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.null-hypothesis-testing-II.html">NHST II: Test Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.null-hypothesis-testing-III.html">NHST III: Statistical Significance</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.controversy.html">The Controversy of NHST</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Inference-Linear-Model" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Inference-Linear-Model/issues/new?title=Issue%20on%20page%20%2F2.estimation-uncertainty.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.estimation-uncertainty.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Uncertainty in Estimation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimates-as-random-variables">Parameter Estimates as Random Variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-in-r">Demonstration in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distributions">Sampling Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distributions-in-linear-models">Sampling Distributions in Linear Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-expected-value">Understanding the Expected Value</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-standard-error">Understanding the Standard Error</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-the-spread-of-x-matter">Why Does the Spread of <span class="math notranslate nohighlight">\(x\)</span> Matter?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dependence-on-sample-size">Dependence on Sample Size</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-about-the-intercept-and-variance">What About the Intercept and Variance?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-about-multiple-rgression">What About Multiple Rgression?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-uncertainty-in-r">Estimation Uncertainty in <code class="docutils literal notranslate"><span class="pre">R</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-wt">Interpreting <code class="docutils literal notranslate"><span class="pre">wt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-hp">Interpreting <code class="docutils literal notranslate"><span class="pre">hp</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-disp">Interpreting <code class="docutils literal notranslate"><span class="pre">disp</span></code></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="uncertainty-in-estimation">
<h1>Uncertainty in Estimation<a class="headerlink" href="#uncertainty-in-estimation" title="Link to this heading">#</a></h1>
<p>In the previous section, we took a detour into the philosophy of science and the logical ground upon which statistical inference is based. For the moment, we will put that discussion to one side and get back to our statistical model. As a reminder, the aim of our statistical model is to estimate <em>population quantities</em> from a sample. If we had the whole population available, there would be no need for inference and our job would be done. Given that this is almost never practical, we need some method for trying to say something about the population based on the information in the sample (even if this desire is logically flawed). In order to do so, we need to understand more about our estimates and, crucially, their uncertainty. This will allow us to judge whether we can <em>trust</em> the values we have calculated as good approximations of the population, allowing us to reach conclusions that we can try to generalise beyond this sample.</p>
<section id="parameter-estimates-as-random-variables">
<h2>Parameter Estimates as Random Variables<a class="headerlink" href="#parameter-estimates-as-random-variables" title="Link to this heading">#</a></h2>
<figure class="align-right">
<a class="reference internal image-reference" href="_images/darts-analogy.png"><img alt="_images/darts-analogy.png" src="_images/darts-analogy.png" style="width: 269.1px; height: 269.1px;" /></a>
</figure>
<p>The first characteristic of our estimates that we need to understand is that they are <em>random variables</em>. Remember that we conceptualise the population parameters as fixed. For every sample we draw from the population, we can use a method such as Maximum Likelihood to <em>estimate</em> those population constants. However, these estimates will change with every new sample we take. You can think of this like throwing darts at a dart board. If the bullseye represents the true population value, every time we take a sample and produce an estimate we are throwing a dart at the board. Sometimes we will hit the bullseyes, other times we might be close and other times we might be far away. Over time, a <em>distribution</em> of darts will emerge. If we are doing well, the hope is that most of our darts are close to the bullseye with fewer of them further away.</p>
<p>Remembering back to earlier in this unit, a variable whose value changes every time we measure it is known as a <em>random variable</em>. As such, the parameter estimates can be characterised as random variables, meaning that each estimate is associated with some probability distribution that indicates:</p>
<ol class="arabic simple">
<li><p>What the <em>average</em> value of the estimate is across different samples (the expected value)</p></li>
<li><p>How much the value of the estimate will change across difference samples (the variance)</p></li>
</ol>
<p>Ideally, these distributions would have a variance that is as <em>small</em> as possible so that the estimates do not change much from sample-to-sample. In addition, we would like these distributions to have a mean equal to the population value so that, on average, we are capturing the <em>true value</em>. In the dartboard analogy, we hope that most of our throws are close to the bullseye, with fewer throws further away. These two conditions are known as <em>efficiency</em> and <em>bias</em>. We desire estimates that are both <em>efficient</em> (minimal variance) and <em>unbiased</em> (mean is the true value). Unfortunately, there is a tension between these conditions known as the <em>bias-variance trade-off</em>, which we will explore later on the course.</p>
<section id="demonstration-in-r">
<h3>Demonstration in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#demonstration-in-r" title="Link to this heading">#</a></h3>
<p>Before getting into more detail, we can illustrate the idea of estimates being random variables in <code class="docutils literal notranslate"><span class="pre">R</span></code>. In the code below, we simulate 1,000 repeats of sampling 100 values from</p>
<div class="math notranslate nohighlight">
\[
y \sim \mathcal{N}\left(5,2\right)
\]</div>
<p>You can think of this as repeating the same experiment 1,000 times, where each repeat consists of a different sample of 100 subjects. Every time we perform the experiment, we calculate the sample mean as an estimate of the population mean <span class="math notranslate nohighlight">\(\mu\)</span>. Over the repeats, we build a collection of 1,000 estimated means <span class="math notranslate nohighlight">\(\left(\hat{\mu}_{1}, \hat{\mu}_{2}, \dots, \hat{\mu}_{1000}\right)\)</span> that we can use to approximate the <em>distribution</em> of <span class="math notranslate nohighlight">\(\hat{\mu}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">999</span><span class="p">)</span>

<span class="n">mu</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span><span class="w">             </span><span class="c1"># True mean</span>
<span class="n">sigma</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w">             </span><span class="c1"># True standard deviation</span>
<span class="n">n.sims</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span><span class="w">          </span><span class="c1"># Consider 1,000 different samples</span>
<span class="n">n</span><span class="w">      </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">100</span><span class="w">           </span><span class="c1"># Each sample will consist of 100 observations</span>
<span class="n">mu.hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">n.sims</span><span class="p">)</span><span class="w"> </span><span class="c1"># Array for saving each estimate of mu</span>

<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n.sims</span><span class="p">){</span>
<span class="w">    </span><span class="n">y</span><span class="w">         </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span><span class="w"> </span><span class="c1"># Simulate a sample from the population</span>
<span class="w">    </span><span class="n">mu.hat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w">                     </span><span class="c1"># Estimate mu and save it</span>
<span class="p">}</span>

<span class="c1"># Histogram of the sampling distribution</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">mu.hat</span><span class="p">,</span><span class="w"> </span>
<span class="w">    </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">    </span><span class="n">probability</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span>
<span class="w">    </span><span class="n">main</span><span class="o">=</span><span class="nf">expression</span><span class="p">(</span><span class="s">&quot;Sampling Distribution of &quot;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">hat</span><span class="p">(</span><span class="n">mu</span><span class="p">)),</span><span class="w"> </span>
<span class="w">    </span><span class="n">xlab</span><span class="o">=</span><span class="nf">expression</span><span class="p">(</span><span class="nf">hat</span><span class="p">(</span><span class="n">mu</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/ce0dbbd993995d66f31fc45c820d6c570021de61dc48ff5ce2a6813236560fd2.png"><img alt="_images/ce0dbbd993995d66f31fc45c820d6c570021de61dc48ff5ce2a6813236560fd2.png" src="_images/ce0dbbd993995d66f31fc45c820d6c570021de61dc48ff5ce2a6813236560fd2.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>So we can see that <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> is indeed a random variable, with a distribution looks a lot like a normal distribution. In fact, it <em>is</em> a normal distribution, which is a consequence of assuming that the population distribution is normal. We can also examine the empirical<a class="footnote-reference brackets" href="#empirfoot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> mean and standard deviation of this distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">mean</span><span class="p">(</span><span class="n">mu.hat</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">sd</span><span class="p">(</span><span class="n">mu.hat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 4.995861
[1] 0.2022037
</pre></div>
</div>
</div>
</div>
<p>Notice that the expected value is basically the true value of <span class="math notranslate nohighlight">\(\mu\)</span>, indicating that our estimate of the mean is <em>unbiased</em>. Notice, as well, that the standard deviation of the sampling distribution is <em>much smaller</em> than the standard deviation of the population distribution. This is an important point for inference, as we will discuss in more detail below.</p>
</section>
</section>
<section id="sampling-distributions">
<h2>Sampling Distributions<a class="headerlink" href="#sampling-distributions" title="Link to this heading">#</a></h2>
<p>The probability distributions of parameters estimates play a central role in statistical inference and so are given a special names. These are known as <em>sampling distributions</em>. So, we now have:</p>
<ul class="simple">
<li><p><em>Population distributions</em> - our theoretical data-generating process</p></li>
<li><p><em>Sampling distributions</em> - how quantities associated with the data-generating process change with each new sample.</p></li>
</ul>
<p>In the example above, the quantity that changed with each sample was a simple estimate of the mean. However, any value we can calculate from our sample that changes with each new sample is a random variable with a sampling distribution. For our current purpose, knowing the exact form of the sampling distribution is key because it tells us whether our estimate is biased, but also how <em>uncertain</em> we are about our estimated values. Because this characterisation of uncertainty is key for inference, the standard deviation of a sampling distribution is also given a special name: the <em>standard error</em>.</p>
<div class="tip admonition">
<p class="admonition-title">Standard Error vs Standard Deviation</p>
<p>Understanding what the standard error is, and how it differs from the standard deviation, is crucial because students often get these muddled. The standard deviation of a set of data represents the <em>raw variability</em> in that data. It is specific to that sample and indicates how far, on average, each data point is from the mean. The <em>standard error</em> is the theoretical variability of some estimate from that sample. This tells us how <em>precise</em> the estimate is likely to be, on average. The standard deviation is therefore most relevant for <em>descriptive statistics</em>, whereas the standard error is most relevant for <em>inferential statistics</em>.</p>
<p>If you are ever confused about which to use as error bars in plots, think about the <em>purpose</em> of the plot. As an example, if you were drawing a bar plot, think about what you want to represent about the top of the bar. If you want to indicate how much the data you have collected differs on average from the top of the bar, use the <em>standard deviation</em>. If you want to indicate how much the top of the bar is likely to change from sample-to-sample, use the <em>standard error</em>. The standard deviation is illustrating how good of a summary the top of the bar is for this one sample. The standard error is representing how accurate the top of the bar is as an estimate of the population value. In the standard deviation case, the focus is on the data moving around. In the standard error case, the focus is on the top of the bar moving around.</p>
</div>
<p>The idea of the sampling distribution is illustrated in <a class="reference internal" href="#sampling-dist-fig"><span class="std std-numref">Fig. 1</span></a>. Here, we conceptualise drawing <span class="math notranslate nohighlight">\(k\)</span> samples of size <span class="math notranslate nohighlight">\(n\)</span> from the same population distribution. Each sample provides an estimate of the mean. Based on this sample of estimates, we can build a distribution of the most probable values for <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> across repeated samples. This distribution is the <em>sampling distribution</em> of the estimate <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>.</p>
<figure class="align-default" id="sampling-dist-fig">
<a class="reference internal image-reference" href="_images/sampling-dist.png"><img alt="_images/sampling-dist.png" src="_images/sampling-dist.png" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Illustration of the concept of a sampling distribution.</span><a class="headerlink" href="#sampling-dist-fig" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="sampling-distributions-in-linear-models">
<h2>Sampling Distributions in Linear Models<a class="headerlink" href="#sampling-distributions-in-linear-models" title="Link to this heading">#</a></h2>
<p>As indicated above, the exact form of the sampling distribution is key for making inference about our estimates. If we know both its expected value and standard error, we can judge how much to trust our estimates. A sampling distribution that is <em>biased</em> with a <em>large standard error</em> suggests that our estimates will be unreliable and we would need to be very cautious drawing conclusions. Alternatively, a sampling distribution that is <em>unbiased</em> with a <em>small standard error</em> suggests that our estimates are likely to be close to the true value, allowing greater confidence in reaching conclusions based on their value.</p>
<p>So what form do the sampling distributions taken within a linear model? We could derive the distributions empirically using simulations, as shown above. However, this is unnecessary if the assumptions about the population distribution hold. Given that, in the past, there were no computers for running simulations, it was historically essential that the sampling distribution could be derived mathematically. As it turns out, if we assume a normal population distribution, the sampling distributions of the slope and intercept parameters are <em>also</em> normal. This is one of the useful features of the normal distribution and is why it is so ubiquitous in statistics.</p>
<p>To see how this works, we will use the following simple regression model as an example</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    y_{i} &amp;= \beta_{0} + \beta_{1}x_{i} + \epsilon_{i} \\
    \epsilon_{i} &amp;\sim \mathcal{N}\left(0,\sigma^{2}\right).
\end{align*}
\end{split}\]</div>
<p>For this model, statistical theory tells us that the sampling distribution of the slope estimate will be</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{1} \sim \mathcal{N}\left(\beta_{1},\frac{\sigma^{2}}{\sum{\left(x_{i} - \bar{x}\right)^{2}}}\right).
\]</div>
<p>So, this is a normal distribution with an expected value of <span class="math notranslate nohighlight">\(\beta_{1}\)</span> (the <em>true</em> slope value), and a variance that is a scaled version of the population variance.</p>
<p>We can demonstrate the correctness of this derivation using simulations in <code class="docutils literal notranslate"><span class="pre">R</span></code>. The output below compares the <em>empirical</em> mean and variance of the sampling distribution of <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> to their <em>theoretical</em> values from the formula above. You can expand the box below if you want to see the code, but the more important aspect is looking at the comparison in the output.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>

<span class="n">beta.0</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span>
<span class="n">beta.1</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">3</span>
<span class="n">sigma</span><span class="w">      </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span>
<span class="n">n</span><span class="w">          </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span>
<span class="n">n.sims</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10000</span>
<span class="n">x</span><span class="w">          </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="m">10</span><span class="p">)</span>
<span class="n">beta.1.hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">n.sims</span><span class="p">)</span>

<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n.sims</span><span class="p">){</span>
<span class="w">    </span><span class="n">y</span><span class="w">             </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">beta.0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta.1</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
<span class="w">    </span><span class="n">beta.1.hat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">))[</span><span class="m">2</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Compare theoretical and empirical values</span>
<span class="n">th.var</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">((</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">th.mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">beta.1</span>
<span class="n">em.var</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">beta.1.hat</span><span class="p">)</span>
<span class="n">em.mean</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">beta.1.hat</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">Derivation</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;Theoretical&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Empirical&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">Mean</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="n">th.mean</span><span class="p">,</span><span class="n">em.mean</span><span class="p">),</span><span class="w"> </span>
<span class="w">                 </span><span class="n">Variance</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="n">th.var</span><span class="p">,</span><span class="n">em.var</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">row.names</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Derivation     Mean   Variance
 Theoretical 3.000000 0.06241401
   Empirical 2.997817 0.06297099
</pre></div>
</div>
</div>
</div>
<p>These values are very close and, in principle, should converge as the number of simulations increases. We can also visualise the theoretical normal sampling distribution on top of the empirical sampling distribution to show their close correspondance.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>

<span class="c1"># Plot histogram of sampling distribution</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">beta.1.hat</span><span class="p">,</span><span class="w"> </span><span class="n">probability</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">1.7</span><span class="p">),</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">),</span><span class="w"> </span>
<span class="w">    </span><span class="n">breaks</span><span class="o">=</span><span class="m">50</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="nf">expression</span><span class="p">(</span><span class="s">&quot;Empirical vs Theoretical Sampling Distribution of &quot;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">hat</span><span class="p">(</span><span class="n">beta</span><span class="p">)[</span><span class="m">1</span><span class="p">]),</span>
<span class="w">    </span><span class="n">xlab</span><span class="o">=</span><span class="nf">expression</span><span class="p">(</span><span class="nf">hat</span><span class="p">(</span><span class="n">beta</span><span class="p">)[</span><span class="m">1</span><span class="p">]))</span>

<span class="c1"># Add a normal density curve with the theoretical mean and standard error</span>
<span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">th.mean</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">th.var</span><span class="p">)),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/65c4e2154117e6aa0a23e9c5450d868528f5d1447ff4d0b877b0c94e1f6ab5c5.png"><img alt="_images/65c4e2154117e6aa0a23e9c5450d868528f5d1447ff4d0b877b0c94e1f6ab5c5.png" src="_images/65c4e2154117e6aa0a23e9c5450d868528f5d1447ff4d0b877b0c94e1f6ab5c5.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>So, the main take-away here is that the theory works and the form of the sampling distribution for <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> is known. Importantly, this can be derived mathematically, without the need for simulation, though it is important to recognise that this depends upon the population distribution being normal<a class="footnote-reference brackets" href="#cltfoot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<section id="understanding-the-expected-value">
<h3>Understanding the Expected Value<a class="headerlink" href="#understanding-the-expected-value" title="Link to this heading">#</a></h3>
<p>As already mentioned, the expected value of the sampling distribution is important in order to determine whether our estimation method is <em>biased</em>. For the derivation above, we have</p>
<div class="math notranslate nohighlight">
\[
E\left(\hat{\beta}_{1}\right) = \beta_{1}.
\]</div>
<p>As such, we expect that, on average across samples, our estimate will be equal to the population value. Going back to the dartboard analogy, this would be akin to our throws mainly clustering on or around the bullseye, meaning that, on average, we have hit the bullseye<a class="footnote-reference brackets" href="#jokefoot" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. A <em>biased</em> estimate, on the other hand, would be one where our throws are consistently clustering around a point that is <em>not</em> our target. On average, we will therefore get the wrong answer. We have seen this previously when discussing the variance estimate from MLE. As such, our desire is generally for an estimate that is <em>unbiased</em> so that we have some theoretical guarantee that we will be accurately estimating the population value over repeated experimentation. Notice that this implicitly embeds the idea of <em>replication</em> in order to accurately estimate the population value.</p>
</section>
<section id="understanding-the-standard-error">
<h3>Understanding the Standard Error<a class="headerlink" href="#understanding-the-standard-error" title="Link to this heading">#</a></h3>
<p>As also mentioned above, the standard error is the name given to the standard deviation of the sampling distribution. This quantity is particularly important because it tells us, on average, how much we expect our estimate to differ from the true value. If this is <em>small</em>, then we have confidence that our estimate is likely to be close to the true value. However, if this is <em>large</em>, then we have much less confidence when interpreting our estimate, as it may actually be quite far from the true value.</p>
<p>For the derivation above, the standard error (SE) is</p>
<div class="math notranslate nohighlight">
\[
\text{SE}\left(\hat{\beta}_{1}\right) = \sqrt{\text{Var}\left(\hat{\beta}_{1}\right)} =  \sqrt{\frac{\sigma^{2}}{\sum{\left(x_{i} - \bar{x}\right)^{2}}}}.
\]</div>
<p>This looks a bit complicated, so let us work through the logic. For the moment, ignore the square-root because this just changes the units from squared distances into the original units of the data. The important element of the SE is that we are <em>scaling</em> the error variance by <span class="math notranslate nohighlight">\(\sum{\left(x_{i} - \bar{x}\right)^{2}}\)</span>. This captures the <em>spread</em> of the <span class="math notranslate nohighlight">\(x\)</span>-values. So we are dividing the spread of the data <em>vertically</em> (the error variance) by the spread of the data <em>horizontally</em>. Or, to look at this another way, the ratio of the <em>noise</em> to the <em>signal</em>.</p>
<section id="why-does-the-spread-of-x-matter">
<h4>Why Does the Spread of <span class="math notranslate nohighlight">\(x\)</span> Matter?<a class="headerlink" href="#why-does-the-spread-of-x-matter" title="Link to this heading">#</a></h4>
<p>To get a better idea of why the spread of <span class="math notranslate nohighlight">\(x\)</span>-values is important, we can run some simulations in <code class="docutils literal notranslate"><span class="pre">R</span></code>. In each instance, we simulate data using known population parameters, fixing <span class="math notranslate nohighlight">\(n = 30\)</span>, <span class="math notranslate nohighlight">\(\beta_{0} = 0\)</span>, <span class="math notranslate nohighlight">\(\beta_{1} = 2\)</span> and <span class="math notranslate nohighlight">\(\sigma = 5\)</span>. The only difference is that in the <em>low-spread</em> simulations we fix the range of <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\([9.5,10.5]\)</span>, whereas in the <em>high-spread</em> simulations we fix the range of <span class="math notranslate nohighlight">\(x\)</span> to <span class="math notranslate nohighlight">\([0,20]\)</span>. The results are shown below for 4 repeats of both the <em>low-spread</em> and <em>high-spread</em> situations, where the true regression line is shown as a dashed line and the estimated regression line is shown as a solid blue line. Again, you can expand the box to view the code, but the more important element here is the output.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span>

<span class="c1"># Plot size</span>
<span class="nf">options</span><span class="p">(</span><span class="n">repr.plot.width</span><span class="o">=</span><span class="m">14</span><span class="p">,</span><span class="w"> </span><span class="n">repr.plot.height</span><span class="o">=</span><span class="m">8</span><span class="p">)</span>

<span class="c1"># Parameters</span>
<span class="n">n</span><span class="w">      </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">30</span>
<span class="n">beta.0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span>
<span class="n">beta.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span>
<span class="n">sigma</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span>
<span class="n">n.reps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4</span>

<span class="c1"># Layout and scaling</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">mar</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">1</span><span class="p">))</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span>

<span class="c1"># Low spread sims</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n.reps</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">x.l</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">9.5</span><span class="p">,</span><span class="w"> </span><span class="m">10.5</span><span class="p">)</span>
<span class="w">  </span><span class="n">y.l</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">beta.0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta.1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x.l</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
<span class="w">  </span><span class="n">fit.l</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y.l</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x.l</span><span class="p">)</span>
<span class="w">  </span><span class="n">title</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Low Spread&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
<span class="w">  </span>
<span class="w">  </span><span class="nf">plot</span><span class="p">(</span><span class="n">x.l</span><span class="p">,</span><span class="w"> </span><span class="n">y.l</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">title</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">20</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">35</span><span class="p">))</span>
<span class="w">  </span><span class="nf">abline</span><span class="p">(</span><span class="n">fit.l</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w">         </span><span class="c1"># Estimated line</span>
<span class="w">  </span><span class="nf">abline</span><span class="p">(</span><span class="n">beta.0</span><span class="p">,</span><span class="w"> </span><span class="n">beta.1</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># True line</span>
<span class="p">}</span>

<span class="c1"># Low spread sims</span>
<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n.reps</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">x.h</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">20</span><span class="p">)</span>
<span class="w">  </span><span class="n">y.h</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">beta.0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta.1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">x.h</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
<span class="w">  </span><span class="n">fit.h</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">y.h</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x.h</span><span class="p">)</span>
<span class="w">  </span><span class="n">title</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;High Spread&quot;</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
<span class="w">  </span>
<span class="w">  </span><span class="nf">plot</span><span class="p">(</span><span class="n">x.h</span><span class="p">,</span><span class="w"> </span><span class="n">y.h</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">title</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="m">20</span><span class="p">),</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-10</span><span class="p">,</span><span class="m">50</span><span class="p">))</span>
<span class="w">  </span><span class="nf">abline</span><span class="p">(</span><span class="n">fit.h</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w">         </span><span class="c1"># Estimated line</span>
<span class="w">  </span><span class="nf">abline</span><span class="p">(</span><span class="n">beta.0</span><span class="p">,</span><span class="w"> </span><span class="n">beta.1</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># True line</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/5473bc71d1eda579faf1a1747c3a1e55676aa3cfef81edd011da9f0c7c0e9da6.png"><img alt="_images/5473bc71d1eda579faf1a1747c3a1e55676aa3cfef81edd011da9f0c7c0e9da6.png" src="_images/5473bc71d1eda579faf1a1747c3a1e55676aa3cfef81edd011da9f0c7c0e9da6.png" style="width: 840px; height: 480px;" /></a>
</div>
</div>
<p>Notice that when the spread of <span class="math notranslate nohighlight">\(x\)</span> is very low, the estimate of the regression line is wildly unstable. This is because, with limited information about <span class="math notranslate nohighlight">\(x\)</span>, the fit is mostly influences by small changes in the vertical spread of the data. In other words, there is very little <em>signal</em> relative to the <em>noise</em>. The degree to which our estimate differs from the truth is therefore much larger and the SE will be much bigger. By comparison, when the spread of <span class="math notranslate nohighlight">\(x\)</span> is much higher, the estimate of the regression line is much more stable and corresponds much more closely to the true value. As such, the SE will be much lower.</p>
<div class="tip admonition">
<p class="admonition-title">Experimental Optimisation I</p>
<p>The dependence of the standard error on the range of values for <span class="math notranslate nohighlight">\(x\)</span> provides important information for optimising experiments. Although the predictor variables are not always under our direct control, considerations should be made about whether a good range of <span class="math notranslate nohighlight">\(x\)</span> values are available. For instance, if we are directly interested in relationships with <code class="docutils literal notranslate"><span class="pre">age</span></code> as a predictor, having a sample that ranges from 20 years old to 21 years old will likely not provide enough information. Sampling more widely and trying to achieve a good spread between 20 years old and 50 years would likely produce much more stable and meaningful estimates.</p>
</div>
</section>
<section id="dependence-on-sample-size">
<h4>Dependence on Sample Size<a class="headerlink" href="#dependence-on-sample-size" title="Link to this heading">#</a></h4>
<p>Beyond the importance of the range of <span class="math notranslate nohighlight">\(x\)</span> values, another element of great importance is the <em>amount</em> of data that we have. In the definition of the SE, notice that the value in the denominator is a <em>sum</em>, rather than an average. As such, it gets bigger as we collect more data. Although slightly hidden in the formula above, we can make this more explicit by writing</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(\hat{\beta}_{1}\right) = \frac{\sigma^{2}}{(n-1)\sigma^{2}_{x}},
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^{2}_{x}\)</span> indicates the variance of <span class="math notranslate nohighlight">\(x\)</span>. The multiplication of the <span class="math notranslate nohighlight">\((n-1)\)</span> term essentially undoes the averaging when calculating the variance of <span class="math notranslate nohighlight">\(x\)</span></p>
<div class="math notranslate nohighlight">
\[
(n-1)\sigma^{2}_{x} = (n-1) \frac{\sum{(x_{i} - \bar{x})^{2}}}{n-1} = \sum{(x_{i} - \bar{x})^{2}},
\]</div>
<p>so it is a bit redundant writing it this way. However, doing so makes the dependence on the sample size clearer. To put it simply, the <em>bigger</em> the sample size the <em>larger</em> the denominator becomes and the <em>smaller</em> the standard error. To put it even more simply, <em>more data</em> makes our estimate <em>more precise</em>.</p>
<p>This makes intuitive sense. The more data we have, the closer we are to having the full population at our disposal and thus the better our estimate of the population value should be. To make our estimate as precise as possible we want both a wide-spread of <span class="math notranslate nohighlight">\(x\)</span> values, as well as more data. We can demonstrate this dependance in <code class="docutils literal notranslate"><span class="pre">R</span></code> using simulations. The output below shows the sampling distribution of <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> for sample sizes of 5, 10, 50, 100, 1000 and 5000. Again, the code is hidden, but you can study it if you like to get a clearer idea of how these simulations work.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">777</span><span class="p">)</span>

<span class="n">beta.0</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span>
<span class="n">beta.1</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">3</span>
<span class="n">sigma</span><span class="w">      </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">5</span>
<span class="n">n.sims</span><span class="w">     </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span>
<span class="n">n</span><span class="w">          </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">5</span><span class="p">,</span><span class="m">10</span><span class="p">,</span><span class="m">50</span><span class="p">,</span><span class="m">100</span><span class="p">,</span><span class="m">1000</span><span class="p">,</span><span class="m">5000</span><span class="p">)</span>

<span class="c1"># Layout and scaling</span>
<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">mar</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">4</span><span class="p">,</span><span class="m">4</span><span class="p">,</span><span class="m">3</span><span class="p">,</span><span class="m">1</span><span class="p">))</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span>

<span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="nf">length</span><span class="p">(</span><span class="n">n</span><span class="p">)){</span>
<span class="w">    </span><span class="n">x</span><span class="w">       </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="m">0</span><span class="p">,</span><span class="m">10</span><span class="p">)</span>
<span class="w">    </span><span class="n">b.1.hat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">n.sims</span><span class="p">)</span>

<span class="w">    </span><span class="kr">for</span><span class="w"> </span><span class="p">(</span><span class="n">j</span><span class="w"> </span><span class="kr">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">n.sims</span><span class="p">){</span>
<span class="w">        </span><span class="n">y</span><span class="w">          </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="n">beta.0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta.1</span><span class="o">*</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span>
<span class="w">        </span><span class="n">b.1.hat</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">))[</span><span class="m">2</span><span class="p">]</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">std.err</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="nf">sd</span><span class="p">(</span><span class="n">b.1.hat</span><span class="p">),</span><span class="m">3</span><span class="p">)</span>
<span class="w">    </span><span class="n">title</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">paste</span><span class="p">(</span><span class="s">&quot;Sampling Distribution with n =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="s">&quot;\nSE =&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">std.err</span><span class="p">)</span>
<span class="w">    </span><span class="n">xlab</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">expression</span><span class="p">(</span><span class="nf">hat</span><span class="p">(</span><span class="n">beta</span><span class="p">)[</span><span class="m">1</span><span class="p">])</span><span class="w">  </span>
<span class="w">    </span><span class="nf">hist</span><span class="p">(</span><span class="n">b.1.hat</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-1</span><span class="p">,</span><span class="m">7</span><span class="p">),</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="n">title</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="n">xlab</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/fdfa7c096b3373e1dde85b0d51f5d68c247a6b0b949a5660bf827cb76a67081c.png"><img alt="_images/fdfa7c096b3373e1dde85b0d51f5d68c247a6b0b949a5660bf827cb76a67081c.png" src="_images/fdfa7c096b3373e1dde85b0d51f5d68c247a6b0b949a5660bf827cb76a67081c.png" style="width: 840px; height: 720px;" /></a>
</div>
</div>
<p>The shrinking width of the sampling distribution as <span class="math notranslate nohighlight">\(n\)</span> increases should be very clear. Although each of these distributions are centred on the true value, their variability differs wildly. As such, our confidence in the precision of our estimates changes dramatically as we get more and more data. When <span class="math notranslate nohighlight">\(n = 5\)</span>, we expect our estimate to differ from the true value by an average of 0.996 units. However, when <span class="math notranslate nohighlight">\(n = 5000\)</span>, we expect our estimate to differ from the true value by an average of 0.025 units. It should be clear that we are more likely to trust our estimate to be close to the true value when we have more data.</p>
<div class="tip admonition">
<p class="admonition-title">Experimental Optimisation II</p>
<p>The dependence of the standard error on the sample size provides even more important information for optimising experiments. Although we want a wide-range of values for <span class="math notranslate nohighlight">\(x\)</span>, we also want as much data as possible. A dataset where we only have a single measurement for each value of <span class="math notranslate nohighlight">\(x\)</span> is not going to be as useful as a dataset with 20 measurements for each value of <span class="math notranslate nohighlight">\(x\)</span>. So, ideally, we want <em>both</em> a large sample size and a large spread of <span class="math notranslate nohighlight">\(x\)</span> values. The importance of <em>both</em> these elements is often under-appreciated in practice, where researchers tend to fixate on sample size above everything else. However, a larger sample across a narrow range of <span class="math notranslate nohighlight">\(x\)</span> could end up being equivalent to a smaller sample across a wider range of <span class="math notranslate nohighlight">\(x\)</span> in terms of the value of the SE. Indeed, in the example in the table below, an experiment with <span class="math notranslate nohighlight">\(n=20\)</span> is better than an experiment with <span class="math notranslate nohighlight">\(n=50\)</span>, when coupled with a larger range of values for <span class="math notranslate nohighlight">\(x\)</span>.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Design</p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(n\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(\text{Var}\left(x\right)\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(n \times \text{Var}\left(x\right)\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Design A</p></td>
<td><p>50</p></td>
<td><p>4</p></td>
<td><p>200</p></td>
</tr>
<tr class="row-odd"><td><p>Design B</p></td>
<td><p>20</p></td>
<td><p>15</p></td>
<td><p>300</p></td>
</tr>
</tbody>
</table>
</div>
<p>Of course, bigger samples come with other benefits, but it is important to recognise that there is an inherent trade-off here and that bigger samples, as far as the SE is concerned, are not always better.</p>
</div>
</section>
</section>
<section id="what-about-the-intercept-and-variance">
<h3>What About the Intercept and Variance?<a class="headerlink" href="#what-about-the-intercept-and-variance" title="Link to this heading">#</a></h3>
<p>We have now spent some time discussing the sampling distribution of <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span>, but what about the sampling distributions of <span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}\)</span>? Like <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span>, under assumptions of population normality, these can be derived mathematically to give:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \hat{\beta}_{0} &amp;\sim \mathcal{N}\left(\beta_{0}, \sigma^{2}\left[\frac{1}{n} + \frac{\bar{x}^{2}}{\sum{(x_{i} - \bar{x})^{2}}}\right]\right) \\
    \hat{\sigma}^{2} &amp;\sim \frac{\sigma^{2}}{n-2} \cdot \chi^{2}\left(n-2\right)
\end{align*}
\end{split}\]</div>
<p>These looks more complex than the slope. However, we can see that the intercept is also normal and <em>unbiased</em>, with a standard error that still relies on the spread of <span class="math notranslate nohighlight">\(x\)</span> (albeit, in a more complicated form). The variance is distributed as a scaled <span class="math notranslate nohighlight">\(\chi^{2}\)</span> with parameter <span class="math notranslate nohighlight">\(k = n-2\)</span>. This <em>is</em> more complex than the distributions for the slope and intercept, but we do not need to worry about it right now. The relevance of this will come into play when we discuss the creation of <em>test statistics</em> in the next part of the lesson.</p>
</section>
<section id="what-about-multiple-rgression">
<h3>What About Multiple Rgression?<a class="headerlink" href="#what-about-multiple-rgression" title="Link to this heading">#</a></h3>
<p>We have seen the sampling distributions in <em>simple</em> regression, but what about <em>multiple</em> regression? The good news is that most of the theory stays the same. The only element that differs is the standard error. This is a consequence of the discussion we had last week about multiple regression coefficients represents the variance of a predictor <em>after</em> taking all other predictors into account. The sampling distribution for the slope estimate <span class="math notranslate nohighlight">\(j\)</span> in multiple regression is</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{j} \sim \mathcal{N}\left(\beta_{j},\frac{\sigma^{2}}{\sum{\left(x_{ij} - \bar{x}_{j}\right)^{2} \cdot \left(1 - R^{2}_{j}\right)}}\right).
\]</div>
<p>This is largely the same as before, except that the spread in <span class="math notranslate nohighlight">\(x_{j}\)</span> is now multiplied by the term <span class="math notranslate nohighlight">\((1 - R^{2}_{j})\)</span>. For now, we can think of this as an adjustment for how correlated predictor <span class="math notranslate nohighlight">\(j\)</span> is with all other predictors in the model. The bigger this is, the smaller <span class="math notranslate nohighlight">\((1 - R^{2}_{j})\)</span> becomes and the more that the spread of <span class="math notranslate nohighlight">\(x_{j}\)</span> is made <em>smaller</em>. As such, the greater the correlation, the <em>larger</em> the standard error. We will discuss the intuition behind this when we cover <em>multicollinearity</em> next week.</p>
</section>
</section>
<section id="estimation-uncertainty-in-r">
<h2>Estimation Uncertainty in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#estimation-uncertainty-in-r" title="Link to this heading">#</a></h2>
<p>As a final part to this section, we can see how <code class="docutils literal notranslate"><span class="pre">R</span></code> reports the uncertainty of all the estimates from a multiple regression fit using the <code class="docutils literal notranslate"><span class="pre">lm()</span></code> function. Here, we will return to the <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example and fit the model <code class="docutils literal notranslate"><span class="pre">mpg</span> <span class="pre">~</span> <span class="pre">wt</span> <span class="pre">+</span> <span class="pre">hp</span> <span class="pre">+</span> <span class="pre">disp</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">data</span><span class="p">(</span><span class="n">mtcars</span><span class="p">)</span>
<span class="n">mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">hp</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">disp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = mpg ~ wt + hp + disp, data = mtcars)

Residuals:
   Min     1Q Median     3Q    Max 
-3.891 -1.640 -0.172  1.061  5.861 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 37.105505   2.110815  17.579  &lt; 2e-16 ***
wt          -3.800891   1.066191  -3.565  0.00133 ** 
hp          -0.031157   0.011436  -2.724  0.01097 *  
disp        -0.000937   0.010350  -0.091  0.92851    
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 2.639 on 28 degrees of freedom
Multiple R-squared:  0.8268,	Adjusted R-squared:  0.8083 
F-statistic: 44.57 on 3 and 28 DF,  p-value: 8.65e-11
</pre></div>
</div>
</div>
</div>
<p>For each one of the slopes (and the intercept) we have a report of both the <code class="docutils literal notranslate"><span class="pre">Estimate</span></code> and the <code class="docutils literal notranslate"><span class="pre">Std.</span> <span class="pre">Error</span></code>. Let us work through each slope and see how we could interpret each estimate in light of its uncertainty. Note that we will see ways of formalising this in the next section. This is just an example of how this information can be used to assess the precision of our estimates in a more general fashion.</p>
<section id="interpreting-wt">
<h3>Interpreting <code class="docutils literal notranslate"><span class="pre">wt</span></code><a class="headerlink" href="#interpreting-wt" title="Link to this heading">#</a></h3>
<p>Starting with <code class="docutils literal notranslate"><span class="pre">wt</span></code>, we can see that, for each unit increase, we have an estimated <em>decrease</em> of 3.80 MPG. The SE is reported as 1.07, meaning that on average we expect this estimate to be around 1.07 MPG off from the true value. The estimate is therefore <em>larger</em> than its uncertainty, suggesting some reasonable degree of precision. By adding or subtracting the SE from the estimate, we can derive a plausible range of slopes within <span class="math notranslate nohighlight">\(\left[-4.88, -2.72\right]\)</span>, all of which seem to be indicative of <em>some</em> negative relationship between <code class="docutils literal notranslate"><span class="pre">wt</span></code> and <code class="docutils literal notranslate"><span class="pre">mpg</span></code>. These ranges are plotted below (as an added-variable plot), where the estimated line is shown as a dashed line, with the upper and lower limits based on <span class="math notranslate nohighlight">\(\pm 1 \times \text{SE}\)</span> shown as coloured lines.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">wt.resid</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">wt</span><span class="w">  </span><span class="o">~</span><span class="w"> </span><span class="n">hp</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">disp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">))</span>
<span class="n">mpg.resid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">hp</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">disp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">))</span>
<span class="w">  </span>
<span class="n">SE</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[</span><span class="s">&quot;wt&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Std. Error&quot;</span><span class="p">]</span>
<span class="n">lower</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">SE</span><span class="w"> </span>
<span class="n">upper</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">SE</span>

<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># Plot scale</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">wt.resid</span><span class="p">,</span><span class="w"> </span><span class="n">mpg.resid</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Weight (corrected)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;MPG (corrected)&quot;</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Estimated line</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1"># Line - 1*SE</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Line + 1*SE</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/fb6f6c58968f6a71dce288e6cc7cacc186f95d3778030edeca19a0792dc649de.png"><img alt="_images/fb6f6c58968f6a71dce288e6cc7cacc186f95d3778030edeca19a0792dc649de.png" src="_images/fb6f6c58968f6a71dce288e6cc7cacc186f95d3778030edeca19a0792dc649de.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
</section>
<section id="interpreting-hp">
<h3>Interpreting <code class="docutils literal notranslate"><span class="pre">hp</span></code><a class="headerlink" href="#interpreting-hp" title="Link to this heading">#</a></h3>
<p>A similar descriptive assessment can be made for <code class="docutils literal notranslate"><span class="pre">hp</span></code>, where the estimate is again <em>larger</em> than its uncertainty, with a plausible range of <span class="math notranslate nohighlight">\(\left[-0.043,-0.020\right]\)</span>. As with <code class="docutils literal notranslate"><span class="pre">wt</span></code>, this appears to indicate some plausible negative relationship. Again, we can plot the ranges below to give a visual sense of this interpretation.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">hp.resid</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">hp</span><span class="w">  </span><span class="o">~</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">disp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">))</span>
<span class="n">mpg.resid</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">disp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">))</span>
<span class="w">  </span>
<span class="n">SE</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[</span><span class="s">&quot;hp&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Std. Error&quot;</span><span class="p">]</span>
<span class="n">lower</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">SE</span><span class="w"> </span>
<span class="n">upper</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">3</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">SE</span>

<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># Plot scale</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">hp.resid</span><span class="p">,</span><span class="w"> </span><span class="n">mpg.resid</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;HP (corrected)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;MPG (corrected)&quot;</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">3</span><span class="p">],</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Estimated line</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1"># Line - 1*SE</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Line + 1*SE</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/e014856de95b97357e80b8b4b7eb7fe19fa0ccee7ffb79d6415124b7fb85b004.png"><img alt="_images/e014856de95b97357e80b8b4b7eb7fe19fa0ccee7ffb79d6415124b7fb85b004.png" src="_images/e014856de95b97357e80b8b4b7eb7fe19fa0ccee7ffb79d6415124b7fb85b004.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
</section>
<section id="interpreting-disp">
<h3>Interpreting <code class="docutils literal notranslate"><span class="pre">disp</span></code><a class="headerlink" href="#interpreting-disp" title="Link to this heading">#</a></h3>
<p>A different story emerges with <code class="docutils literal notranslate"><span class="pre">disp</span></code>. Here the estimate is actually <em>smaller</em> than its uncertainty, with the estimate itself close to 0. The plausible range is then <span class="math notranslate nohighlight">\(\left[-0.011, 0.010\right]\)</span>, which includes a <em>reversal</em> of the effect. This indicates a clear lack of precision about both the <em>direction</em> and <em>magnitude</em> of the true slope value. This can again be seen visually below, where the estimated slope is flat and the upper and lower slopes change direction.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">disp.resid</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">disp</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">hp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">))</span>
<span class="n">mpg.resid</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">resid</span><span class="p">(</span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w">  </span><span class="o">~</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">hp</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">))</span>
<span class="w">  </span>
<span class="n">SE</span><span class="w">    </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">$</span><span class="n">coefficients</span><span class="p">[</span><span class="s">&quot;disp&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Std. Error&quot;</span><span class="p">]</span>
<span class="n">lower</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">4</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">SE</span><span class="w"> </span>
<span class="n">upper</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">4</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">SE</span>

<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># Plot scale</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">disp.resid</span><span class="p">,</span><span class="w"> </span><span class="n">mpg.resid</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Displacement (corrected)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;MPG (corrected)&quot;</span><span class="p">)</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">mod</span><span class="p">)[</span><span class="m">4</span><span class="p">],</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;black&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="c1"># Estimated line</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1"># Line - 1*SE</span>
<span class="nf">abline</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">)</span><span class="w">  </span><span class="c1"># Line + 1*SE</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/6c32529a851ce7e3c688994b304d9b3a3e422d1146722d752cd27d1d1e741e3c.png"><img alt="_images/6c32529a851ce7e3c688994b304d9b3a3e422d1146722d752cd27d1d1e741e3c.png" src="_images/6c32529a851ce7e3c688994b304d9b3a3e422d1146722d752cd27d1d1e741e3c.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<aside class="topic">
<p class="topic-title">What do you now know?</p>
<p>In this section, we have explored how uncertainty in the estimation of population parameters can be quantified. After reading this section, you should have a good sense of:</p>
<ul class="simple">
<li><p>The concept that parameter <em>estimates</em> are random variables with some sampling distribution.</p></li>
<li><p>How the <em>mean</em> and <em>variance</em> of these sampling distributions characterise the <em>bias</em> and <em>variance</em> of our estimates (thinking of the dartboard analogy).</p></li>
<li><p>How the standard deviation of a sampling distribution is known as the <em>standard error</em>, and why this differs from the raw standard deviation of a dataset.</p></li>
<li><p>How the sampling distributions of the estimates in linear models are known, as a consequence of assuming a normal population distribution.</p></li>
<li><p>Why the estimates in linear model are considered <em>unbiased</em>.</p></li>
<li><p>How the standard error of the estimates scales with both the spread of <span class="math notranslate nohighlight">\(x\)</span> and the sample size.</p></li>
</ul>
</aside>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="empirfoot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Empirical means that we have derived the values from real data or simulation, as opposed to <em>theoretical</em> values which can be calculated using known formulas.</p>
</aside>
<aside class="footnote brackets" id="cltfoot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>This reliance on normality is not always needed. As we will explore next week, the central limit theorem indicates that under large-enough sample sizes, the sampling distribution will be normal, even if the population distribution is not.</p>
</aside>
<aside class="footnote brackets" id="jokefoot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Three statisticians go deer hunting with bows and arrows. They spot a big buck and take aim. One shoots and his arrow flies off three meters to the right. The second shoots and his arrow flies off three meters to the left. The third statistician jumps up and down yelling: We got him! We got him!.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.purpose-of-inference.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The Purpose of Statistical Inference</p>
      </div>
    </a>
    <a class="right-next"
       href="3.null-hypothesis-testing-I.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">NHST I: The Null Hypothesis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimates-as-random-variables">Parameter Estimates as Random Variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-in-r">Demonstration in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distributions">Sampling Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distributions-in-linear-models">Sampling Distributions in Linear Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-expected-value">Understanding the Expected Value</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-the-standard-error">Understanding the Standard Error</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-the-spread-of-x-matter">Why Does the Spread of <span class="math notranslate nohighlight">\(x\)</span> Matter?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dependence-on-sample-size">Dependence on Sample Size</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-about-the-intercept-and-variance">What About the Intercept and Variance?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-about-multiple-rgression">What About Multiple Rgression?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-uncertainty-in-r">Estimation Uncertainty in <code class="docutils literal notranslate"><span class="pre">R</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-wt">Interpreting <code class="docutils literal notranslate"><span class="pre">wt</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-hp">Interpreting <code class="docutils literal notranslate"><span class="pre">hp</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-disp">Interpreting <code class="docutils literal notranslate"><span class="pre">disp</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr George Farmer & Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>