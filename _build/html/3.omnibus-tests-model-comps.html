
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Omnibus Tests and Model Comparisons &#8212; Linear Models IV: Model Comparisons and the ANOVA</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=90b7ad94" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3.omnibus-tests-model-comps';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Higher-order ANOVA I: The Additive Model" href="4.higher-order-ANOVA-I.html" />
    <link rel="prev" title="One-way ANOVA" href="2.oneway-ANOVA.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models IV: Model Comparisons and the ANOVA - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models IV: Model Comparisons and the ANOVA - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.dummy-variables.html">Dummy Variable Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.oneway-ANOVA.html">One-way ANOVA</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Omnibus Tests and Model Comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.higher-order-ANOVA-I.html">Higher-order ANOVA I: The Additive Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.higher-order-ANOVA-II.html">Higher-order ANOVA II: The Full Factorial Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Model-Comparisons-ANOVA" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Model-Comparisons-ANOVA/issues/new?title=Issue%20on%20page%20%2F3.omnibus-tests-model-comps.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3.omnibus-tests-model-comps.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Omnibus Tests and Model Comparisons</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-as-a-model-comparison-procedure">ANOVA as a Model Comparison Procedure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests">Omnibus Tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests-from-model-comparisons">Omnibus Tests From Model Comparisons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparisons-using-sums-of-squares">Model Comparisons Using Sums-of-Squares</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares-for-the-effect">Sum-of-Squares for the Effect</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares-for-the-error">Sum-of-Squares for the Error</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-f-ratio">The <span class="math notranslate nohighlight">\(F\)</span>-ratio</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-between-group-mean-square">The Between-Group Mean Square</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-within-group-mean-square">The Within-Group Mean Square</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-definition-of-f">The Definition of <span class="math notranslate nohighlight">\(F\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-calculations">Summary of Calculations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-tables-in-r">ANOVA Tables in <code class="docutils literal notranslate"><span class="pre">R</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-anova-function">The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">The <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> Function</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="omnibus-tests-and-model-comparisons">
<h1>Omnibus Tests and Model Comparisons<a class="headerlink" href="#omnibus-tests-and-model-comparisons" title="Link to this heading">#</a></h1>
<p>In the previous section, we saw how to use dummy variables with multiple categorical levels and then specify a subsequent regression model that fits group means and mean differences. Although we called this a One-way ANOVA model, we have yet to connect what we have done with the familiar ANOVA table. In this section, we will complete the picture by discussing the nature of the ANOVA omnibus tests and showing how these are effectively <em>model comparisons</em>. The familiar ANOVA table is simply a way of displaying the results of model comparisons.</p>
<section id="anova-as-a-model-comparison-procedure">
<h2>ANOVA as a Model Comparison Procedure<a class="headerlink" href="#anova-as-a-model-comparison-procedure" title="Link to this heading">#</a></h2>
<p>In order to understand the ANOVA within the framework of linear models, we need to demonstrate how the ANOVA results are simply the outcomes from comparing different linear models in a specific way. To begin, we need to consider the logic of an <em>omnibus test</em>.</p>
<section id="omnibus-tests">
<h3>Omnibus Tests<a class="headerlink" href="#omnibus-tests" title="Link to this heading">#</a></h3>
<p>An omnibus test is a test that contains <em>multiple</em> comparisons between means. In comparison to a procedure such as a <span class="math notranslate nohighlight">\(t\)</span>-test, which only compares <em>two</em> means, an omnibus test can compare <em>multiple</em> means. In our example of a One-way ANOVA where <span class="math notranslate nohighlight">\(k = 3\)</span>, the omnibus null hypothesis is</p>
<div class="math notranslate nohighlight">
\[
\mathcal{H}_{0} : \mu_{1} = \mu_{2} = \mu_{3}.
\]</div>
<p>In other words, the null is that <em>all</em> the means are identical. We can also put this in the context of the model in the previous part. If all the means were identical, they would be the same as the grand mean and the deflections would be 0. We can therefore express our omnibus null equivalently as</p>
<div class="math notranslate nohighlight">
\[
\mathcal{H}_{0} : \alpha_{1} = \alpha_{2} = \alpha_{3} = 0.
\]</div>
<p>No matter how it is written, an omnibus test is able to simultaneously consider <em>all possible comparions</em> between the group means. Within the NHST framework, a significant omnibus effect suggests that <em>at least one</em> of all possible mean differences is significant. Traditionally, we would then drill-down to see which of the differences is driving this effect.</p>
<div class="tip admonition">
<p class="admonition-title">What is the point of an omnibus test?</p>
<p>At this point, you may well ask: what is the point of an omnibus test? If we just end up drilling-down to work out which differences are significant, why not just start there? Why even both with the omnibus test? There are two arguments here in favour of omnibus tests, one from a Fisherian perspective and one from a Neyman-Pearson perspective.</p>
<p>For Fisher, an omnibus test is useful as an extra layer of <em>signal detection</em>. It is asking whether investigating a particular effect in any more detail is worth our time. The argument would be that if the omnibus test of an effect were not significant, then it is not worthwhile spending time digging into the specifics. This also protects against misinterpreting noisy results by first screening the effect as a whole to see whether it is strong. So, for Fisher, an omnibus test is primarily a screening tool that also helps save time. This latter point would have been much more important in Fisher’s day, prior to the advant of computers.</p>
<p>From a Neyman-Pearson perspective, the argument is one of <em>error control</em> in relation to the problem of <em>multiple comparisons</em>. If our categorical variable has <span class="math notranslate nohighlight">\(k\)</span> levels, then there are <span class="math notranslate nohighlight">\(m = \frac{k(k-1)}{2}\)</span> comparisons we can make between the levels. If our desired error level is given by <span class="math notranslate nohighlight">\(\alpha\)</span>, then across all tests the probability of <em>at least one</em> being significant is <span class="math notranslate nohighlight">\((1 - (1 - \alpha))^{m}\)</span>. This is known as the <em>familywise error rate</em> (FWER). So, notice that whenever <span class="math notranslate nohighlight">\(m &gt; 1\)</span> our desired error-rate will be scaled by the number of tests and therefore get <em>bigger</em>. If we first screen these tests by considering a single test with an error-rate of <span class="math notranslate nohighlight">\(\alpha\)</span>, it protects us from spurious results within the individual comparisons.</p>
<p>Importantly, there are actually good arguments for <em>not</em> using omnibus tests. Although such tests have become entrenched in modern statistics, we need to remember that these are largely <em>optional</em>. Indeed, as we will see later, such tests obfuscate the actual effects we are interested in. Such an abstraction can be unhelpful, particularly when it is difficult to interpret omnibus tests numerically in terms of the actual differences we care about. Although we will spend time discussing omnibus tests, we need to remember that sometimes they are not all that useful. Indeed, they are not even the most useful approach for determining the <em>best model</em>, which is the more intuitive way of framing these tests and the way we will encourage in this lesson.</p>
</div>
</section>
<section id="omnibus-tests-from-model-comparisons">
<h3>Omnibus Tests From Model Comparisons<a class="headerlink" href="#omnibus-tests-from-model-comparisons" title="Link to this heading">#</a></h3>
<p>So, how do we generate omnibus tests from model comparisons? To see how this works, consider that the omnibus null hypothesis above actually <em>implies</em> a specific model. If it were true that all the group means are identical, then the grouping variable is effectively meaningless. It has simply chopped the data up randomly into 3 groups. Assuming that the population means of the groups are all the <em>same</em> implies that all the data are drawn from the <em>same population distribution</em>. Thus, rather than assuming</p>
<div class="math notranslate nohighlight">
\[
y_{ij} \sim \mathcal{N}\left(\mu + \alpha_{j},\sigma^{2}\right)
\]</div>
<p>we are assuming</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\mu,\sigma^{2}\right).
\]</div>
<p>Here we have <em>two different models</em>. One that just assumes a single mean for all the data and one that assumes <em>different</em> means for the different groups. Typically, these are called the <em>null model</em> and the <em>full model</em>, so we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{3}
    \mathcal{M}_{0} &amp;: y_{i}  &amp;&amp;= \mu + \epsilon_{i} &amp;&amp;\quad \text{Null Model} \\
    \mathcal{M}_{1} &amp;: y_{ij} &amp;&amp;= \mu + \alpha_{j} + \epsilon_{ij} &amp;&amp;\quad \text{Full Model} \\
\end{alignat*}
\end{split}\]</div>
<p>In <code class="docutils literal notranslate"><span class="pre">R</span></code>, sticking with our <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example, we could specify these in the following way<a class="footnote-reference brackets" href="#intercept-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">null.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">      </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span><span class="w"> </span><span class="c1"># null model (intercept only)</span>
<span class="n">full.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">origin</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span><span class="w"> </span><span class="c1"># full model (intercept + factor)</span>
</pre></div>
</div>
</div>
</div>
<p>Thus, the full model contains our categorical variable of interest and the null model does not. If our question revolves around whether this predictor is actually necessary, a natural way to do so would be to compare how well each model fits the data. If the null and full model have a similar model fit, then it suggests that <code class="docutils literal notranslate"><span class="pre">origin</span></code> is doing little more than an intercept. In other words, the groups means appear largely identical. Alternatively, if the full model fits much better than the null model then it suggests that allowing the group means to differ is a more accurate reflection of the data. In other words, at least two of the group means appear to be different.</p>
</section>
<section id="model-comparisons-using-sums-of-squares">
<h3>Model Comparisons Using Sums-of-Squares<a class="headerlink" href="#model-comparisons-using-sums-of-squares" title="Link to this heading">#</a></h3>
<p>In order to compare the model fits, the most intuitive method would be to calculate the the magnitude of the residual variance of each model and compare them. If a model fits better, its residual variance will be smaller, meaning that the average degree to which the data deviates from the model prediction is smaller. Intuitively, what we might think about doing is calculating</p>
<div class="math notranslate nohighlight">
\[
\Delta\sigma^{2} = \sigma^{2}_{\text{null}} - \sigma^{2}_{\text{full}}.
\]</div>
<p>At the level of the <em>population</em>, this would work. However, at the level of <em>sample estimates</em>, this is actually a messy quantity that does not cleanly isolate the improvement added by the full model. To see why, consider the expanded definition of the variances as calculated from a sample</p>
<div class="math notranslate nohighlight">
\[
\Delta\hat{\sigma}^{2} = \underbrace{\frac{\sum{\epsilon_{0}^{2}}}{n - p_{0}}}_{\hat{\sigma}^{2}_{\text{null}}} - \underbrace{\frac{\sum{\epsilon_{1}^{2}}}{n - p_{1}}}_{\hat{\sigma}^{2}_{\text{full}}},
\]</div>
<p>where <span class="math notranslate nohighlight">\(p_{0}\)</span> and <span class="math notranslate nohighlight">\(p_{1}\)</span> are the number of parameters from the null and full models. Written this way, it is clear that we are subtracting quantities with different denominators<a class="footnote-reference brackets" href="#pop-foot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. This makes the final value unclear in terms of what it is actually telling us, because the two terms are weighted differently.</p>
<section id="sum-of-squares-for-the-effect">
<h4>Sum-of-Squares for the Effect<a class="headerlink" href="#sum-of-squares-for-the-effect" title="Link to this heading">#</a></h4>
<p>Given that the residual variance is <em>not</em> a suitable metric, our solution is to simply forego the denominators to give</p>
<div class="math notranslate nohighlight">
\[
SS_{\text{effect}} = \sum{\epsilon_{0}^{2}} - \sum{\epsilon_{1}^{2}} = RSS_{\text{null}} - RSS_{\text{full}}
\]</div>
<p>This value is more usually known as the <em>between-groups sum-of-squares</em> (<span class="math notranslate nohighlight">\(SS_{B}\)</span>) and is formed from the <em>residual sum-of-squares</em> (RSS) from each model. Unlike the residual variance, the sum-of-squares <em>do</em> have nice summative properties and can be used to assess the model fit across models with different numbers of parameters.</p>
<p>Let us see this in practice for our two example models. In the code below, we can calculate the RSS as a measure of each model fit. The <em>larger</em> the value, the more error remains and the <em>worse</em> the model fits the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">null.RSS</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">null.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">full.RSS</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">null.RSS</span><span class="p">,</span><span class="n">full.RSS</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 1126.0472  732.1721
</pre></div>
</div>
</div>
</div>
<p>So, we can see already that the null model has a larger RSS and thus is a worse fit to the data. The difference between these values therefore tells us how much the error <em>reduces</em> after including <code class="docutils literal notranslate"><span class="pre">origin</span></code> in the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">SS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">null.RSS</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">full.RSS</span>

<span class="nf">print</span><span class="p">(</span><span class="n">SS.B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 393.8751
</pre></div>
</div>
</div>
</div>
<p>Generally, we cannot interpret this value directly because it is not any sort of standardised scale. However, what we can do is compare this value <em>relative</em> to some other measure on the same scale. At present, the <span class="math notranslate nohighlight">\(SS_{B}\)</span> gives us a sense of how much we have reduced the error of the null model by including a specific predictor. What we want to know is whether this is <em>large</em> or <em>small</em>. More generally, we want to know whether any improvement we have seen is likely to be random noise (in which case the predictor has done <em>nothing</em> to help the model) or whether it implies something more systematic about the data (such as the population means differing across the groups).</p>
</section>
<section id="sum-of-squares-for-the-error">
<h4>Sum-of-Squares for the Error<a class="headerlink" href="#sum-of-squares-for-the-error" title="Link to this heading">#</a></h4>
<p>Given what we have stated above, what we need is some measure of <em>noise</em> to compare <span class="math notranslate nohighlight">\(SS_{B}\)</span> to. This will tell us whether <span class="math notranslate nohighlight">\(SS_{B}\)</span> is large relative to the noise in the data, or of a similar magnitude. If it is of a similar magnitude, then we have no way of telling whether any apparent improvement is actually just random variation. It might be, or it might not be, we cannot tell. However, if the improvement is much larger than noise, then it gets harder to believe that the improvement is simply random chance. In this case, it becomes more plausible that there is some systematic relationship between the data and the predictor we have added into the full model. In the context of an ANOVA, this would be taken as evidence of some difference between the group means. For this purpose, we typically use <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> to represent noise.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Why choose <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span>?</p>
<p>In general, within the context of our two models we have two options to represent noise: <span class="math notranslate nohighlight">\(RSS_{\text{null}}\)</span> or <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span>. These are both sums-of-squares that reflect <em>error</em> or <em>noise</em>, as they capture the degree of variability that is left-over within each model. If it were the case that the predictor was <em>not</em> related to the data then these quantities would be similar. However, if the predictor <em>was</em> related to the data then the null model would be missing a key explanatory component and its error would be larger than it should be. This would make <span class="math notranslate nohighlight">\(RSS_{\text{null}}\)</span> a poor choice. Because of this, <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> becomes the much better option. If the predictor <em>does</em> relate to the data then <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> will be the correct magnitude, but if the predictor <em>does not</em> relate to the data then <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> will be similar to <span class="math notranslate nohighlight">\(RSS_{\text{null}}\)</span>. So either way, <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> becomes the better measure of <em>noise</em>.</p>
</div>
<p>Within the context of an ANOVA model, <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> is more usually known as the <em>within-group sum-of-squares</em>, or <span class="math notranslate nohighlight">\(SS_{W}\)</span> for short. This is because it effectively measures variability in terms of the scattering of individual subjects around the group means. In other words, how well do the group means fit the data? Within our example in <code class="docutils literal notranslate"><span class="pre">R</span></code>, we already calculated <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> and so can simply copy it to a new variable with a different name.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">SS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.RSS</span>
<span class="nf">print</span><span class="p">(</span><span class="n">SS.W</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 732.1721
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="the-f-ratio">
<h3>The <span class="math notranslate nohighlight">\(F\)</span>-ratio<a class="headerlink" href="#the-f-ratio" title="Link to this heading">#</a></h3>
<p>Given what we have discussed above, we could just eye-ball the magnitude of <span class="math notranslate nohighlight">\(SS_{B}\)</span> relative to <span class="math notranslate nohighlight">\(SS_{W}\)</span>. However, a more principled approach is to combine these values into some sort of <em>test statistic</em>, akin to the <span class="math notranslate nohighlight">\(t\)</span>-statistic we have discussed previously. In doing so, we can combine the two sources of information into a single standardised value that can be interpreted across different datasets. Much in the same way that a <span class="math notranslate nohighlight">\(t\)</span>-statistic is formed by dividing an <em>effect</em> by <em>error</em>, we could similarly form a statistic by calculating <span class="math notranslate nohighlight">\(\frac{SS_{B}}{SS_{W}}\)</span>. This would tell us how large the improvement in model fit is, relative to the amount of error left over.</p>
<p>The statistic we use for this purpose is known as <span class="math notranslate nohighlight">\(F\)</span> (named after <em>Fisher</em>). Given the description above, it may seem like we could calculate <span class="math notranslate nohighlight">\(F = \frac{SS_{B}}{SS_{W}}\)</span>. However, there is some additional complexity. Although both <span class="math notranslate nohighlight">\(SS_{B}\)</span> and <span class="math notranslate nohighlight">\(SS_{W}\)</span> appear to be compatible, because they are both sums-of-squares, they cannot be directly compared. This is because they are both <em>sums</em>, and so their magnitude is dependant upon whatever we are summing over. If they were both summed over the same element of the model, there would be no problem. But this is not the case. As we will see below, the magnitude of <span class="math notranslate nohighlight">\(SS_{B}\)</span> depends upon the number of model parameters, yet the magnitude of <span class="math notranslate nohighlight">\(SS_{W}\)</span> depends upon the sample size. So both terms need to be <em>scaled</em> first, to make them truly comparable. These scaled values are known as <em>mean squares</em>.</p>
<section id="the-between-group-mean-square">
<h4>The Between-Group Mean Square<a class="headerlink" href="#the-between-group-mean-square" title="Link to this heading">#</a></h4>
<p>Starting with <span class="math notranslate nohighlight">\(SS_{B}\)</span>, this value can be interpreted as the improvement in model fit after adding a certain number of parameters to the model. Unfortunately, this value will always scale with the number of parameters we add. This is because the more parameters we add, the better the fit can become. The most extreme example of this is having one parameter for every observation. In this case, we could make the model fit <em>perfectly</em> with no error. Thus, we can always make the model better and better by adding more and more parameters<a class="footnote-reference brackets" href="#overfit-foot" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. The problem is that we do not know whether <span class="math notranslate nohighlight">\(SS_{B}\)</span> is large because of a genuine improvement to the model fit, or simply because we have added more parameters.</p>
<p>To make this value more meaningful, we can therefore divide it by the number of parameters we have added to give an <em>average improvement per-parameter</em>. This has the advantage of turning the sums-of-squares back into a measure of variance, but one that is now correctly calculated to give <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}_{\text{effect}}\)</span>. The number of additional parameters is known as the <em>numerator degrees of freedom</em> (or <span class="math notranslate nohighlight">\(df_{1}\)</span>) and the scaled version of <span class="math notranslate nohighlight">\(SS_{B}\)</span> is known as the <em>between-group mean square</em>, or <span class="math notranslate nohighlight">\(MS_{B}\)</span> for short. As such</p>
<div class="math notranslate nohighlight">
\[
MS_{B} = \frac{SS_{B}}{df_{1}} = \frac{SS_{B}}{k - 1} = \hat{\sigma}^{2}_{\text{effect}}.
\]</div>
<p>In the case of the <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example, we need to add <span class="math notranslate nohighlight">\(k - 1 = 2\)</span> parameters to the model to capture the different group means. As such, we divide <span class="math notranslate nohighlight">\(SS_{B}\)</span> by <span class="math notranslate nohighlight">\(df_{1} = 2\)</span> to produce the <span class="math notranslate nohighlight">\(MS_{B}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">df.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span>
<span class="n">MS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.1</span>
<span class="nf">print</span><span class="p">(</span><span class="n">MS.B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 196.9376
</pre></div>
</div>
</div>
</div>
<p>So, we have an improvement in model fit in terms of reducing the error variance by 196.94 per-parameter.</p>
</section>
<section id="the-within-group-mean-square">
<h4>The Within-Group Mean Square<a class="headerlink" href="#the-within-group-mean-square" title="Link to this heading">#</a></h4>
<p>Moving on to <span class="math notranslate nohighlight">\(SS_{W}\)</span>, we have a similar problem because this value always scales with <em>sample size</em>. Remember, this is simply the RSS for the full model. As such, the more residuals we have, the larger the sum will be. As noted above for <span class="math notranslate nohighlight">\(SS_{B}\)</span>, we therefore do not know whether <span class="math notranslate nohighlight">\(SS_{W}\)</span> is large because the model fit is poor, or because we have a large <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>Using a similar logic to above, it would seem that we could just divide <span class="math notranslate nohighlight">\(SS_{W}\)</span> by <span class="math notranslate nohighlight">\(n\)</span>. However, there is a catch. Because <span class="math notranslate nohighlight">\(SS_{W}\)</span> is an <em>estimate</em> that depends upon other estimates (i.e. the parameters from the model), it does not scale with <span class="math notranslate nohighlight">\(n\)</span> it actually scales with <span class="math notranslate nohighlight">\(n-p\)</span>. This is the same logic as Bessel’s correction and agrees with what we have discussed before about degrees of freedom. In fact, dividing <span class="math notranslate nohighlight">\(SS_{W}\)</span> by <span class="math notranslate nohighlight">\(n-p\)</span> gives us the estimated <em>error variance</em> of the model, <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}\)</span>. Within the context of an ANOVA, this is known as the <em>within-groups mean-square</em>, or <span class="math notranslate nohighlight">\(MS_{W}\)</span> for short</p>
<div class="math notranslate nohighlight">
\[
MS_{W} = \frac{SS_{W}}{df_{2}} = \frac{SS_{W}}{n-p} = \hat{\sigma}^{2}_{\text{error}}.
\]</div>
<p>We can see this in our <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">df.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.mod</span><span class="o">$</span><span class="n">df.residual</span><span class="w"> </span><span class="c1"># this is always n - p</span>
<span class="n">MS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.W</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.2</span>
<span class="nf">print</span><span class="p">(</span><span class="n">MS.W</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 25.24731
</pre></div>
</div>
</div>
</div>
<p>Which, as already indicated, is <em>identical</em> to the error variance from the full model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sigma</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 25.24731
</pre></div>
</div>
</div>
</div>
<p>This gives us the left-over variance after fitting the full model. So together, we have a reduction in residual variance of 196.94 after adding <code class="docutils literal notranslate"><span class="pre">origin</span></code> to the model, with only a residual variance of 25.25 left over.</p>
<div class="tip admonition">
<p class="admonition-title">What’s in a name?</p>
<p>As we can see, some of the confusion around ANOVAs and ANOVA calculations simply comes down to using <em>different names</em> for familiar quantities. The name ANOVA tells us that the method involves comparing variances, yet those variances are called <em>mean-squares</em>. Usually, we would not give a name to the intermediate quantities produced during the calculation of variances, but the ANOVA names them as <em>sums-of-squares</em>. These quantities take on more importance within an ANOVA, because the sums-of-squares are the only meaningful way to compare two model fits, before they can be scaled back into variances. However, this creates a confusing collection of sums-of-squares, mean squares and degrees of freedom.</p>
<p><em>Remember</em>, all we are doing is comparing two models using their residuals. That is it. Try not to get too lost in the specifics of <em>how</em> this is done and keep focus on the very simple aim of the ANOVA. Remember as well that the ANOVA table was introduced by Fisher as a convenient way of organising all the arithmetic. The table was designed to make the calculations less confusing, but the table is <em>not</em> the ANOVA itself. There is nothing in an ANOVA table that implies any form of model comparison, but this is exactly what it is showing. As we will see below, in <code class="docutils literal notranslate"><span class="pre">R</span></code> such a table can be produced by <em>directly</em> comparing two models, making this perspective even clearer.</p>
</div>
</section>
<section id="the-definition-of-f">
<h4>The Definition of <span class="math notranslate nohighlight">\(F\)</span><a class="headerlink" href="#the-definition-of-f" title="Link to this heading">#</a></h4>
<p>So, given everything we have discussed above, we have taken a rather long and winding road to the definition of the <span class="math notranslate nohighlight">\(F\)</span>-statistic, which is:</p>
<div class="math notranslate nohighlight">
\[
F = \frac{SS_{B} / df_{1}}{SS_{W} / df_{2}} = \frac{MS_{B}}{MS_{W}} = \frac{\hat{\sigma}^{2}_{\text{effect}}}{\hat{\sigma}^{2}_{\text{error}}}.
\]</div>
<p>At its most basic, the <span class="math notranslate nohighlight">\(F\)</span>-ratio is comparing two measures of variance. Hence the name, Analysis of <em>Variance</em>. If we want to make this even simpler, we can say</p>
<div class="math notranslate nohighlight">
\[
F = \frac{\text{Improvement in error between the null and full models}}{\text{Error remaining}}.
\]</div>
<p>Or, to put this a different way, how much variance have we managed to explain for each parameter we have added compared to how much we still have left to explain?</p>
<p>Given that <span class="math notranslate nohighlight">\(F\)</span> is a <em>ratio</em>, we can think of its value in fairly simple terms. If <span class="math notranslate nohighlight">\(F = 1\)</span> then the magnitude of the improvement is the same as the magnitude of the error. This is what we would expect if the null hypothesis were true, because any improvement is indistinguishable from normal sampling error. However, if <span class="math notranslate nohighlight">\(F &gt; 1\)</span>, it means that the improvement is larger than the error. The bigger this value becomes, the more the improvement dwarfs the error and the harder it becomes to believe that all we have captured is noise.</p>
<p>Because the <span class="math notranslate nohighlight">\(F\)</span> is the ratio of two <em>estimates</em> (<span class="math notranslate nohighlight">\(\hat{\sigma}^{2}_{\text{effect}}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}_{\text{error}}\)</span>), and because each estimate is a <em>random variable</em>, the <span class="math notranslate nohighlight">\(F\)</span>-ratio itself is a random variable with some distribution. Under the null hypothesis that there is no effect, <span class="math notranslate nohighlight">\(\sigma^{2}_{\text{effect}} = \sigma^{2}_{\text{error}}\)</span> and the <span class="math notranslate nohighlight">\(F\)</span>-ratio will be 1 on average, as indicated above. The null <span class="math notranslate nohighlight">\(F\)</span>-distribution, as derived from our original assumptions of normality, has a form where the expected value is 1. This makes the null <span class="math notranslate nohighlight">\(F\)</span>-distribution only <em>one-tailed</em>, as illustrated below for an example <span class="math notranslate nohighlight">\(F_{2,29}\)</span>.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/b221be4cc861567d0b6ff72093064965a3415cdb9ce397e13f77805eeb40098b.png"><img alt="_images/b221be4cc861567d0b6ff72093064965a3415cdb9ce397e13f77805eeb40098b.png" src="_images/b221be4cc861567d0b6ff72093064965a3415cdb9ce397e13f77805eeb40098b.png" style="width: 420px; height: 420px;" /></a>
</div>
</div>
<p>If we are following NHST convention, we can therefore compare the value of <span class="math notranslate nohighlight">\(F\)</span> we have calculated to the null distribution and produce an associated <span class="math notranslate nohighlight">\(p\)</span>-value. As with the <span class="math notranslate nohighlight">\(t\)</span>-statistic, the larger <span class="math notranslate nohighlight">\(F\)</span> becomes, the less probable it is if the null were true and thus the <em>smaller</em> the <span class="math notranslate nohighlight">\(p\)</span>-value becomes.</p>
</section>
<section id="summary-of-calculations">
<h4>Summary of Calculations<a class="headerlink" href="#summary-of-calculations" title="Link to this heading">#</a></h4>
<p>Because the steps needed to calculate <span class="math notranslate nohighlight">\(F\)</span> are quite involved, we have summarised all of them in the <code class="docutils literal notranslate"><span class="pre">R</span></code> code below. This will hopefully make it clear that we are really comparing two models to each other, it is just that we have to go about it in a slightly complicated way in order for the numbers to make sense. Also, do not worry, we will see how to automate all of this in <code class="docutils literal notranslate"><span class="pre">R</span></code> very shortly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Null model and full model</span>
<span class="n">null.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">      </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>
<span class="n">full.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">origin</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>

<span class="c1"># Residual sums-of-squares</span>
<span class="n">null.RSS</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">null.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">full.RSS</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>

<span class="c1"># Sums-of-squares</span>
<span class="n">SS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">null.RSS</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">full.RSS</span><span class="w"> </span><span class="c1"># between-groups (model improvement)</span>
<span class="n">SS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.RSS</span><span class="w">            </span><span class="c1"># within-groups (error)</span>

<span class="c1"># Mean-squares</span>
<span class="n">df.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span><span class="w">                    </span><span class="c1"># k - 1</span>
<span class="n">df.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.mod</span><span class="o">$</span><span class="n">df.residual</span><span class="w"> </span><span class="c1"># n - p</span>
<span class="n">MS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.1</span><span class="w">          </span><span class="c1"># reduction in error variance (effect)</span>
<span class="n">MS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.W</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.2</span><span class="w">          </span><span class="c1"># remaining error variance (error)</span>

<span class="c1"># F-ratio</span>
<span class="bp">F</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MS.B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">MS.W</span>

<span class="c1"># p-value from null F-distribution with df1 and df2</span>
<span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">pf</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="bp">F</span><span class="p">,</span><span class="w"> </span><span class="n">df1</span><span class="o">=</span><span class="n">df.1</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="o">=</span><span class="n">df.2</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>

<span class="c1"># Results</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="s">&quot;F.ratio&quot;</span><span class="o">=</span><span class="bp">F</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;p.value&quot;</span><span class="o">=</span><span class="n">p</span><span class="p">),</span><span class="w"> </span><span class="n">row.names</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  F.ratio     p.value
 7.800338 0.001946794
</pre></div>
</div>
</div>
</div>
<p>The value of <span class="math notranslate nohighlight">\(F\)</span> indicates that the reduction in error between the null and full model is nearly 8 times <em>larger</em> than we would expect, if this effect was just noise. In other words, this is nearly 8 times bigger than our expectation under the null hypothesis of no differences between the group means. The probability of achieving a value of <span class="math notranslate nohighlight">\(F_{2,29} = 7.80\)</span> if the null were true is <span class="math notranslate nohighlight">\(p = 0.002\)</span>, which is below the usual NHST threshold of <span class="math notranslate nohighlight">\(p = 0.05\)</span>, thus this would be declared “significant” within this framework. In terms of our omnibus hypothesis, this is taken to imply that <em>at least one</em> of the mean differences between the levels of <code class="docutils literal notranslate"><span class="pre">origin</span></code> is also significant.</p>
</section>
</section>
</section>
<section id="anova-tables-in-r">
<h2>ANOVA Tables in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#anova-tables-in-r" title="Link to this heading">#</a></h2>
<p>As should now be clear, the calculation of <span class="math notranslate nohighlight">\(F\)</span> as a metric for comparing two models is somewhat involved. As such, it would be a bit unreasonable if we were expected to perform all this arithmetic manually every time we wanted to compare two models. Luckily, <code class="docutils literal notranslate"><span class="pre">R</span></code> can do all of this very easily for us using the <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function. All we do is provide the function with two models (or more) and <code class="docutils literal notranslate"><span class="pre">R</span></code> will produce an ANOVA table of all the calculations, along with an <span class="math notranslate nohighlight">\(F\)</span>-statistic and <span class="math notranslate nohighlight">\(p\)</span>-value.</p>
<section id="the-anova-function">
<h3>The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> Function<a class="headerlink" href="#the-anova-function" title="Link to this heading">#</a></h3>
<p>The built-in <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function can be used in many different contexts to compare different models. For our current use case, providing two models fit using <code class="docutils literal notranslate"><span class="pre">lm()</span></code> will produce the expected ANOVA table. For example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">anova</span><span class="p">(</span><span class="n">null.mod</span><span class="p">,</span><span class="w"> </span><span class="n">full.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Analysis of Variance Table

Model 1: mpg ~ 1
Model 2: mpg ~ origin
  Res.Df     RSS Df Sum of Sq      F   Pr(&gt;F)   
1     31 1126.05                                
2     29  732.17  2    393.88 7.8003 0.001947 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
<p>Within this table, we should see all the values that we calculated manually above. The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function can also automate the model comparisons procedure if we simply provide the full model, producing something closer to a traditional ANOVA table.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">anova</span><span class="p">(</span><span class="n">full.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Analysis of Variance Table

Response: mpg
          Df Sum Sq Mean Sq F value   Pr(&gt;F)   
origin     2 393.88 196.938  7.8003 0.001947 **
Residuals 29 732.17  25.247                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
<p>As practice, to make sure you have understood the discussion so far, see if you can explain all the values in this table.</p>
</section>
<section id="id4">
<h3>The <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> Function<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p>Although the default <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function is useful for model comparisons, things start to get more complicated once we consider <em>unbalanced</em> higher-order ANOVA models. Unbalanced ANOVAs are those where there are different numbers of subjects in each group. We will discuss all this later, but for now it is enough to indicate that these types of application are special because the summative nature of the sums-of-squares breaks-down, making it harder to disentangle the different effects. Because of this, we just want to recommend the use of the <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">car</span></code> package as the most flexible method of producing an ANOVA table within <code class="docutils literal notranslate"><span class="pre">R</span></code>. As an example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">Anova</span><span class="p">(</span><span class="n">full.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Loading required package: carData
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Anova Table (Type II tests)

Response: mpg
          Sum Sq Df F value   Pr(&gt;F)   
origin    393.88  2  7.8003 0.001947 **
Residuals 732.17 29                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
<p>Here, there is no difference between <code class="docutils literal notranslate"><span class="pre">anova()</span></code> and <code class="docutils literal notranslate"><span class="pre">Anova()</span></code>. However, this will not always be true and so we would always recommend defaulting to <code class="docutils literal notranslate"><span class="pre">Anova()</span></code>. Notice that this table says <code class="docutils literal notranslate"><span class="pre">Type</span> <span class="pre">II</span> <span class="pre">tests</span></code> at the top. This is related to how the <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> function deals with unbalanced data, which <code class="docutils literal notranslate"><span class="pre">anova()</span></code> does not do. This is a complicated topic we will leave for another day. For the moment, just try and remember that whatever form of ANOVA table we produce, this is the result of comparing multiple models, with the <span class="math notranslate nohighlight">\(F\)</span>-statistic reflecting the degree of model improvement relative to the error.</p>
<aside class="topic">
<p class="topic-title">What do you now know?</p>
<p>In this section, we have explored the concept of omnibus ANOVA tests and model comparisons. After reading this section, you should have a good sense of:</p>
<ul class="simple">
<li><p>What an omnibus test is and why we might be interested in using them.</p></li>
<li><p>The concept of an omnibus test as a <em>comparison</em> between two competing models (known as the <em>null</em> and <em>full</em> models).</p></li>
<li><p>The idea that the omnibus test of a single factor in an ANOVA model is equivalent to comparing a model that contains the factor and the model that does not contain the factor.</p></li>
<li><p>The concept that comparing two models uses the <em>residual sum-of-squares</em> rather than the error variance, due to differences in the number of model parameters. This results in a value known as the <em>between-groups sums-of-squares</em> (<span class="math notranslate nohighlight">\(SS_{B}\)</span>).</p></li>
<li><p>The concept that the value of <span class="math notranslate nohighlight">\(SS_{B}\)</span> is only meaningful when <em>compared</em> to some measure of noise. This measure of noise is typically the residual sums-of-squares from the full model, which is known as the <em>within-groups sums-of-squares</em> (<span class="math notranslate nohighlight">\(SS_{W}\)</span>).</p></li>
<li><p>The idea that our final comparison forms a test statistic, known as <span class="math notranslate nohighlight">\(F\)</span>, from the ratio of the effect to the noise, similar to the structure of the <span class="math notranslate nohighlight">\(t\)</span>-statistic. However, both <span class="math notranslate nohighlight">\(SS_{B}\)</span> and <span class="math notranslate nohighlight">\(SS_{W}\)</span> must first be scaled to make them comparable.</p></li>
<li><p>The idea that we can perform all these calculations in <code class="docutils literal notranslate"><span class="pre">R</span></code> automatically, either through explicit model comparisons with the <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function, or by using the <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">car</span></code> package.</p></li>
<li><p>The concept that an overall ANOVA omnibus test is always provided at the bottom of the <code class="docutils literal notranslate"><span class="pre">summary()</span></code> table produced when using <code class="docutils literal notranslate"><span class="pre">lm()</span></code>.</p></li>
</ul>
</aside>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="intercept-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Remember, the intercept term is always <em>implicit</em> in <code class="docutils literal notranslate"><span class="pre">R</span></code>. However, if you like the symmetry, you can specify the full model as <code class="docutils literal notranslate"><span class="pre">mpg</span> <span class="pre">~</span> <span class="pre">1</span> <span class="pre">+</span> <span class="pre">origin</span></code>. Similarly, you can remove the intercept by adding <code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">1</span></code>, or you can use <code class="docutils literal notranslate"><span class="pre">0</span></code>. For instance, <code class="docutils literal notranslate"><span class="pre">mpg</span> <span class="pre">~</span> <span class="pre">origin</span> <span class="pre">-</span> <span class="pre">1</span></code> or <code class="docutils literal notranslate"><span class="pre">mpg</span> <span class="pre">~</span> <span class="pre">0</span> <span class="pre">+</span> <span class="pre">origin</span></code>.</p>
</aside>
<aside class="footnote brackets" id="pop-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Remember that Bessel’s correction is related to <em>estimating</em> parameters from a sample. When we have the full population, we would simply divide by <span class="math notranslate nohighlight">\(n\)</span> and could therefore compare the variances as the denominators would be the same.</p>
</aside>
<aside class="footnote brackets" id="overfit-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>You may wonder what the problem is with this. Surely we want the model to fit as well as possible? However, a <em>perfect</em> fit suggests <em>over-fitting</em>. Remember, our aim is to use our model to separate those effects that are universal to our population of interest from the noise. A model that fits one specific dataset does not do this. In fact, it will be fitting <em>both</em> the effects we are interested in <em>and</em> the noise. This may result in a perfect fit for that specific dataset, but it tells us nothing about our population of interest and certainly would not fit another sample very well.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="2.oneway-ANOVA.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">One-way ANOVA</p>
      </div>
    </a>
    <a class="right-next"
       href="4.higher-order-ANOVA-I.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Higher-order ANOVA I: The Additive Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-as-a-model-comparison-procedure">ANOVA as a Model Comparison Procedure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests">Omnibus Tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests-from-model-comparisons">Omnibus Tests From Model Comparisons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparisons-using-sums-of-squares">Model Comparisons Using Sums-of-Squares</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares-for-the-effect">Sum-of-Squares for the Effect</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum-of-squares-for-the-error">Sum-of-Squares for the Error</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-f-ratio">The <span class="math notranslate nohighlight">\(F\)</span>-ratio</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-between-group-mean-square">The Between-Group Mean Square</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-within-group-mean-square">The Within-Group Mean Square</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-definition-of-f">The Definition of <span class="math notranslate nohighlight">\(F\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-calculations">Summary of Calculations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-tables-in-r">ANOVA Tables in <code class="docutils literal notranslate"><span class="pre">R</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-anova-function">The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">The <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> Function</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar & Dr George Farmer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025-26.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>