
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Omnibus Tests and Model Comparisons &#8212; Linear Models IV: Model Comparisons and the ANOVA</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=90b7ad94" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '3.omnibus-tests-model-comps';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models IV: Model Comparisons and the ANOVA - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models IV: Model Comparisons and the ANOVA - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.dummy-variables.html">Dummy Variable Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.oneway-ANOVA-alt.html">One-way ANOVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.omnibus-tests-model-comps-alt.html">Omnibus Tests and Model Comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.higher-order-ANOVA-I.html">Higher-order ANOVA I: The Additive Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.higher-order-ANOVA-II.html">Higher-order ANOVA II: The Full Factorial Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.follow-up.html">Follow-up Tests and Visualisations</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Model-Comparisons-ANOVA" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Model-Comparisons-ANOVA/issues/new?title=Issue%20on%20page%20%2F3.omnibus-tests-model-comps.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/3.omnibus-tests-model-comps.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Omnibus Tests and Model Comparisons</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-as-a-model-comparison-procedure">ANOVA as a Model Comparison Procedure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests">Omnibus Tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests-from-model-comparisons">Omnibus Tests From Model Comparisons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparisons-using-sums-of-squares">Model Comparisons Using Sums-of-Squares</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-f-ratio">The <span class="math notranslate nohighlight">\(F\)</span>-ratio</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squares">Mean-squares</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-definition-of-f">The Definition of <span class="math notranslate nohighlight">\(F\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-calculations">Summary of Calculations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-tables-in-r">ANOVA Tables in <code class="docutils literal notranslate"><span class="pre">R</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-anova-function">The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">The <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-regression-anova-f-test">The Regression ANOVA <span class="math notranslate nohighlight">\(F\)</span>-test</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="omnibus-tests-and-model-comparisons">
<h1>Omnibus Tests and Model Comparisons<a class="headerlink" href="#omnibus-tests-and-model-comparisons" title="Link to this heading">#</a></h1>
<p>In the previous section, we saw how to use dummy variables with multiple categorical levels and then specify a subsequent regression model that fits group means and mean differeces. Although we called this a One-way ANOVA model, it probably does not look much like an ANOVA to you yet. In this section, we will complete the picture by discussing the nature of the ANOVA omnibus tests and showing how these are effectively <em>model comparisons</em>. The familiar ANOVA table is simply a way of displaying the results of several model comparisons. We will show how to generate this within <code class="docutils literal notranslate"><span class="pre">R</span></code> and also show how the values within this table relate to comparing different regression models.</p>
<section id="anova-as-a-model-comparison-procedure">
<h2>ANOVA as a Model Comparison Procedure<a class="headerlink" href="#anova-as-a-model-comparison-procedure" title="Link to this heading">#</a></h2>
<p>In order to understand the ANOVA within the framework of linear models, we need to demonstrate how the ANOVA results are simply the outcomes from comparing different linear models in a specific way. To begin, we need to consider the logic of an <em>omnibus test</em>.</p>
<section id="omnibus-tests">
<h3>Omnibus Tests<a class="headerlink" href="#omnibus-tests" title="Link to this heading">#</a></h3>
<p>An omnibus test is a test that contains <em>multiple</em> comparisons between means. In comparison to a procedure such as a <span class="math notranslate nohighlight">\(t\)</span>-test, which only compares <em>two</em> means, an omnibus test can compare <em>multiple</em> means. In our example of a One-way ANOVA where <span class="math notranslate nohighlight">\(k = 3\)</span>, the omnibus null hypothesis is</p>
<div class="math notranslate nohighlight">
\[
\mathcal{H}_{0} : \mu_{1} = \mu_{2} = \mu_{3}.
\]</div>
<p>In other words, the null is that <em>all</em> the means are identical. Or, to put it another way, that all the mean differences are 0. We can also put this in the context of the model in the previous part. If all the means were identical, they would the same as the grand mean and the deflections from the grand mean would therefore be 0. We can therefore express our omnibus null equivalently as:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{H}_{0} : \alpha_{1} = \alpha_{2} = \alpha_{3} = 0.
\]</div>
<p>No matter how it is written, an omnibus test of this null is able to simultaneously consider <em>all possible comparions</em>. Within the NHST framework, a significant omnibus effect suggests that <em>at least one</em> of all possible mean differences is significant. Traditionally, we would then drill-down to see which of the differences is driving the omnibus effect[^omnibus-foot].</p>
<div class="tip dropdown admonition">
<p class="admonition-title">What is the point of an omnibus test?</p>
<p>At this point, you may well ask: what is the point of an omnibus test? If we just end up drilling-down to work out which differences are significant, why not just start there? Why even both with the omnibus test?</p>
<p>The traditional argument is one of <em>error control</em> in relation to the problem of <em>multiple testing</em> or <em>multiple comparisons</em>. If our categorical variable has <span class="math notranslate nohighlight">\(k\)</span> levels, then there are <span class="math notranslate nohighlight">\(m = \frac{k(k-1)}{2}\)</span> comparisons we can make between the levels. If our desired error level is given by <span class="math notranslate nohighlight">\(\alpha\)</span>, then across all tests the probability of <em>at least one</em> being significant is <span class="math notranslate nohighlight">\(1 - (1 - \alpha)^{m}\)</span>. This is known as the <em>familywise error rate</em> (FWER). So, notice that whenever <span class="math notranslate nohighlight">\(m &gt; 1\)</span> our desired error-rate will be scaled by the number of tests and therefore get <em>bigger</em>.</p>
<p>As an example, if we take <span class="math notranslate nohighlight">\(k = 5\)</span>, <span class="math notranslate nohighlight">\(m = 10\)</span> and <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, the FWER is</p>
<div class="math notranslate nohighlight">
\[
\text{FWER} = 1 - (1 - \alpha)^{m} = 1 - 0.95^{10} = 0.40.
\]</div>
<p>This means there is now a 40% chance of a significant effect under the null, rather than a 5% chance. This is the <em>multiple testing</em> problem. The more levels our categorical predictor has, the worse this gets. This is where an omnibus test helps because, irrespective of the value of <span class="math notranslate nohighlight">\(k\)</span>, the FWER stays at the desired <span class="math notranslate nohighlight">\(\alpha\)</span> because it is only a <em>single test</em>. So, we can have a factor with many levels and can assess all the differerences simultaneously using a single test that does not inflate the FWER.</p>
<p>It is worth noting as well that multiple testing is really a problem of NHST and frequentist statistics. Because of these approaches, there is a sense that traditional statistical inference actively <em>punishes</em> researchers for wanting to investigate and explore their data. This is not universal of all statistical methods. For instance, Bayesian statistics allows as many comparisons as you want without disturbing the probabilistic structure of the conclusions. So just know that ominbus tests and the multiple comparisons problem are not <em>universal</em> in statistics, rather they are a consequence of one particular school of thought and one particular definition of probability.</p>
</div>
</section>
<section id="omnibus-tests-from-model-comparisons">
<h3>Omnibus Tests From Model Comparisons<a class="headerlink" href="#omnibus-tests-from-model-comparisons" title="Link to this heading">#</a></h3>
<p>So, how do we generate omnibus tests from model comparisons? To see how this works, consider that the omnibus null hypothesis above actually <em>implies</em> a specific model. If it were true that all the group means are identical, then the grouping variable is effectively meaningless. It has simply chopped the data up randomly into 3 groups. Assuming that the population means of the groups are all the <em>same</em> implies that all the data are drawn from the <em>same population distibution</em>. Thus, rather than assuming</p>
<div class="math notranslate nohighlight">
\[
y_{ij} \sim \mathcal{N}\left(\mu_{j},\sigma^{2}\right)
\]</div>
<p>we are assuming</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\mu,\sigma^{2}\right).
\]</div>
<p>Here we have <em>two different models</em>. One that just assumes a single mean for all the data and one that assumes <em>different</em> means for the different groups. In the context of a regression model, this is a comparison between a model that only contains an intercept, and a model containing an intercept <em>and</em> dummy variables for the categories. Typically, these are called the <em>null model</em> and the <em>full model</em>, so we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \mathcal{M}_{0} &amp;: y_{i\phantom{j}}  = \mu_{\phantom{j}}     + \epsilon_{i}  &amp;\quad \text{Null Model} \\
    \mathcal{M}_{1} &amp;: y_{ij} = \mu_{j} + \epsilon_{ij} &amp;\quad \text{Full Model} \\
\end{align*}
\end{split}\]</div>
<p>In <code class="docutils literal notranslate"><span class="pre">R</span></code>, sticking with our <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example, we could specify these in the following way</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">null.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">      </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span><span class="w"> </span><span class="c1"># null model</span>
<span class="n">full.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">origin</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span><span class="w"> </span><span class="c1"># full model</span>
</pre></div>
</div>
</div>
</div>
<p>Thus, the full model contains our categorical variable of interest and the null model does not. If our question revolves around whether this predictor is actually necessary, a natural way to do so would be to compare how well each model fits the data. If the null and full model have a similar model fit, then it suggests that <code class="docutils literal notranslate"><span class="pre">origin</span></code> is doing little more than an intercept. In other words, the groups means appear largely identical. Alternatively, if the full model fits much better than the null model then it suggests that allowing the group means to differ is a more accurate reflection of the data. In other words, at least two of the group means appear to be different.</p>
</section>
<section id="model-comparisons-using-sums-of-squares">
<h3>Model Comparisons Using Sums-of-Squares<a class="headerlink" href="#model-comparisons-using-sums-of-squares" title="Link to this heading">#</a></h3>
<p>In order to compare the model fits, the most intuitive method would be to calculate the the magnitude of the residual variance of each model and compare them. If a model fits better, its residual variance will be smaller. In other words, the average degree to which the data deviates from the model prediction will be reduced. Unfortunately, there is a numeric problem with this. What we really want to do is figure out how much the model has improved between the null and the full. In other words, what is the magnitude of variance associated with our effect of interest. Intutively, what we might think about doing is calculating</p>
<div class="math notranslate nohighlight">
\[
\Delta\sigma^{2} = \sigma^{2}_{\text{null}} - \sigma^{2}_{\text{full}}.
\]</div>
<p>At the level of the <em>population</em>, this would work. However, at the level of <em>sample estimates</em>, this is a messy quantity that does not cleanly isolate the improvement added by the full model. To see why, consider the expanded definition of the variances as calculated from a sample</p>
<div class="math notranslate nohighlight">
\[
\Delta\hat{\sigma}^{2} = \underbrace{\frac{\sum{\epsilon_{0}^{2}}}{n - p_{0}}}_{\hat{\sigma}^{2}_{\text{null}}} - \underbrace{\frac{\sum{\epsilon_{1}^{2}}}{n - p_{1}}}_{\hat{\sigma}^{2}_{\text{full}}},
\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon_{0}\)</span> and <span class="math notranslate nohighlight">\(\epsilon_{1}\)</span> are the residuals from the null and full models, and <span class="math notranslate nohighlight">\(p_{0}\)</span> and <span class="math notranslate nohighlight">\(p_{1}\)</span> are the number of parameters from the null and full models. Written this way, it is clear that we are subtracting quantities with different denominators. If we had the whole population at our disposal, each quantity would be divided by <span class="math notranslate nohighlight">\(n\)</span> and there would be no problem. However, because these are <em>estimates</em>, we lose a degree of freedom for each parameter we have to estimate. Because the full and null models have different numbers of parameters, this makes the final value very unclear in terms of what it is actually telling us about the differences between these models. This is precisely because, in a sample, the individual terms are scaled differently. As such, even if the model fits were <em>identical</em>, we may still see a difference here due to differences in the number of parameters.</p>
<p>The solution then is to <em>not</em> use the residual variances to compare the models, despite its intuitive appeal. Instead, we forego the denominators entirely to give</p>
<div class="math notranslate nohighlight">
\[
SS_{\text{effect}} = \sum{\epsilon_{0}^{2}} - \sum{\epsilon_{1}^{2}}.
\]</div>
<p>This value is more usually known as the <em>between-groups sum-of-squares</em> (<span class="math notranslate nohighlight">\(SS_{B}\)</span>) and is formed from the <em>residual sum-of-squares</em> (RSS) from each model. The logic is that we cannot isolate the magnitude of the model improvement by using the sample error variances because</p>
<div class="math notranslate nohighlight">
\[
\hat{\sigma}^{2}_{\text{effect}} \neq \hat{\sigma}^{2}_{\text{null}} - \hat{\sigma}^{2}_{\text{full}}.
\]</div>
<p>But we <em>can</em> using the sums-of-squares because</p>
<div class="math notranslate nohighlight">
\[
SS_{\text{effect}} = RSS_{\text{null}} - RSS_{\text{full}}.
\]</div>
<p>This is a direct consequence of removing the messiness of the denominators from the calculation.</p>
<p>Let us see this in practice for our two example models. In the code below, we can calculate the residual sums-of-squares as a measure of each model fit. The <em>larger</em> the value, the more error remains and the <em>worse</em> the model fits the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">null.RSS</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">null.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">full.RSS</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">null.RSS</span><span class="p">,</span><span class="n">full.RSS</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 1126.0472  732.1721
</pre></div>
</div>
</div>
</div>
<p>So, we can see already that the null model has a larger RSS and thus is a worse fit to the data. The difference between these values therefore tells us how much the error <em>reduces</em> after including <code class="docutils literal notranslate"><span class="pre">origin</span></code> in the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">SS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">null.RSS</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">full.RSS</span>

<span class="nf">print</span><span class="p">(</span><span class="n">SS.B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 393.8751
</pre></div>
</div>
</div>
</div>
<p>How do we interpret this value? Generally, we cannot because the units are not any sort of standardised scale. However, what we can do is compare this value <em>relative</em> to some other measure on the same scale. What measure to use? Well, at present, the <span class="math notranslate nohighlight">\(SS_{B}\)</span> gives us a sense of how much we have reduced the error of the null model by including a specific predictor. What we want to know is whether this is <em>large</em> or <em>small</em>? More generally, we want to know whether any improvement we have seen is likely to be random noise (in which case the predictor has done <em>nothing</em> to help the model) or whether it implies something more systematic about the data (i.e. that the population means differ across the groups).</p>
<p>So, we need some measure of noise to compare <span class="math notranslate nohighlight">\(SS_{B}\)</span> to. In general, we have two options: <span class="math notranslate nohighlight">\(RSS_{\text{null}}\)</span> or <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span>. These are both sums-of-sqaures that reflect the <em>error</em> or <em>noise</em>, as they capture the degree of variability that is left-over within each model. If it were the case that the predictor was <em>not</em> related to the data then these quantities would be similar. However, if the predictor <em>was</em> related to the data then the null model would be missing a key component and its error would be larger than it should be. This would make <span class="math notranslate nohighlight">\(RSS_{\text{null}}\)</span> a poor comparison. Because of this, <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> becomes the much better choice. If the predictor <em>does</em> relate to the data then <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> will be the correct magnitude, but if the predictor <em>does not</em> relate to the data then <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> will be similar to <span class="math notranslate nohighlight">\(RSS_{\text{null}}\)</span>. So either way, <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> becomes the better measure of <em>error</em> or <em>noise</em>.</p>
<p>Within the context of an ANOVA model, <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> is more usually known as the <em>within-group sum-of-squares</em>, or <span class="math notranslate nohighlight">\(SS_{W}\)</span> for short, because it effectively measures variability in terms of individual subjects around the group means. In other words, how well do the group means fit the data? Within our example in <code class="docutils literal notranslate"><span class="pre">R</span></code>, we already calculated <span class="math notranslate nohighlight">\(RSS_{\text{full}}\)</span> and so can simply copy it to a new variable with a different name.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">SS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.RSS</span>
<span class="nf">print</span><span class="p">(</span><span class="n">SS.W</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 732.1721
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-f-ratio">
<h3>The <span class="math notranslate nohighlight">\(F\)</span>-ratio<a class="headerlink" href="#the-f-ratio" title="Link to this heading">#</a></h3>
<p>Given what we have discussed above, we could just eye-ball the magnitude of <span class="math notranslate nohighlight">\(SS_{B}\)</span> relative to <span class="math notranslate nohighlight">\(SS_{W}\)</span>. However, a more principled approach is to combine these values into some sort of <em>test statistic</em>, akin to the <span class="math notranslate nohighlight">\(t\)</span>-statistic we have discussed previously. In doing so, we can combine the two sources of information into a single standardised value that can be interpreted across different datasets. Much in the same way that a <span class="math notranslate nohighlight">\(t\)</span>-statistic is formed by dividing an <em>effect</em> by <em>error</em>, we could similarly form a statistic by calculating <span class="math notranslate nohighlight">\(\frac{SS_{B}}{SS_{W}}\)</span>. This would tell us how large the improvement in model fit is, relative to the amount of error left over.</p>
<p>The statistic we use for this purpose is known as <span class="math notranslate nohighlight">\(F\)</span> (named after <em>Fisher</em>). Given the description above, it may seem like we could calculate <span class="math notranslate nohighlight">\(F = \frac{SS_{B}}{SS_{W}}\)</span>. However, there is some additional complexity. Although both <span class="math notranslate nohighlight">\(SS_{B}\)</span> and <span class="math notranslate nohighlight">\(SS_{W}\)</span> appear to be compatible, because they are both sums-of-squares, they cannot be directly compared. This is because they are both <em>sums</em>, and so their magnitude is dependant upon whatever we are summing over. If they were both summed over the same element of the model, there would be no problem. But this is not the case. As we will see below, the magnitude of <span class="math notranslate nohighlight">\(SS_{B}\)</span> depends upon the number of model parameters, yet the magnitude of <span class="math notranslate nohighlight">\(SS_{W}\)</span> depends upon the sample size. So both terms need to be <em>scaled</em> first, to make them truly comparable. These scaled values are known as <em>mean squares</em>.</p>
<section id="mean-squares">
<h4>Mean-squares<a class="headerlink" href="#mean-squares" title="Link to this heading">#</a></h4>
<p>Starting with <span class="math notranslate nohighlight">\(SS_{B}\)</span>, this value can be interpreted as the improvement in model fit after adding a certain number of parameters to the model. Unfortunately, this value will always scale with the number of parameters we add. This is because the more parameters we add, the better the fit can become. The most extreme example of this is having one parameter for every observation. In this case, we could make the model fit <em>perfectly</em> with no error. Thus, we can always make the model better and better by adding more and more parameters<a class="footnote-reference brackets" href="#overfit-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. The problem is that we do not know whether <span class="math notranslate nohighlight">\(SS_{B}\)</span> is large because of a genuine improvement to the model fit, or simply because we have added more parameters.</p>
<p>To make this value more meaningful, we can therefore divide it by the number of parameters we have added to give an <em>average improvement per-parameter</em>. This has the advantage of turning the sums-of-squares back into a measure of variance, but one that is now correctly calculated to give <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}_{\text{effect}}\)</span>. The number of additional parameters is known as the <em>numerator degrees of freedom</em> (or <span class="math notranslate nohighlight">\(df_{1}\)</span>) and the scaled version of <span class="math notranslate nohighlight">\(SS_{B}\)</span> is known as the <em>between-group mean square</em>, or <span class="math notranslate nohighlight">\(MS_{B}\)</span> for short. As such</p>
<div class="math notranslate nohighlight">
\[
MS_{B} = \frac{SS_{B}}{df_{1}} = \frac{SS_{B}}{k - 1} = \hat{\sigma}^{2}_{\text{effect}}.
\]</div>
<p>In the case of the <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example, we need to add <span class="math notranslate nohighlight">\(k - 1 = 2\)</span> parameters to the model to capture the different group means. As such, we divide <span class="math notranslate nohighlight">\(SS_{B}\)</span> by <span class="math notranslate nohighlight">\(df_{1} = 2\)</span> to produce the <span class="math notranslate nohighlight">\(MS_{B}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">df.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span>
<span class="n">MS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.1</span>
<span class="nf">print</span><span class="p">(</span><span class="n">MS.B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 196.9376
</pre></div>
</div>
</div>
</div>
<p>So, we have an improvement in model fit in terms of reducing the error variance by an average of 196.94 for each parameter we have added.</p>
<p>Moving on to <span class="math notranslate nohighlight">\(SS_{W}\)</span>, we have a similar problem because this value always scales with <em>sample size</em>. Remember, this is simply the residual sum-of-sqaures for the full model. As such, the more residuals we have, the larger the sum will be. As noted above for <span class="math notranslate nohighlight">\(SS_{B}\)</span>, we therefore do not know whether <span class="math notranslate nohighlight">\(SS_{W}\)</span> is large because the model fit is poor, or because we have a large <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>Using a similar logic to above, it would seem that we could just divide <span class="math notranslate nohighlight">\(SS_{W}\)</span> by <span class="math notranslate nohighlight">\(n\)</span>. However, there is a catch. Remember that dividing a sums-of-squares by some value gives us a <em>mean-square</em>, but that mean-squares are effectively <em>variances</em>. So what variance do we get from the residual sum-of-squares? As covered in previous weeks, this is simply the estimated <em>error variance</em> of the model, <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}\)</span>. However, we also know from previous weeks that dividing by <span class="math notranslate nohighlight">\(n\)</span> leads to a <em>biased</em> estimate of the population variance and that, as a generalisation of Bessel’s correction, we must divide by <span class="math notranslate nohighlight">\(n-p\)</span>. As such, rather than dividing <span class="math notranslate nohighlight">\(SS_{W}\)</span> by <span class="math notranslate nohighlight">\(n\)</span>, we divide by <span class="math notranslate nohighlight">\(n-p\)</span>, which gives the <em>denominator</em> degrees of freedom <span class="math notranslate nohighlight">\(df_{2} = n - p\)</span>. This gives the <em>within-groups mean-square</em>, or <span class="math notranslate nohighlight">\(MS_{W}\)</span> for short</p>
<div class="math notranslate nohighlight">
\[
MS_{W} = \frac{SS_{W}}{df_{2}} = \frac{SS_{W}}{n-p} = \hat{\sigma}^{2}_{\text{error}}.
\]</div>
<p>We can see this in our <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">df.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.mod</span><span class="o">$</span><span class="n">df.residual</span><span class="w"> </span><span class="c1"># this is always n - p</span>
<span class="n">MS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.W</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.2</span>
<span class="nf">print</span><span class="p">(</span><span class="n">MS.W</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 25.24731
</pre></div>
</div>
</div>
</div>
<p>Which, as already indicated, is <em>identical</em> to the error variance from the full model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">summary</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span><span class="o">$</span><span class="n">sigma</span>
<span class="nf">print</span><span class="p">(</span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 25.24731
</pre></div>
</div>
</div>
</div>
<p>This gives us the left-over variance after fitting the full model. So together, we have a reduction in residual variance of 196.94 after adding <code class="docutils literal notranslate"><span class="pre">origin</span></code> to the model, with only a residual variance of 25.25 left over. If our reduction in variance were of a similar magnitude to the amount left over, we could not say with any certainty that it was a true effect because the “effect” and the “error” look basically the same. However, in this case, the reduction in error variance is <em>much larger</em> than the amount left over, which is already suggestive of some true effect and thus that including <code class="docutils literal notranslate"><span class="pre">origin</span></code> in the model allows for a much better model fit. Because the <code class="docutils literal notranslate"><span class="pre">origin</span></code> factor allows for the group means to differ, this implies that <em>at least</em> one pair of group means are different from each other. This connects this result directly to our original omnibus hypothesis.</p>
<div class="tip admonition">
<p class="admonition-title">What’s in a name?</p>
<p>As we can see, some of the confusion around ANOVAs and ANOVA calculations simply comes down to using <em>different names</em> for familiar quantities. The name ANOVA tells us that the method involves comparing variances, yet those variances are called <em>mean-squares</em>. Usually, we would not give a name to the intermediate quantities produced during the calculation of variances, but the ANOVA names them as <em>sums-of-squares</em>. These quantities take on more importance within an ANOVA, because the sums-of-squares are the only meaningful way to compare two model fits, before they can be scaled back into variances. However, this creates a confusing collection of sums-of-squares, mean squares and degrees of freedom.</p>
<p><em>Remember</em>, all we are doing is comparing two models using their residuals. That is it. Try not to get too lost in the specifics of <em>how</em> this is done and keep focus on the very simple aim of the ANOVA. Remember as well that the ANOVA table was introduced by Fisher as a convenient way of organising all the arithmetic. The table was designed to make the calculations less confusing, but the table is <em>not</em> the ANOVA itself. There is nothing in an ANOVA table that implies any form of model comparison, but this is exactly what it is showing. As we will see below, in <code class="docutils literal notranslate"><span class="pre">R</span></code> such a table can be produce by <em>directly</em> comparing two models, making this perspective event clearer.</p>
</div>
</section>
<section id="the-definition-of-f">
<h4>The Definition of <span class="math notranslate nohighlight">\(F\)</span><a class="headerlink" href="#the-definition-of-f" title="Link to this heading">#</a></h4>
<p>So, given everything we have discussed above, we have taken a rather long and winding road to the definition of the <span class="math notranslate nohighlight">\(F\)</span>-statistic, which is:</p>
<div class="math notranslate nohighlight">
\[
F = \frac{SS_{B} / df_{1}}{SS_{W} / df_{2}} = \frac{MS_{B}}{MS_{W}} = \frac{\hat{\sigma}^{2}_{\text{effect}}}{\hat{\sigma}^{2}_{\text{error}}}.
\]</div>
<p>At its most basic, the <span class="math notranslate nohighlight">\(F\)</span>-ratio is compaing two measures of variance. Hence the name, Analysis of <em>Variance</em>. If we want to make this even simpler, we can say</p>
<div class="math notranslate nohighlight">
\[
F = \frac{\text{Improvement in error between the null and full models}}{\text{Error remaining}}.
\]</div>
<p>Or, to put this a difference way, how much variance have we managed to explain for each parameter we have added compared to how much we still have left to explain?</p>
<p>Given that <span class="math notranslate nohighlight">\(F\)</span> is a <em>ratio</em>, we can think of its value in fairly simple terms. If <span class="math notranslate nohighlight">\(F = 1\)</span> then the magnitude of the improvement is the same as the magnitude of the error. This is what we would expect if the null hypothesis were true, because any improvement is indistinguishable from normal sampling error. However, if <span class="math notranslate nohighlight">\(F &gt; 1\)</span>, it means that the improvement is much larger than the error. The bigger this value becomes, the more the improvement dwarfs the error and the harder it becomes to believe that all we have captured is noise.</p>
<p>Because the <span class="math notranslate nohighlight">\(F\)</span> is the ratio of two <em>estimates</em> (<span class="math notranslate nohighlight">\(\hat{\sigma}^{2}_{\text{effect}}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}^{2}_{\text{error}}\)</span>), and because each estimate is a <em>random variable</em>, the <span class="math notranslate nohighlight">\(F\)</span>-ratio itself is a random variable with some distribution. Under the null hypothesis that there is no effect, <span class="math notranslate nohighlight">\(\sigma^{2}_{\text{effect}} = \sigma^{2}_{\text{error}}\)</span> and the <span class="math notranslate nohighlight">\(F\)</span>-ratio will be 1 on average, as indicated above. The null <span class="math notranslate nohighlight">\(F\)</span>-distribution therefore has a form where the expected value is 1. This makes the null <span class="math notranslate nohighlight">\(F\)</span>-distribution only <em>one-tailed</em>, as illustrated below for an example <span class="math notranslate nohighlight">\(F_{2,29}\)</span>.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/b221be4cc861567d0b6ff72093064965a3415cdb9ce397e13f77805eeb40098b.png"><img alt="_images/b221be4cc861567d0b6ff72093064965a3415cdb9ce397e13f77805eeb40098b.png" src="_images/b221be4cc861567d0b6ff72093064965a3415cdb9ce397e13f77805eeb40098b.png" style="width: 420px; height: 420px;" /></a>
</div>
</div>
<p>If we are following NHST convention, we can therefore compare the value of <span class="math notranslate nohighlight">\(F\)</span> we have calculated to the null distribution and produce an associated <span class="math notranslate nohighlight">\(p\)</span>-value. As with the <span class="math notranslate nohighlight">\(t\)</span>-statistic, the larger <span class="math notranslate nohighlight">\(F\)</span> becomes, the less probable it is if the null were true and thus the <em>smaller</em> the <span class="math notranslate nohighlight">\(p\)</span>-value becomes.</p>
</section>
<section id="summary-of-calculations">
<h4>Summary of Calculations<a class="headerlink" href="#summary-of-calculations" title="Link to this heading">#</a></h4>
<p>Because the steps needed to calculate <span class="math notranslate nohighlight">\(F\)</span> are quite involved, we have summarised all of them in the <code class="docutils literal notranslate"><span class="pre">R</span></code> code below. This will hopefully make it clear that we are really comparing two models to each other, it is just that we have to go about it in a slightly complicated way in order for the numbers to make sense. Also, do not worry, we will see how to automate all of this in <code class="docutils literal notranslate"><span class="pre">R</span></code> very shortly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Null model and full model</span>
<span class="n">null.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w">      </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>
<span class="n">full.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">origin</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>

<span class="c1"># Residual sums-of-squares</span>
<span class="n">null.RSS</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">null.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">full.RSS</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="nf">resid</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>

<span class="c1"># Sums-of-squares</span>
<span class="n">SS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">null.RSS</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">full.RSS</span><span class="w"> </span><span class="c1"># between-groups (model improvement)</span>
<span class="n">SS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.RSS</span><span class="w">            </span><span class="c1"># within-groups (error)</span>

<span class="c1"># Mean-squares</span>
<span class="n">df.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2</span>
<span class="n">df.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">full.mod</span><span class="o">$</span><span class="n">df.residual</span><span class="w"> </span><span class="c1"># (n-p)</span>
<span class="n">MS.B</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.1</span><span class="w">          </span><span class="c1"># reduction in error variance (effect)</span>
<span class="n">MS.W</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">SS.W</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">df.2</span><span class="w">          </span><span class="c1"># remnaining error variance (error)</span>

<span class="c1"># F-ratio</span>
<span class="bp">F</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MS.B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">MS.W</span>

<span class="c1"># p-value from null F-distribution with df1 and df2</span>
<span class="n">p</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">pf</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="bp">F</span><span class="p">,</span><span class="w"> </span><span class="n">df1</span><span class="o">=</span><span class="n">df.1</span><span class="p">,</span><span class="w"> </span><span class="n">df2</span><span class="o">=</span><span class="n">df.2</span><span class="p">,</span><span class="w"> </span><span class="n">lower.tail</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>

<span class="c1"># Results</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="s">&quot;F.ratio&quot;</span><span class="o">=</span><span class="bp">F</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;p.value&quot;</span><span class="o">=</span><span class="n">p</span><span class="p">),</span><span class="w"> </span><span class="n">row.names</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  F.ratio     p.value
 7.800338 0.001946794
</pre></div>
</div>
</div>
</div>
<p>The value of <span class="math notranslate nohighlight">\(F\)</span> indicates that the reduction in error between the null and full model is nearly 8 times <em>larger</em> than we would expect, if this effect was just noise. In other words, this is nearly 8 times bigger than our expectation under the null hypothesis of no differences between the group means. The probability of achieving a value of <span class="math notranslate nohighlight">\(F_{2,29} = 7.80\)</span> if the null were true is <span class="math notranslate nohighlight">\(p = 0.002\)</span>, which is below the usual NHST threshold of <span class="math notranslate nohighlight">\(p = 0.05\)</span>, thus this would be declared “significant” within this framework. In terms of our omnibus hypothesis, this is taken to imply that <em>at least one</em> of the mean differences between the levels of <code class="docutils literal notranslate"><span class="pre">origin</span></code> is also significant.</p>
</section>
</section>
</section>
<section id="anova-tables-in-r">
<h2>ANOVA Tables in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#anova-tables-in-r" title="Link to this heading">#</a></h2>
<p>As should now be clear, the calculation of <span class="math notranslate nohighlight">\(F\)</span> as a metric for comparing two models is somewhat involved. As such, it would be a bit unreasonable if we were expected to perform all this arithmetic manually every time we wanted to compare two models. Luckily, <code class="docutils literal notranslate"><span class="pre">R</span></code> can do all of this very easily for us using the <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function. All we do is provide the function with two models (or more) and <code class="docutils literal notranslate"><span class="pre">R</span></code> will produce an ANOVA table of all the calculations, along with an <span class="math notranslate nohighlight">\(F\)</span>-statistic and <span class="math notranslate nohighlight">\(p\)</span>-value.</p>
<section id="the-anova-function">
<h3>The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> Function<a class="headerlink" href="#the-anova-function" title="Link to this heading">#</a></h3>
<p>The built-in <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function can be used in many different contexts to compare different models. For our current use case, providing two models fit using <code class="docutils literal notranslate"><span class="pre">lm()</span></code> will produce the expected ANOVA table. For example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">anova</span><span class="p">(</span><span class="n">null.mod</span><span class="p">,</span><span class="w"> </span><span class="n">full.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Analysis of Variance Table

Model 1: mpg ~ 1
Model 2: mpg ~ origin
  Res.Df     RSS Df Sum of Sq      F   Pr(&gt;F)   
1     31 1126.05                                
2     29  732.17  2    393.88 7.8003 0.001947 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
<p>Within this table, we should see all the values that we calculated manually above, alongside the <span class="math notranslate nohighlight">\(p\)</span>-value for the <span class="math notranslate nohighlight">\(F\)</span>-ratio. Given the discussions above, you should be able to explain what <em>all</em> the numbers in this table mean. If you cannot, we would suggest going back and re-reading the section above. The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function can also automate the model comparisons procedure if we simply provide the full model, producing something closer to a traditional ANOVA table.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">anova</span><span class="p">(</span><span class="n">full.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Analysis of Variance Table

Response: mpg
          Df Sum Sq Mean Sq F value   Pr(&gt;F)   
origin     2 393.88 196.938  7.8003 0.001947 **
Residuals 29 732.17  25.247                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>The <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> Function<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Although the default <code class="docutils literal notranslate"><span class="pre">anova()</span></code> function is useful for model comparisons, things start to get more complicated once we consider <em>unbalanced</em> ANOVA models that contain interactions. We will discuss all this later, but for now we just want to recommend the use of the <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> function from the <code class="docutils literal notranslate"><span class="pre">car</span></code> package as the most flexible method of producing an ANOVA table that can accommodate unbalanced models in different ways. For example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">Anova</span><span class="p">(</span><span class="n">full.mod</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Anova Table (Type II tests)

Response: mpg
          Sum Sq Df F value   Pr(&gt;F)   
origin    393.88  2  7.8003 0.001947 **
Residuals 732.17 29                    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
<p>For this example, there is no difference between <code class="docutils literal notranslate"><span class="pre">anove()</span></code> and <code class="docutils literal notranslate"><span class="pre">Anova()</span></code>. However, this will not always be true and so we would always recommend defaulting to <code class="docutils literal notranslate"><span class="pre">Anova()</span></code>. Notice that this table says <code class="docutils literal notranslate"><span class="pre">Type</span> <span class="pre">II</span> <span class="pre">tests</span></code> at the top. This is related to how the <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> function deals with unablanced data, which <code class="docutils literal notranslate"><span class="pre">anova()</span></code> does not do. This is a complicated topic we will leave for another day. For the moment, just try and remember that whatever form of ANOVA table we produce, this is the result of comparing multiple models, with the <span class="math notranslate nohighlight">\(F\)</span>-statistic reflecting the degree of model improvement relative to the error.</p>
</section>
</section>
<section id="the-regression-anova-f-test">
<h2>The Regression ANOVA <span class="math notranslate nohighlight">\(F\)</span>-test<a class="headerlink" href="#the-regression-anova-f-test" title="Link to this heading">#</a></h2>
<p>As a final point, it is interesting to note that we did not actually need to do any of the calculations above, because the results were provided all along at the bottom of the summary table for the full model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="n">full.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = mpg ~ origin, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.8071 -4.1718 -0.7885  3.3444 10.5929 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   21.807      1.343  16.239 4.26e-16 ***
originJapan    3.753      2.618   1.434  0.16238    
originUSA     -5.669      1.935  -2.929  0.00656 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 5.025 on 29 degrees of freedom
Multiple R-squared:  0.3498,	Adjusted R-squared:  0.3049 
F-statistic:   7.8 on 2 and 29 DF,  p-value: 0.001947
</pre></div>
</div>
</div>
</div>
<p>Notice that the very last line says:</p>
<p><code class="docutils literal notranslate"><span class="pre">F-statistic:</span> <span class="pre">7.8</span> <span class="pre">on</span> <span class="pre">2</span> <span class="pre">and</span> <span class="pre">29</span> <span class="pre">DF,</span>&#160; <span class="pre">p-value:</span> <span class="pre">0.001947</span></code></p>
<p>which is exactly the results from the ANOVA table. In general, it is customary to always provide an omnibus test of the <em>whole</em> regression model, by comparing the full model to a model containing an intercept. Because this model only contains a single term, this is then equivalent to the one-way ANOVA. In general, if there are multiple terms, this will not be the same. However, the omnibus regression test is useful as a single way of asking the question “is our model actually doing anything?”</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="overfit-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>You may wonder what the problem is with this. Surely we want the model to fit as well as possible? However, a <em>perfect</em> fit suggests <em>over-fitting</em>. Remember, our aim is to use our model to separate those effects that are universal to our population of interest from the noise. A model that fits one specific dataset does not do this. In fact, it will be fitting <em>both</em> the effects we are interested in <em>and</em> the noise. This may result in a perfect fit for that specific dataset, but it tells us nothing about our population of interest and certainly would not fit another sample very well.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-as-a-model-comparison-procedure">ANOVA as a Model Comparison Procedure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests">Omnibus Tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests-from-model-comparisons">Omnibus Tests From Model Comparisons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparisons-using-sums-of-squares">Model Comparisons Using Sums-of-Squares</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-f-ratio">The <span class="math notranslate nohighlight">\(F\)</span>-ratio</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-squares">Mean-squares</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-definition-of-f">The Definition of <span class="math notranslate nohighlight">\(F\)</span></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-calculations">Summary of Calculations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-tables-in-r">ANOVA Tables in <code class="docutils literal notranslate"><span class="pre">R</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-anova-function">The <code class="docutils literal notranslate"><span class="pre">anova()</span></code> Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">The <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-regression-anova-f-test">The Regression ANOVA <span class="math notranslate nohighlight">\(F\)</span>-test</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar & Dr George Farmer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025-26.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>