
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>One-way ANOVA &#8212; Linear Models IV: Model Comparisons and the ANOVA</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=90b7ad94" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.oneway-ANOVA';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Omnibus Tests and Model Comparisons" href="3.omnibus-tests-model-comps.html" />
    <link rel="prev" title="Dummy Variable Regression" href="1.dummy-variables.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models IV: Model Comparisons and the ANOVA - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models IV: Model Comparisons and the ANOVA - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.dummy-variables.html">Dummy Variable Regression</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">One-way ANOVA</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.omnibus-tests-model-comps.html">Omnibus Tests and Model Comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.higher-order-ANOVA-I.html">Higher-order ANOVA I: The Additive Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.higher-order-ANOVA-II.html">Higher-order ANOVA II: The Full Factorial Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Model-Comparisons-ANOVA" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Model-Comparisons-ANOVA/issues/new?title=Issue%20on%20page%20%2F2.oneway-ANOVA.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.oneway-ANOVA.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>One-way ANOVA</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-way-anova-as-a-linear-model">One-way ANOVA as a Linear Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#numeric-example">Numeric Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connecting-dummy-variable-regression-to-the-anova-model">Connecting Dummy Variable Regression to the ANOVA Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-parameterisation-and-constraints">Model Parameterisation and Constraints</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-dummy-variable-anova-model">The Dummy Variable ANOVA Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dummy-variables-coding-2-levels">Dummy Variables Coding &gt; 2 Levels</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-in-r">Example in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="one-way-anova">
<h1>One-way ANOVA<a class="headerlink" href="#one-way-anova" title="Link to this heading">#</a></h1>
<p>In the previous section, we saw how dummy variables can be incorporated into a regression model to represent a categorical predictor. We also saw how this can produce <em>identical</em> results to a traditional <span class="math notranslate nohighlight">\(t\)</span>-test. Now it is time to take this further and see how dummy variable regression can also be equivalent to a traditional Analysis of Variance (ANOVA). The starting point for this is the basic <em>One-way ANOVA</em>, where we have a <em>single</em> categorical predictor with <span class="math notranslate nohighlight">\(&gt; 2\)</span> levels. As we will see, this is simply a generalisation of the <span class="math notranslate nohighlight">\(t\)</span>-test we have already seen.</p>
<p>Before we begin, it is important to set expectations and address a common misunderstanding. When you think of an ANOVA, you may automatically think of an ANOVA <em>table</em>, like the one shown below</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Source</p></th>
<th class="head"><p>df</p></th>
<th class="head"><p>SS</p></th>
<th class="head"><p>MS</p></th>
<th class="head"><p>F</p></th>
<th class="head"><p>p-value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Between Groups</p></td>
<td><p>2</p></td>
<td><p>24.67</p></td>
<td><p>12.33</p></td>
<td><p>5.21</p></td>
<td><p>0.012</p></td>
</tr>
<tr class="row-odd"><td><p>Within Groups</p></td>
<td><p>27</p></td>
<td><p>63.83</p></td>
<td><p>2.36</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Total</p></td>
<td><p>29</p></td>
<td><p>88.50</p></td>
<td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
<p>However, this is <em>not</em> the ANOVA. In reality, an ANOVA is a very basic <em>linear model</em> concerned with <em>group means</em>. The ANOVA table is simply a convenient way to organise the arithmetic of hypothesis tests. The term <em>Analysis of Variance</em> comes from the way that these hypothesis tests are determined, but the estimates that these hypotheses are actually about come from a <em>model</em>. Traditional statistical education in Psychology tends to skip the actual model and go straight to the hypothesis tests. But this is not what we are going to do. Instead, we will ignore the ANOVA table for the moment and start by focusing on the <em>true form</em> of the ANOVA as a <em>basic linear model of group means</em>.</p>
<section id="one-way-anova-as-a-linear-model">
<h2>One-way ANOVA as a Linear Model<a class="headerlink" href="#one-way-anova-as-a-linear-model" title="Link to this heading">#</a></h2>
<p>The linear model at the heart of the one-way ANOVA is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    y_{ij} &amp;= \mu + \alpha_{j} + \epsilon_{ij} \\
    \epsilon_{ij} &amp;\sim \mathcal{N}\left(0,\sigma^{2}\right).
\end{align*}
\end{split}\]</div>
<p>Or, equivalently</p>
<div class="math notranslate nohighlight">
\[
y_{ij} \sim \mathcal{N}\left(\mu + \alpha_{j},\sigma^{2}\right).
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\mu\)</span> represents the <em>grand mean</em> (the overall mean of all the data) and <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> represents the <em>deviation</em> from the grand mean to the mean of group <span class="math notranslate nohighlight">\(j\)</span>. If our categorical predictor has <span class="math notranslate nohighlight">\(k\)</span> levels (<span class="math notranslate nohighlight">\(j = 1,2,..,k\)</span>), then the <span class="math notranslate nohighlight">\(i\text{th}\)</span> observation from the first level would be denoted <span class="math notranslate nohighlight">\(y_{i1}\)</span>, the <span class="math notranslate nohighlight">\(i\text{th}\)</span> observation from the second level would be denoted <span class="math notranslate nohighlight">\(y_{i2}\)</span> and so on. The model given above has <span class="math notranslate nohighlight">\(k\)</span> unique model predictions, because <span class="math notranslate nohighlight">\(\alpha\)</span> has <span class="math notranslate nohighlight">\(k\)</span> different values, one for each level of the categorical predictor. For example, if <span class="math notranslate nohighlight">\(j = 1,2,3\)</span> then <span class="math notranslate nohighlight">\(k=3\)</span> and we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    E\left(y_{i1}\right) &amp;= \mu + \alpha_{1} = \mu_{1} \\
    E\left(y_{i2}\right) &amp;= \mu + \alpha_{2} = \mu_{2} \\
    E\left(y_{i3}\right) &amp;= \mu + \alpha_{3} = \mu_{3}
\end{align*}
\end{split}\]</div>
<p>When written this way, the term <span class="math notranslate nohighlight">\(\alpha\)</span> captures the <em>effect</em> of the categorical predictor. This is encoded as deviations from the grand mean. When the group means are very similar, they will all be close to the grand mean and these deviations will be <em>small</em>. However, if the group means are quite different from each other, they will be much further away from the grand mean and the deviations will be <em>larger</em>. So, the magnitude of the <span class="math notranslate nohighlight">\(\alpha_{j}\)</span>’s tells us precisely how different the group means are from each other. Indeed, if there were <em>no</em> differences between the means then the group means would be the same as the grand mean and <span class="math notranslate nohighlight">\(\alpha_{1} = \alpha_{2} = \dots = \alpha_{k} = 0\)</span>.</p>
<p>The most important element of this model is that the grand mean plus the effect of the predictor will always equal the group mean. Much like we saw for regression models, we can think of the model equation as a set of <em>instructions</em>. For every observation, our starting point is the grand mean <span class="math notranslate nohighlight">\(\mu\)</span>. The <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> then tells us how far we have to travel to reach the mean of group <span class="math notranslate nohighlight">\(j\)</span>. So <span class="math notranslate nohighlight">\(\mu + \alpha_{j} = \mu_{j}\)</span>, the mean of group <span class="math notranslate nohighlight">\(j\)</span>. In order to reach observation <span class="math notranslate nohighlight">\(i\)</span> from that point, we need to walk a final <span class="math notranslate nohighlight">\(\epsilon_{ij}\)</span> number of steps. So think of the model equation as a map that takes you from the grand mean to the actual data value, via the group means. This makes the model <em>very simple</em>. Every data point has a predicted value that is equal to the mean of the group that the data point belongs to. The errors then reflect the differences between the group means and the raw data.</p>
<p>To make this even clearer, if we say that there are <span class="math notranslate nohighlight">\(n = 4\)</span> data point per-group then <span class="math notranslate nohighlight">\(i = 1,2,3,4\)</span> and the model for the whole dataset is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
&amp;\text{Group 1} \begin{cases}
        y_{11} &amp;= \mu + \alpha_{1} + \epsilon_{11} &amp;&amp;= \mu_{1} + \epsilon_{11} \\
        y_{21} &amp;= \mu + \alpha_{1} + \epsilon_{21} &amp;&amp;= \mu_{1} + \epsilon_{21} \\
        y_{31} &amp;= \mu + \alpha_{1} + \epsilon_{31} &amp;&amp;= \mu_{1} + \epsilon_{31} \\
        y_{41} &amp;= \mu + \alpha_{1} + \epsilon_{41} &amp;&amp;= \mu_{1} + \epsilon_{41} \\
\end{cases} \\
&amp;\text{Group 2} \begin{cases}
        y_{12} &amp;= \mu + \alpha_{2} + \epsilon_{12} &amp;&amp;= \mu_{2} + \epsilon_{12} \\
        y_{22} &amp;= \mu + \alpha_{2} + \epsilon_{22} &amp;&amp;= \mu_{2} + \epsilon_{22} \\
        y_{32} &amp;= \mu + \alpha_{2} + \epsilon_{32} &amp;&amp;= \mu_{2} + \epsilon_{32} \\
        y_{42} &amp;= \mu + \alpha_{2} + \epsilon_{42} &amp;&amp;= \mu_{2} + \epsilon_{42} \\
\end{cases} \\
&amp;\text{Group 3} \begin{cases}
        y_{13} &amp;= \mu + \alpha_{3} + \epsilon_{13} &amp;&amp;= \mu_{3} + \epsilon_{13} \\
        y_{23} &amp;= \mu + \alpha_{3} + \epsilon_{23} &amp;&amp;= \mu_{3} + \epsilon_{23} \\
        y_{33} &amp;= \mu + \alpha_{3} + \epsilon_{33} &amp;&amp;= \mu_{3} + \epsilon_{33} \\
        y_{43} &amp;= \mu + \alpha_{3} + \epsilon_{43} &amp;&amp;= \mu_{3} + \epsilon_{43} \\
\end{cases}
\end{alignat*}.
\end{split}\]</div>
<p>So, <span class="math notranslate nohighlight">\(\mu\)</span> is common across all the model equations (a <em>constant</em>), with <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> encoding the unique effect of level <span class="math notranslate nohighlight">\(j\)</span> of the categorical predictor. Together, these values will always equal the <em>group mean</em>.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Why write the ANOVA this way?</p>
<p>At first glance, it may seem unnecessarily complicated to write the ANOVA model as</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu + \alpha_{j} + \epsilon_{ij},
\]</div>
<p>rather than</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu_{j} + \epsilon_{ij}.
\]</div>
<p>The second form is actually more intuitive and makes it much more explicit that the ANOVA is using <em>means</em> as its predicted values.</p>
<p>However, there are more subtle benefits to a model that uses <em>deviations</em> from the grand mean to parameterise the model. To begin with, there is a clearer link here with regression models that constain an intercept (constant) and a slope. This will make mapping the ANOVA on to a regression model simpler. In addition, when we come to add <em>more predictors</em> to the ANOVA, each one can be conceptualised as a separate deviation from the grand mean. So, a model with an additional factor can be written as</p>
<div class="math notranslate nohighlight">
\[
y_{ijk} = \mu + \alpha_{j} + \beta_{k} + \epsilon_{ijk}
\]</div>
<p>as opposed to</p>
<div class="math notranslate nohighlight">
\[
y_{ijk} = \mu_{jk} + \epsilon_{ijk},
\]</div>
<p>where the additional factor is hidden within the subscripts. This becomes even more important when we talk about an ANOVA as a model comparison procedure, because we need to add and remove different predictors from the model. This is much clearer to do when the predictors are represented by explicit terms, rather than hidden in the definition of a mean. Finally, thinking about elements of a model as <em>deviations</em> from a constant will be helpful for more complex circumstances, such as mixed-effects model, which we will cover later in the course.</p>
<p>Aside from practical considerations, there are also some conceptual advantages to spelling the ANOVA out this way. To see why, consider the analogy of the model equation providing travel instructions to reach each data point. From this perspective, the model <span class="math notranslate nohighlight">\(y_{ij} = \mu_{j} + \epsilon_{ij}\)</span> is like starting from 0 and then travelling <span class="math notranslate nohighlight">\(\mu_{j}\)</span> steps to reach the group mean. The problem here is that most of that journey relates to the <em>units</em> of the data, rather than anything meaningful about our experiment. For instance, if we have measured reaction time in milliseconds, we will need to travel thousands of units to reach the data, but most of that journey has nothing to do with our experimental manipulations. If instead we <em>start</em> at the grand mean, then this scaling has already been taken care of and we start in a more reasonable position. In a way, the grand mean serves to start us in a decent place, separating out the experimental effects from the magnitude of the units. At the risk of stretching this metaphor too far, it is the difference between instructions for climbing a mountain starting from the base of the mountain, or including all the steps to travel to the base of the mountain from your own front door.</p>
</div>
<section id="numeric-example">
<h3>Numeric Example<a class="headerlink" href="#numeric-example" title="Link to this heading">#</a></h3>
<p>To make this particular model parameterisation even clearer, let us insert some actual numbers. In the table below, we list 3 groups with 3 observations each.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Group</p></th>
<th class="head"><p>Observations</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>2, 7, 4</p></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>8, 6, 9</p></td>
</tr>
<tr class="row-even"><td><p>C</p></td>
<td><p>10, 12, 8</p></td>
</tr>
</tbody>
</table>
</div>
<p>The estimated group means are then simply the sample means</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \hat{\mu}_{1} &amp;= \frac{2 + 7 + 4}{3} = 4.33 \\
    \hat{\mu}_{2} &amp;= \frac{8 + 6 + 9}{3} = 7.66 \\
    \hat{\mu}_{3} &amp;= \frac{10 + 12 + 8}{3} = 10
\end{align*}
\end{split}\]</div>
<p>and the estimated grand mean is</p>
<div class="math notranslate nohighlight">
\[
\hat{\mu} = \frac{4.33 + 7.66 + 10}{3} = 7.33.
\]</div>
<p>In terms of the factor effects, we therefore have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
    \hat{\alpha}_{1} &amp;= \hat{\mu}_{1} - \hat{\mu} = 4.33 - 7.33 &amp;&amp;= -3   \\
    \hat{\alpha}_{2} &amp;= \hat{\mu}_{2} - \hat{\mu} = 7.66 - 7.33 &amp;&amp;= 0.33 \\
    \hat{\alpha}_{3} &amp;= \hat{\mu}_{3} - \hat{\mu} = 10.0 - 7.33 &amp;&amp;= 2.67 
\end{alignat*}
\end{split}\]</div>
<p>Notice as well that <span class="math notranslate nohighlight">\(\sum{\hat{\alpha}_{j}} = 0\)</span>, which is an important feature we will come back to later. Inserting all of this into the model equations, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
&amp;\text{Group A} \begin{cases}
        2\phantom{0} &amp;= \overbrace{7.33 + (-3)}^{\mu + \alpha_{1}} &amp;+&amp; \overbrace{(-2.33)}^{\epsilon_{i1}} \\
        7\phantom{0} &amp;= 7.33 + (-3) &amp;+&amp; \phantom{(-}2.67  \\
        4\phantom{0} &amp;= 7.33 + (-3) &amp;+&amp; (-0.33) \\
\end{cases} \\
&amp;\text{Group B} \begin{cases}
        8\phantom{0} &amp;= \overbrace{7.33 + 0.33}^{\mu + \alpha_{2}} &amp;+&amp; \overbrace{\phantom{(-}0.34\phantom{)}}^{\epsilon_{i2}} \\
        6\phantom{0} &amp;= 7.33 + 0.33 &amp;+&amp; (-1.66) \\
        9\phantom{0} &amp;= 7.33 + 0.33 &amp;+&amp; \phantom{(-}1.34 \\
\end{cases} \\
&amp;\text{Group C} \begin{cases}
        9\phantom{0} &amp;= \overbrace{7.33 + 2.67}^{\mu + \alpha_{3}} &amp;+&amp; \overbrace{(-1.00)}^{\epsilon_{i3}} \\
        10 &amp;= 7.33 + 2.67 &amp;+&amp; \phantom{(-}0.00 \\
        11 &amp;= 7.33 + 2.67 &amp;+&amp; \phantom{(-}1.00 \\
\end{cases}
\end{alignat*}.
\end{split}\]</div>
<p>It is hopefully now clear that <span class="math notranslate nohighlight">\(\mu\)</span> is constant across all observations, <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> is unique to each group and <span class="math notranslate nohighlight">\(\epsilon_{ij}\)</span> is unique to each observation. In other words, <span class="math notranslate nohighlight">\(\mu\)</span> captures a univeral truth of the outcome variable, <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> captures how this truth changes across the different groups and <span class="math notranslate nohighlight">\(\epsilon_{ij}\)</span> captures the random abberations from this truth that are unique to each measurement.</p>
</section>
</section>
<section id="connecting-dummy-variable-regression-to-the-anova-model">
<h2>Connecting Dummy Variable Regression to the ANOVA Model<a class="headerlink" href="#connecting-dummy-variable-regression-to-the-anova-model" title="Link to this heading">#</a></h2>
<p>We have now seen in more detail the theory behind the ANOVA model. However, we have yet to explicitly connect this with the dummy variable regression model we saw in the previous part of this lesson. To do so, notice that there is nothing in the definition above that states how many values <span class="math notranslate nohighlight">\(j\)</span> should take. This is important because both the one-sample and two-sample <span class="math notranslate nohighlight">\(t\)</span>-tests are <em>sepecial cases</em> of the one-way ANOVA model. In the <em>one-sample</em> case, we set <span class="math notranslate nohighlight">\(j = 1\)</span> and we have</p>
<div class="math notranslate nohighlight">
\[
y_{i} = \mu + \epsilon_{i},
\]</div>
<p>which is about as simply as any linear model can get<a class="footnote-reference brackets" href="#j-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. In the <em>two-sample</em> case, we set <span class="math notranslate nohighlight">\(j = 1,2\)</span> and we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    y_{i1} &amp;= \mu + \alpha_{1} + \epsilon_{i1} \\
    y_{i2} &amp;= \mu + \alpha_{2} + \epsilon_{i2},
\end{align*}
\end{split}\]</div>
<p>which is even more clearly a simplification of the one-way ANOVA. From a modelling perspective, there is therefore <em>no difference</em> between a <span class="math notranslate nohighlight">\(t\)</span>-test and an ANOVA. In fact, giving these two procedures different names is almost entirely unnecessary.</p>
<p>Seeing that the two-sample <span class="math notranslate nohighlight">\(t\)</span>-test is equivalent to a simplified one-way ANOVA provides us a good opportunity to make a more explicit connection between the one-way ANOVA model</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu + \alpha_{j} + \epsilon_{ij}
\]</div>
<p>and the simple regression model</p>
<div class="math notranslate nohighlight">
\[
y_{i} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}.
\]</div>
<p>You may <em>almost</em> be able to see it, as these two models are very close to each other, save for the use of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span> instead of <span class="math notranslate nohighlight">\(\beta\)</span>, and the inclusion of <span class="math notranslate nohighlight">\(x\)</span> in the regression model. So, we just need to do a little bit more work before these specifications become <em>identical</em>.</p>
<section id="model-parameterisation-and-constraints">
<h3>Model Parameterisation and Constraints<a class="headerlink" href="#model-parameterisation-and-constraints" title="Link to this heading">#</a></h3>
<p>One of the problems with ANOVA models is that there are many different ways of writing them, using different numbers of parameters. These different options are known as model <em>parameterisations</em>. We have already seen two examples, where we have chosen to write the model as <span class="math notranslate nohighlight">\(E(y_{ij}) = \mu + \alpha_{j}\)</span> instead of <span class="math notranslate nohighlight">\(E(y_{ij}) = \mu_{j}\)</span>. Remember, the most important element of an ANOVA model is that the model predictions are always the <em>group means</em>. These are the least-squares estimates as well as the maximum likelihood estimates. So, no matter how we want to write the model, the best estimates will always be the sample means.</p>
<p>With this in mind, consider possible solutions for <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> when we have</p>
<div class="math notranslate nohighlight">
\[
E(y_{ij}) = \mu + \alpha_{j} = \mu_{j}.
\]</div>
<p>In effect, we want two numbers that add up to <span class="math notranslate nohighlight">\(\mu_{j}\)</span>, the sample mean. The problem is that there are literally an <em>infinite</em> number of possible choices here. For instance, if <span class="math notranslate nohighlight">\(\mu_{1} = 6\)</span>, we could choose <span class="math notranslate nohighlight">\(\mu = 5\)</span> and <span class="math notranslate nohighlight">\(\alpha_{1} = 1\)</span>, or <span class="math notranslate nohighlight">\(\mu = 200\)</span> and <span class="math notranslate nohighlight">\(\alpha_{1} = -194\)</span>, or <span class="math notranslate nohighlight">\(\mu = -3,467\)</span> and <span class="math notranslate nohighlight">\(\alpha_{1} = 3,473\)</span> and so on. This is know as the model being <em>overparameterised</em> or <em>unidentifiable</em>. If we try to use this model in a computer, the computer will not be able to find a unique single set of parameters because the options are, quite literally, <em>limitless</em>. This is not just a problem in a computer. If you tried to find the parameter values that maximise the likelihood, you would find yourself dealing with an infinite number of possibilities.</p>
<p>To stop this from happening and to force the model to choose one possibility out of the infinity of options, we have to impose a <em>constraint</em>. Think of this as adding some <em>rule</em> to finding parameters that allows the computer (or person) to settle on one possible solution. Although these constraints could be <em>anything</em>, we typically choose between constraints that lead to useful values of the parameters. Whilst <span class="math notranslate nohighlight">\(\mu = -3,467\)</span> and <span class="math notranslate nohighlight">\(\alpha_{1} = 3,473\)</span> would work (because the predicted value is still <span class="math notranslate nohighlight">\(\mu_{1}\)</span>), neither of these values are particularly useful or meaningful. However, if we impose the constraint that <span class="math notranslate nohighlight">\(\sum{\alpha_{j}} = 0\)</span>, then the <em>only</em> choice is that <span class="math notranslate nohighlight">\(\mu\)</span> is the grand mean and the <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> are deflections from the grand mean. These are much more useful parameters because they actually tell us something about the data that we are interested in.</p>
<p>Imposing <span class="math notranslate nohighlight">\(\sum{\alpha_{j}} = 0\)</span> is one constraint we can use, but there are many others. In fact, the use of dummy variables is a different form of constraint. Instead of imposing <span class="math notranslate nohighlight">\(\sum{\alpha_{j}} = 0\)</span>, the dummy variables actually impose that one of the factor effects is equal to 0. For instance, if we have <span class="math notranslate nohighlight">\(j = 1,2\)</span> and set <span class="math notranslate nohighlight">\(\alpha_{1} = 0\)</span>, then we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
    E\left(y_{i1}\right) &amp;= \mu + \alpha_{1} = \mu &amp;&amp;= \mu_{1} \\
    E\left(y_{i2}\right) &amp;= \mu + \alpha_{2} = \mu + \alpha_{2} &amp;&amp;= \mu_{2}.
\end{alignat*}
\end{split}\]</div>
<p>This means that <span class="math notranslate nohighlight">\(\mu\)</span> <em>has</em> to be the mean of the first group, which then forces <span class="math notranslate nohighlight">\(\alpha_{2}\)</span> to be the <em>mean difference</em>. This is the <em>only way</em> that this combination of parameters with this constraint can ever equal the group means. So, the correct way of viewing a regression model containing dummy variables is as an ANOVA model with a <em>built-in constraint</em> that produces useful parameter estimates<a class="footnote-reference brackets" href="#r-constraints-foot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
</section>
<section id="the-dummy-variable-anova-model">
<h3>The Dummy Variable ANOVA Model<a class="headerlink" href="#the-dummy-variable-anova-model" title="Link to this heading">#</a></h3>
<p>As a final step, we will just make the link between the constrainted one-way ANOVA and a dummy variable regression model absolutely explicit, so there can be no doubts that these are <em>exactly the same model</em>.</p>
<p>As we saw in the previous part of the lesson, the dummy variable representation of the two-sample <span class="math notranslate nohighlight">\(t\)</span>-test creates <em>two</em> equations for the <em>two</em> different categories</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    E\left(y_{i1}\right) &amp;= \beta_{0} + \left(\beta_{1} \times 0\right) = \beta_{0} \\
    E\left(y_{i2}\right) &amp;= \beta_{0} + \left(\beta_{1} \times 1\right) = \beta_{0} + \beta_{1}
\end{align*}
\end{split}\]</div>
<p>In other words, every data point from the first category gets a predicted value of <span class="math notranslate nohighlight">\(\beta_{0}\)</span> and every data point from the second category gets a predicted value of <span class="math notranslate nohighlight">\(\beta_{0} + \beta_{1}\)</span>. Putting this in the context of group means, we also know that <span class="math notranslate nohighlight">\(\beta_{0} = \mu_{1}\)</span> and <span class="math notranslate nohighlight">\(\beta_{1} = \left(\mu_{2} - \mu_{1}\right)\)</span>. If we substitute these values in to the regression equations above, we get</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    E\left(y_{i1}\right) &amp;= \mu_{1} \\
    E\left(y_{i2}\right) &amp;= \mu_{1} + \left(\mu_{2} - \mu_{1}\right) = \mu_{2}
\end{align*}
\end{split}\]</div>
<p>Putting it all together, we get</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
    y_{i1} &amp;= \beta_{0} + \epsilon_{i1} &amp;&amp;= \mu_{1} + \epsilon_{i1} \\
    y_{i2} &amp;= \beta_{0} + \beta_{1} + \epsilon_{i2} &amp;&amp;= \mu_{2} + \epsilon_{i2}
\end{alignat*}
\end{split}\]</div>
<p>So we know these models are equivalent in terms of the predicted values. However, if we now rename <span class="math notranslate nohighlight">\(\beta_{0} \rightarrow \mu\)</span>, <span class="math notranslate nohighlight">\(\beta_{1} \rightarrow \alpha_{2}\)</span> and assume that <span class="math notranslate nohighlight">\(\alpha_{1} = 0\)</span>, then we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
    y_{i1} &amp;= \mu + \epsilon_{i1} &amp;&amp;= \mu_{1} + \epsilon_{i1} \\
    y_{i2} &amp;= \mu + \alpha_{2} + \epsilon_{i2} &amp;&amp;= \mu_{2} + \epsilon_{i2},
\end{alignat*}
\end{split}\]</div>
<p>which is exactly the one-way ANOVA model with the constraint that <span class="math notranslate nohighlight">\(\alpha_{1} = 0\)</span>. So, we can now say that the dummy variable regression model is <em>identical</em> to a one-way ANOVA model, with the constraint that the <span class="math notranslate nohighlight">\(\alpha_{j}\)</span> associated with the <em>reference category</em> is equal to 0.</p>
</section>
</section>
<section id="dummy-variables-coding-2-levels">
<h2>Dummy Variables Coding &gt; 2 Levels<a class="headerlink" href="#dummy-variables-coding-2-levels" title="Link to this heading">#</a></h2>
<p>At this point, we should have a sense of the more formal linear model specification of a one-way ANOVA <em>and</em> should have a sense of how we can create this same model within the context of linear regression by using dummy variables. However, we have only seen this for cases where the categorical predictor has 2 levels. What happens when our our predictor has <em>more</em> than 2 levels?</p>
<p>The short answer is that we simply <em>add more dummy variables</em>. The general rule is that for <span class="math notranslate nohighlight">\(k\)</span> levels of a predictor we need to add <span class="math notranslate nohighlight">\(k - 1\)</span> dummy variables to the model. Notice that this fits with what we have already seen. For a two-sample <span class="math notranslate nohighlight">\(t\)</span>-test, <span class="math notranslate nohighlight">\(k = 2\)</span> and we had to add <span class="math notranslate nohighlight">\(2 - 1 = 1\)</span> dummy variable to the model. If it were a one-sample <span class="math notranslate nohighlight">\(t\)</span>-test, we would have <span class="math notranslate nohighlight">\(k = 1\)</span> and we would add <span class="math notranslate nohighlight">\(1 - 1 = 0\)</span> dummy variables to the model (because we only need an intercept). For the most basic one-way ANOVA case where <span class="math notranslate nohighlight">\(k = 3\)</span>, we therefore need to add <span class="math notranslate nohighlight">\(3 - 1 = 2\)</span> dummy variables to the model.</p>
<div class="tip admonition">
<p class="admonition-title">The number of dummy variables and constraints</p>
<p>The number of dummy variables we add is actually directly tied to the model constraint. We add <span class="math notranslate nohighlight">\(k-1\)</span> because we are setting one of the effects to 0. So we explicitly model <span class="math notranslate nohighlight">\(k-1\)</span> levels of the categorical predictor and let the <span class="math notranslate nohighlight">\(k\text{th}\)</span> level fall into the intercept. If we were to add <span class="math notranslate nohighlight">\(k\)</span> levels then the model will become unidentifiable (because the choice of estimates is infinite) and it would not work. <code class="docutils literal notranslate"><span class="pre">R</span></code> will not let you do this when it makes its own dummy variables, but you can try it for yourself and see what happens if you manually create as many dummy variables as factor levels.</p>
</div>
<section id="example-in-r">
<h3>Example in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#example-in-r" title="Link to this heading">#</a></h3>
<p>We will examine how this is done in <code class="docutils literal notranslate"><span class="pre">R</span></code> and then use this to discuss the theory in more detail. To begin with, we will redefine our <code class="docutils literal notranslate"><span class="pre">origin</span></code> variable to further split the <code class="docutils literal notranslate"><span class="pre">Other</span></code> category into <code class="docutils literal notranslate"><span class="pre">Japan</span></code> and <code class="docutils literal notranslate"><span class="pre">Europe</span></code>. We also convert this into a factor straight away and check the levels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">data</span><span class="p">(</span><span class="n">mtcars</span><span class="p">)</span>
<span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&#39;Japan&#39;</span><span class="p">,</span><span class="s">&#39;Japan&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span>
<span class="w">                   </span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span>
<span class="w">                   </span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Japan&#39;</span><span class="p">,</span><span class="s">&#39;Japan&#39;</span><span class="p">,</span><span class="s">&#39;Japan&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span>
<span class="w">                   </span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;USA&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">,</span><span class="s">&#39;Europe&#39;</span><span class="p">)</span>
<span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.factor</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">levels</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] &quot;Europe&quot; &quot;Japan&quot;  &quot;USA&quot;   
</pre></div>
</div>
</div>
</div>
<p>So we now have a categorical variable with <span class="math notranslate nohighlight">\(k = 3\)</span> levels and the dataset looks like this</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">mtcars</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb origin
Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4  Japan
Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4  Japan
Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1    USA
Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1    USA
Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2    USA
Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1    USA
Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4    USA
Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 Europe
Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 Europe
Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 Europe
Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 Europe
Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 Europe
Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 Europe
Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 Europe
Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4    USA
Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4    USA
Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4    USA
Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 Europe
Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2  Japan
Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1  Japan
Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1  Japan
Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2    USA
AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2    USA
Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4    USA
Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2    USA
Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 Europe
Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 Europe
Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 Europe
Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4    USA
Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 Europe
Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 Europe
Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 Europe
</pre></div>
</div>
</div>
</div>
<p>Before modelling anything, let us now see how <code class="docutils literal notranslate"><span class="pre">R</span></code> has coded these catgories in terms of dummy variables</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">contrasts</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       Japan USA
Europe     0   0
Japan      1   0
USA        0   1
</pre></div>
</div>
</div>
</div>
<p>So, now we have <em>two</em> dummy variables. The first (lablled <code class="docutils literal notranslate"><span class="pre">Japan</span></code>) is a 1 for all the Japanese cars and a 0 for everything else, whereas the second (labelled <code class="docutils literal notranslate"><span class="pre">USA</span></code>) is a 1 for all the USA cars and a 0 for everything else. Although we will not be using manually-defined dummy variables, it can be helpful to create these so you have the clearest sense of what is being put into the model. The code below shows the creation of these two dummy variables. Adding these to the model will results in an <em>identical</em> fit to the model we will use use a little further below<a class="footnote-reference brackets" href="#tryit-foot" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="w">         </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="p">)</span>
<span class="n">dummy.JAP</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
<span class="n">dummy.USA</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">dummy.JAP</span><span class="p">[</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;Japan&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span>
<span class="n">dummy.USA</span><span class="p">[</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;USA&quot;</span><span class="p">]</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span>

<span class="nf">print</span><span class="p">(</span><span class="n">dummy.JAP</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dummy.USA</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> [1] 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0
 [1] 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0
</pre></div>
</div>
</div>
</div>
<p>Including <em>two</em> dummy variables in the model will lead to <em>three</em> model parameters (intercept + two dummies), which we will call <span class="math notranslate nohighlight">\(\beta_{0}\)</span>, <span class="math notranslate nohighlight">\(\beta_{1}\)</span> and <span class="math notranslate nohighlight">\(\beta_{2}\)</span>. As we saw in previous examples, the intercept parameter <span class="math notranslate nohighlight">\(\beta_{0}\)</span> will become the <em>mean of the reference category</em>. In this example, this is whatever level is coded as a 0 across <em>both</em> dummy variables. The two slope parameters <span class="math notranslate nohighlight">\(\beta_{1}\)</span> and <span class="math notranslate nohighlight">\(\beta_{2}\)</span> will again become <em>mean differences</em> relative to the reference category. Without even fitting the model yet, we can work out that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \mu_{\text{EUR}} &amp;= \beta_{0} + (\beta_{1} \times \mathbf{0}) + (\beta_{2} \times \mathbf{0}) = \beta_{0} \\
    \mu_{\text{JAP}}  &amp;= \beta_{0} + (\beta_{1} \times \mathbf{1}) + (\beta_{2} \times \mathbf{0}) = \beta_{0} + \beta_{1} \\
    \mu_{\text{USA}}    &amp;= \beta_{0} + (\beta_{1} \times \mathbf{0}) + (\beta_{2} \times \mathbf{1}) = \beta_{0} + \beta_{2} \\
\end{align*}
\end{split}\]</div>
<p>The dummy coding has been highlighted here in <strong>bold</strong> to make the clearest connection to the table of dummy values given by <code class="docutils literal notranslate"><span class="pre">R</span></code> earlier. Our interpretation of the parameters in this model is therefore</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\beta_{0}\)</span></p></td>
<td><p>Mean of <code class="docutils literal notranslate"><span class="pre">Europe</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\beta_{1}\)</span></p></td>
<td><p>Mean difference <code class="docutils literal notranslate"><span class="pre">Japan</span> <span class="pre">-</span> <span class="pre">Europe</span></code></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\beta_{2}\)</span></p></td>
<td><p>Mean difference <code class="docutils literal notranslate"><span class="pre">USA</span> <span class="pre">-</span> <span class="pre">Europe</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<p>Linking back with the ANOVA model form earlier, this gives</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu + \alpha_{j} + \epsilon_{ij},
\]</div>
<p>where <span class="math notranslate nohighlight">\(j = (1,2,3)\)</span> and the constraint has been imposed that <span class="math notranslate nohighlight">\(\alpha_{3} = 0\)</span>. Let us double-check our understanding by fitting this model and examing the output</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">origin.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">origin</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">origin.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Call:
lm(formula = mpg ~ origin, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.8071 -4.1718 -0.7885  3.3444 10.5929 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   21.807      1.343  16.239 4.26e-16 ***
originJapan    3.753      2.618   1.434  0.16238    
originUSA     -5.669      1.935  -2.929  0.00656 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 5.025 on 29 degrees of freedom
Multiple R-squared:  0.3498,	Adjusted R-squared:  0.3049 
F-statistic:   7.8 on 2 and 29 DF,  p-value: 0.001947
</pre></div>
</div>
</div>
</div>
<p>Let us calculate the group means and differences manually and compare them with the model estimates</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">mu.EUR</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">mpg</span><span class="p">[</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;Europe&quot;</span><span class="p">])</span>
<span class="n">mu.JAP</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">mpg</span><span class="p">[</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;Japan&quot;</span><span class="p">])</span>
<span class="n">mu.USA</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">mtcars</span><span class="o">$</span><span class="n">mpg</span><span class="p">[</span><span class="n">mtcars</span><span class="o">$</span><span class="n">origin</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;USA&quot;</span><span class="p">])</span>

<span class="n">beta.0</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mu.EUR</span>
<span class="n">beta.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mu.JAP</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mu.EUR</span>
<span class="n">beta.2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mu.USA</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mu.EUR</span>

<span class="n">comp.table</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="s">&quot;Means&quot;</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">beta.0</span><span class="p">,</span><span class="n">beta.1</span><span class="p">,</span><span class="n">beta.2</span><span class="p">),</span>
<span class="w">                         </span><span class="s">&quot;Estimates&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">coef</span><span class="p">(</span><span class="n">origin.mod</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="n">comp.table</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                Means Estimates
(Intercept) 21.807143 21.807143
originJapan  3.752857  3.752857
originUSA   -5.668681 -5.668681
</pre></div>
</div>
</div>
</div>
<p>As we can see, the model fit is exactly as expected from our knowledge of the dummy variables. Furthermore, the automatic tests on the slope parameters are equivalent to performing <span class="math notranslate nohighlight">\(t\)</span>-tests on two of the possible mean differences across the levels of <code class="docutils literal notranslate"><span class="pre">origin</span></code>. On this basis, we could immediately draw some conclusions about the differences in MPG between these categories. For instance, if we want to use NHST for inference, we could say that there is a significant difference between the average MPG of USA cars and European cars (<span class="math notranslate nohighlight">\(t_{29} = -2.929, p &lt; 0.01\)</span>), but not between the average MPG of Japanese cars and European cars (<span class="math notranslate nohighlight">\(t_{29} = 1.434, p = 0.16\)</span>). What about comparing the USA and Japan? We could simply relevel the <code class="docutils literal notranslate"><span class="pre">origin</span></code> factor and change the reference in order to generate this test.</p>
<aside class="topic">
<p class="topic-title">What do you now know?</p>
<p>In this section, we have explored how a One-way ANOVA can be represented within a multiple regression through the inclusion of dummy variables. After reading this section, you should have a good sense of:</p>
<ul class="simple">
<li><p>The conceptualisation of an ANOVA as a basic linear model that uses <em>group means</em> as the predicted values.</p></li>
<li><p>The idea that these group means can be represented as a combination of the <em>grand mean</em> and a separate <em>effect</em> for each level of the categorical predictor.</p></li>
<li><p>The concept that this model can be represented by a multiple regression that contains <span class="math notranslate nohighlight">\(k-1\)</span> dummy variables, where <span class="math notranslate nohighlight">\(k = 1\)</span> and <span class="math notranslate nohighlight">\(k = 2\)</span> are special cases that are equivalent to a <em>one-sample</em> and <em>two-sample</em> <span class="math notranslate nohighlight">\(t\)</span>-tests.</p></li>
<li><p>The concept that the multiple regression model is equiavlent to the One-way ANOVA model, with the additional constraint that one of the factor effects is 0.</p></li>
<li><p>The concept that a constraint of some sort is always needed in an ANOVA model due to the infinite number of solutions available.</p></li>
<li><p>The idea that the interpretation of the multiple regression parameters is a simple extension of the single dummy variable example, where the intercept represents the mean of a single group (the <em>reference group</em>) and the remaining slopes represent <em>mean differences</em> with that reference group.</p></li>
</ul>
</aside>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="j-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Here, we have removed <span class="math notranslate nohighlight">\(j\)</span> because it is constant across all the model equations and thus has become redundant.</p>
</aside>
<aside class="footnote brackets" id="r-constraints-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>In fact, <code class="docutils literal notranslate"><span class="pre">R</span></code> contains different options for how factors are coded, which are effectively different constraints. Each one differs in how it forces the model estimates to be certain values. So, if you do not like the default constraint <code class="docutils literal notranslate"><span class="pre">R</span></code> imposes, you can always change it. We will see more about this later.</p>
</aside>
<aside class="footnote brackets" id="tryit-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>We will leave it as an exercise if you want to validate this for yourself. Remember, the only difference between doing this manually and letting <code class="docutils literal notranslate"><span class="pre">R</span></code> do it automatically is whether other functions inside <code class="docutils literal notranslate"><span class="pre">R</span></code> “know” that the two dummy variable actually represent a single categorical variable. Without this knowledge, everything else inside <code class="docutils literal notranslate"><span class="pre">R</span></code> will treat them as two separate binary variables.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.dummy-variables.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Dummy Variable Regression</p>
      </div>
    </a>
    <a class="right-next"
       href="3.omnibus-tests-model-comps.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Omnibus Tests and Model Comparisons</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#one-way-anova-as-a-linear-model">One-way ANOVA as a Linear Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#numeric-example">Numeric Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#connecting-dummy-variable-regression-to-the-anova-model">Connecting Dummy Variable Regression to the ANOVA Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-parameterisation-and-constraints">Model Parameterisation and Constraints</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-dummy-variable-anova-model">The Dummy Variable ANOVA Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dummy-variables-coding-2-levels">Dummy Variables Coding &gt; 2 Levels</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-in-r">Example in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar & Dr George Farmer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025-26.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>