{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Higher-order ANOVA Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c48fa9",
   "metadata": {},
   "source": [
    "## The Higher-order ANOVA Framework\n",
    "\n",
    "### Terminology and Mean Tables\n",
    "\n",
    "### Cell Means and Marginal Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f7571",
   "metadata": {},
   "source": [
    "\n",
    "```{admonition} Higher-order terminology\n",
    ":class: tip\n",
    "... For instance, the most basic higher-order ANOVA is the two-way ANOVA, that contains two factors. IF each factor had two levels, we would write this as a $2 \\times 2$ ANOVA. If the second factor had three levels, we would call it a $2 \\times 3$ ANOVA. If there were *three* factors, we would have a three-way ANOVA. If each factor had two levels we could call it a $2 \\times 2 \\times 2$ ANOVA, and so on.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fa1a9",
   "metadata": {},
   "source": [
    "## The Additive Model\n",
    "Let us start with the simplest approach, which is to just add another factor to the model. In terms of notation, this is a basic extension of what we already known\n",
    "\n",
    "$$\n",
    "y_{ijk} = \\mu + \\alpha_{i} + \\beta_{j} + \\epsilon_{ijk},\n",
    "$$\n",
    "\n",
    "where $\\alpha_{i}$ is the effect associated with Factor A and $\\beta_{j}$ is the effect associated with Factor B. The most basic form of this model would be one that represents a $2 \\times 2$ design, with $i = 1,2$ and $j = 1,2$.\n",
    "\n",
    "It is important to recognise at this point the assumptions that this model makes. If we stick with a $2 \\times 2$ design then we have 4 cell means \n",
    "\n",
    "|                       | Factor B: Level 1 | Factor B: Level 2 | \n",
    "|-----------------------|-------------------|-------------------|\n",
    "| **Factor A: Level 1** | $\\mu_{11}$        | $\\mu_{12}$        |\n",
    "| **Factor A: Level 2** | $\\mu_{21}$        | $\\mu_{22}$        |\n",
    "\n",
    "and thus 4 unique predicted values formed from:\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    \\mu_{11} &= \\mu + \\alpha_{1} + \\beta_{1} \\\\\n",
    "    \\mu_{21} &= \\mu + \\alpha_{2} + \\beta_{1} \\\\\n",
    "    \\mu_{12} &= \\mu + \\alpha_{1} + \\beta_{2} \\\\\n",
    "    \\mu_{22} &= \\mu + \\alpha_{2} + \\beta_{2}. \n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Although probably not immediately obvious, this model makes the assumption that the difference between the levels of each factor is the *same* irrespective of the levels of the other factor. In other words, the model assumes a *constant* difference between the rows or the columns of the means table, no matter which cell you start in. For instance, the two differences between the 1st and 2nd levels of Factor A are\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    \\mu_{11} - \\mu_{21} &= \\left(\\mu + \\alpha_{1} + \\beta_{1}\\right) - \\left(\\mu + \\alpha_{2} + \\beta_{1}\\right) &&= \\alpha_{1} - \\alpha_{2} \\\\\n",
    "    \\mu_{12} - \\mu_{22} &= \\left(\\mu + \\alpha_{1} + \\beta_{2}\\right) - \\left(\\mu + \\alpha_{2} + \\beta_{2}\\right) &&= \\alpha_{1} - \\alpha_{2}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "As such, no matter the level of Factor B, $\\alpha_{1} - \\alpha_{2}$ is always the same. The same is true across the levels of Factor A, where $\\beta_{1} - \\beta_{2}$ is always the same. In other words, this model make the strong assumption that the two factors are entirely *independant* and do not affect each other in any way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ef5b3",
   "metadata": {},
   "source": [
    "\n",
    "```{admonition} Grounding ANOVA Examples\n",
    ":class: tip\n",
    "It can be difficult at times to conceptualise what an ANOVA model is saying when working in abstract terms such as \"Factor A\" or $\\mu_{12}$. Often, it is useful to have a concrete example to drive the point home. For instance, imagine that Factor A is *depression diagnosis* with two levels: *depressed* and *non-depressed*. Now imagine that Factor B is *anxiety status* with two levels: *high-anxiety* and *low-anxiety*. Our $2 \\times 2$ table of means would be\n",
    "\n",
    "|                   | Depression: Non-Depressed | Depression: Depressed | \n",
    "|-------------------|---------------------------|-----------------------|\n",
    "| **Anxiety: Low**  | $\\mu_{11}$                | $\\mu_{12}$            |\n",
    "| **Anxiety: High** | $\\mu_{21}$                | $\\mu_{22}$            |\n",
    "\n",
    "\n",
    "Remembering that the additive model assumes a *constant* row difference and a *constant* column difference, this is the same as assuming that the difference between those with and without depression is the same, irrespective of their anxiety. Similarly, this is the same as assuming that the difference between those with high and low anxiety is the same, irrespective of whether they are depressed. Of course, this depends entirely on what our outcome measure actually is. However, in the real world, it would seem unlikely that depression and anxiety are two completely independant conditions that do not influence each other in any way. As such, this assumption of the additive model is somewhat questionable.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee651a01",
   "metadata": {},
   "source": [
    "It is important to recognise that this assumption of additivity is actually a *constraint* on the fitting procedure. By specifying the model in this fashion, either least-squares or maximum likelihood will produce estimated means that adhere to additivity. The estimated cell means will therefore have a constant difference between the rows and the columns of the table. However, if this assumption is not true, the estimated call means and the sample cell means will be *different*. The degree to which the model does not fit the actual sample means is therefore indicative of the degree to which the additivity assumption does not hold. We will see this in the example below and will be the starting point for justifying the concept of an *interaction* a little later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b204600",
   "metadata": {},
   "source": [
    "### Additive Model Example in `R`\n",
    "As an example, let us expand our `mtcars` example with an addition categorical predictor. Within `mtcars` there already exists a factor called `vs` which indicates whether the engine is V-shaped or straight. This is already coded as a dummy variable, but we will label it so that it is clearer what it means before turning it into a factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f7e14d2",
   "metadata": {
    "tags": [
     "remove-cell"
    ],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(mtcars)\n",
    "mtcars$origin <- c('Other','Other','USA','USA','USA','USA','USA','Other','Other','Other',\n",
    "                   'Other','Other','Other','Other','USA','USA','USA','Other','Other',\n",
    "                   'Other','Other','USA','USA','USA','USA','Other','Other','Other',\n",
    "                   'USA','Other','Other','Other')\n",
    "mtcars$origin <- as.factor(mtcars$origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37f4dcad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"straight\" \"v-shaped\"\n"
     ]
    }
   ],
   "source": [
    "vs.lab <- rep(\"\",length(mtcars$mpg)) \n",
    "vs.lab[mtcars$vs == 0] <- \"v-shaped\"\n",
    "vs.lab[mtcars$vs == 1] <- \"straight\"\n",
    "\n",
    "mtcars$vs <- vs.lab\n",
    "mtcars$vs <- as.factor(mtcars$vs)\n",
    "print(levels(mtcars$vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600075be",
   "metadata": {},
   "source": [
    "We will also work with the simpler version of `origin`, where we only had 2 levels: `USA` and `Other`. Our table of means is therefore\n",
    "\n",
    "|                  | Origin: Other | Origin: USA | \n",
    "|------------------|---------------|-------------|\n",
    "| **VS: Straight** | $\\mu_{11}$    | $\\mu_{12}$  |\n",
    "| **VS: V-shaped** | $\\mu_{21}$    | $\\mu_{22}$  |\n",
    "\n",
    "We can now examine how `R` has coded both `vs` and `origin` as dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7d80faf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      USA\n",
      "Other   0\n",
      "USA     1\n",
      "         v-shaped\n",
      "straight        0\n",
      "v-shaped        1\n"
     ]
    }
   ],
   "source": [
    "print(contrasts(mtcars$origin))\n",
    "print(contrasts(mtcars$vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16950d52",
   "metadata": {},
   "source": [
    "So there are now 4 unique combinations of dummy values that lead to the 4 cell means. This leads to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49876b0c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    &\\mu^{(\\texttt{other},\\texttt{straight})} &&= \\beta_{0} + (\\beta_{1} \\times \\mathbf{0}) + (\\beta_{2} \\times \\mathbf{0}) = \\beta_{0} \\\\\n",
    "    &\\mu^{(\\texttt{USA},\\texttt{straight})}   &&= \\beta_{0} + (\\beta_{1} \\times \\mathbf{1}) + (\\beta_{2} \\times \\mathbf{0}) = \\beta_{0} + \\beta_{1} \\\\\n",
    "    &\\mu^{(\\texttt{other},\\texttt{v-shaped})} &&= \\beta_{0} + (\\beta_{1} \\times \\mathbf{0}) + (\\beta_{2} \\times \\mathbf{1}) = \\beta_{0} + \\beta_{2} \\\\\n",
    "    &\\mu^{(\\texttt{USA,v-shaped})}   &&= \\beta_{0} + \\underbrace{(\\beta_{1} \\times \\mathbf{1})}_{\\texttt{origin}} + \\underbrace{(\\beta_{2} \\times \\mathbf{1})}_{\\texttt{vs}} = \\beta_{0} + \\beta_{1} + \\beta_{2} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "Based on this we can summise that\n",
    "\n",
    "| Parameter   | Meaning                                               | Interpretation           |\n",
    "|-------------|-------------------------------------------------------|--------------------------|\n",
    "| $\\beta_{0}$ | Mean of `(other,straight)` cell                       | Reference cell           |\n",
    "| $\\beta_{1}$ | Mean difference `(USA,straight) - (other,straight)`   | Constant *column* effect |\n",
    "| $\\beta_{2}$ | Mean difference `(other,v-shaped) - (other,straight)` | Constant *row* effect    |\n",
    "\n",
    "This also helps make sense of how the model prediction works. If we start at the reference cell ($\\beta_{0} = \\mu_{11}$) and then add the *row effect* ($\\beta_{1}$) we move *down* a row and end up at $\\mu_{21}$. Instead, if we start at the reference cell ($\\beta_{0} = \\mu_{11}$) and then add the *column effect* ($\\beta_{2}$) we move *across* a column and end up at $\\mu_{12}$. Finally, if we start at the reference cell ($\\beta_{0} = \\mu_{11}$) and then add the *row effect* ($\\beta_{1}$) and the *column effect* ($\\beta_{2}$) we move down a row and across a column and end up at $\\mu_{22}$. Note that this only works because of the additive assumptions about contant row and column effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c13a3c",
   "metadata": {},
   "source": [
    "Given all this, we can now see how `R` fits this model and check that it aligns with our understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3450611",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = mpg ~ origin + vs, data = mtcars)\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median      3Q     Max \n",
      "-7.7035 -3.2079  0.1795  1.9298  8.3965 \n",
      "\n",
      "Coefficients:\n",
      "            Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)   25.504      1.157  22.036  < 2e-16 ***\n",
      "originUSA     -4.416      1.587  -2.783  0.00939 ** \n",
      "vsv-shaped    -6.433      1.571  -4.094  0.00031 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Residual standard error: 4.139 on 29 degrees of freedom\n",
      "Multiple R-squared:  0.5588,\tAdjusted R-squared:  0.5283 \n",
      "F-statistic: 18.36 on 2 and 29 DF,  p-value: 7.044e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add.mod <- lm(mpg ~ origin + vs, data=mtcars)\n",
    "print(summary(add.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c91558",
   "metadata": {},
   "source": [
    "Based on this, we can construct the estimated cell means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74c4e44c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            origin.other origin.USA\n",
      "vs.straight     25.50350   21.08716\n",
      "vs.vshaped      19.07019   14.65385\n"
     ]
    }
   ],
   "source": [
    "beta <- coef(add.mod)\n",
    "\n",
    "# fitted cell means\n",
    "mu.other.straight <- beta[1]\n",
    "mu.USA.straight   <- beta[1] + beta[2]\n",
    "mu.other.vshaped  <- beta[1] + beta[3]\n",
    "mu.USA.vshaped    <- beta[1] + beta[2] + beta[3]\n",
    "\n",
    "# means table\n",
    "means.tbl <- data.frame(\"origin.other\"=c(mu.other.straight,mu.other.vshaped),\n",
    "                        \"origin.USA\"  =c(mu.USA.straight,  mu.USA.vshaped),\n",
    "                        row.names=c(\"vs.straight\",\"vs.vshaped\"))\n",
    "\n",
    "print(means.tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbe319",
   "metadata": {},
   "source": [
    "As expected, these fitted values have a constant difference between each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "668b8171",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 6.433314\n",
      "[1] 6.433314\n"
     ]
    }
   ],
   "source": [
    "print(unname(mu.other.straight - mu.other.vshaped))\n",
    "print(unname(mu.USA.straight   - mu.USA.vshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c57b3",
   "metadata": {},
   "source": [
    "and a constant difference between each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c37e47af",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 4.416336\n",
      "[1] 4.416336\n"
     ]
    }
   ],
   "source": [
    "print(unname(mu.other.straight - mu.USA.straight))\n",
    "print(unname(mu.other.vshaped  - mu.USA.vshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c700918",
   "metadata": {},
   "source": [
    "Unfortunately, these estimated means do not match the actual sample means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44225415",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            origin.other origin.USA\n",
      "vs.straight     25.59091   20.76667\n",
      "vs.vshaped      18.95000   14.75000\n"
     ]
    }
   ],
   "source": [
    "# sample cell means\n",
    "mu.other.straight <- mean(mtcars$mpg[mtcars$origin == \"Other\" & mtcars$vs == \"straight\"])\n",
    "mu.USA.straight   <- mean(mtcars$mpg[mtcars$origin == \"USA\"   & mtcars$vs == \"straight\"])\n",
    "mu.other.vshaped  <- mean(mtcars$mpg[mtcars$origin == \"Other\" & mtcars$vs == \"v-shaped\"])\n",
    "mu.USA.vshaped    <- mean(mtcars$mpg[mtcars$origin == \"USA\"   & mtcars$vs == \"v-shaped\"])\n",
    "\n",
    "# means table\n",
    "means.tbl <- data.frame(\"origin.other\"=c(mu.other.straight,mu.other.vshaped),\n",
    "                        \"origin.USA\"  =c(mu.USA.straight,  mu.USA.vshaped),\n",
    "                        row.names=c(\"vs.straight\",\"vs.vshaped\"))\n",
    "\n",
    "print(means.tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750016ab",
   "metadata": {},
   "source": [
    "These are not too far off, however, this does suggest that the assumptions of the additive model may not hold in this example. It is also possible that the fitted values are close enough that we can treat these factors as additive for simplicity. We will come back to this when we explore the Full Factorial model below. First, we need to discuss the ANOVA omnibus effects in an additive $2 \\times 2$ design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420f97b",
   "metadata": {},
   "source": [
    "### Main Effects\n",
    "\n",
    "So, the main effect of Factor A is equivalent to the following model comparison\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    \\mathcal{M}_{0} &: y_{jk}  &&= \\mu + \\beta_{j} + \\epsilon_{jk} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} &&= \\mu + \\alpha_{i} + \\beta_{j} + \\epsilon_{ijk},\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "and the main effect of Factor B is equivalent to the following model comparison\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    \\mathcal{M}_{0} &: y_{ik}  &&= \\mu + \\alpha_{i} + \\epsilon_{ik} \\\\\n",
    "    \\mathcal{M}_{1} &: y_{ijk} &&= \\mu + \\alpha_{i} + \\beta_{j} + \\epsilon_{ijk}.\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "In each case, we simply remove the terms associated with the factor of interest and see whether the change in the residual sums-of-squares is large relative to the error.\n",
    "\n",
    "As we saw previously, we can do this as explicit model comparisons using the `anova()` function, where the main effect of `origin` would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "782fc3bb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Model 1: mpg ~ vs\n",
      "Model 2: mpg ~ origin + vs\n",
      "  Res.Df    RSS Df Sum of Sq      F   Pr(>F)   \n",
      "1     30 629.52                                \n",
      "2     29 496.86  1    132.66 7.7428 0.009386 **\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "null.mod <- lm(mpg ~ vs,          data=mtcars)\n",
    "full.mod <- lm(mpg ~ origin + vs, data=mtcars)\n",
    "\n",
    "print(anova(null.mod,full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291846e1",
   "metadata": {},
   "source": [
    "and the main effect of `vs` would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d482c4de",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Model 1: mpg ~ origin\n",
      "Model 2: mpg ~ origin + vs\n",
      "  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n",
      "1     30 784.06                                  \n",
      "2     29 496.86  1     287.2 16.763 0.0003096 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "null.mod <- lm(mpg ~ origin,      data=mtcars)\n",
    "full.mod <- lm(mpg ~ origin + vs, data=mtcars)\n",
    "\n",
    "print(anova(null.mod,full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054947b2",
   "metadata": {},
   "source": [
    "Or, we could much more easily give the full model to the `Anova()` function from the `car` package to deal with the model comparisons automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "974f11f2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anova Table (Type II tests)\n",
      "\n",
      "Response: mpg\n",
      "          Sum Sq Df F value    Pr(>F)    \n",
      "origin    132.66  1  7.7428 0.0093864 ** \n",
      "vs        287.20  1 16.7628 0.0003096 ***\n",
      "Residuals 496.86 29                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "print(Anova(full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c051e2",
   "metadata": {},
   "source": [
    "Which agrees with the comparisons we ran above. Notice, however, that generating the full ANOVA table using `anova()` gives us a *different* answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdcf6cfb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of Variance Table\n",
      "\n",
      "Response: mpg\n",
      "          Df Sum Sq Mean Sq F value    Pr(>F)    \n",
      "origin     1 341.99  341.99  19.961 0.0001110 ***\n",
      "vs         1 287.20  287.20  16.763 0.0003096 ***\n",
      "Residuals 29 496.86   17.13                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "print(anova(full.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fbf01",
   "metadata": {},
   "source": [
    "We will discuss the reasons why later on the unit. For now, this should be evidence enough for always using `Anova()` instead of `anova()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f3651",
   "metadata": {},
   "source": [
    "## The Full Factorial Model\n",
    "\n",
    "So, the interaction terms represents that \"bit extra\" that we need in order to allow the fitted means to be the same as the sample means. The additive model only gets us so far. The interaction terms allows for a cell-specific adjustment to shift the additive model means so that they are the actual cell means. The larger this adjustment, the larger the interaction effect. In other words, the more that effect of one factor depends upon the levels of the other. \n",
    "\n",
    "Note that you do not *have* to include an interaction. A typical approach in Psychology is always to specify a *full factorial* model containing every main effect and every possible interaction. In general, this is probably the approach you should take, otherwise you make strong assumptions that all interactions are 0. However, there is nothing that says you *have* to do this. You have the flexibility to only include the effects that you want in the model. You just have to be aware of the consequences of doing so. \n",
    "\n",
    "$$\n",
    "SS_{\\text{model}} = SS_{A} + SS_{B} + SS_{AB}\n",
    "$$\n",
    "\n",
    "### Cell Means and Marginal Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe63c1",
   "metadata": {},
   "source": [
    "\n",
    "```{admonition} Interaction notation\n",
    ":class: tip\n",
    "There are different conventions for writing an interaction into a model. Some authors like to add an additional symbol to denote the interaction, leaving the subscripts to imply that the term is an interaction rather than a main effect. For instance\n",
    "\n",
    "$$\n",
    "y_{ijk} = \\mu +\\alpha_{i} + \\beta_{j} + \\gamma_{ij} + \\epsilon_{ijk},\n",
    "$$\n",
    "\n",
    "where $\\gamma_{ij}$ is the interaction. Personally, we like to use the following notation as it makes the interaction terms much more explicit, particularly in terms of which effects the interaction corresponds to\n",
    "\n",
    "$$\n",
    "y_{ijk} = \\mu +\\alpha_{i} + \\beta_{j} + (\\alpha\\beta)_{ij} + \\epsilon_{ijk}.\n",
    "$$\n",
    "\n",
    "For a model containing multiple interactions, this helps to make the meaning of the terms clearer, rather than somewhat hiding it in the subscripts. For instance, a 3-way full factorial ANOVA would be\n",
    "\n",
    "$$\n",
    "y_{ijkl} = \\mu +\\alpha_{i} + \\beta_{j} + \\gamma_{k} + (\\alpha\\beta)_{ij} + (\\beta\\gamma)_{jk} + (\\alpha\\gamma)_{ik} + (\\alpha\\beta\\gamma)_{ijk} + \\epsilon_{ijkl},\n",
    "$$\n",
    "\n",
    "where each main effect, 2-way interaction and 3-way interaction is clearly denoted.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10cbb17",
   "metadata": {},
   "source": [
    "\n",
    "### Interactions as Multiplicative Effects\n",
    "\n",
    "### Interpreting Main Effects in the Presence of an Interaction\n",
    "... We can see that averaging over either the rows or columns of the means table only makes sense when additivity is assumed. If we do this when there is not a constant row or column effect, the very meaning of the main effect breaks down. If we want to think of a main effect as the consistent effect of a factor irrespective of other factors, this is no longer valid when those effects are *not* consistent. As such, main effects must assume additivity to make any sense. If there is a large interaction effect, the very concept of a main effects no longer make sense. \n",
    "\n",
    "Indeed, you do not need to know anything about the model to see this. The interaction tells us that the main effect depends upon the level of another factor. Why would we then try to look at a main effect *ignoring* that factor? We know that other factor matters. That is what the interaction tells us. Unfortuantely, it is common practise in Psychology to ignore this and try to interpret main effects in the presence of significant interactions. Hopefully it is clear how meaningless this actually is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf905e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
